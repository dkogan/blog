#+TITLE: Dima Kogan
#-DESCRIPTION: Dima's notes
#+DATE: <2014-07-25 Fri 17:34>
#+AUTHOR Dima Kogan

#+STARTUP: logdone
#+STARTUP: overview

#+PLUGIN_QRCODE: nil
#+TEMPLATE_DIR: templates
#+URL: http://notes.secretsauce.net

#+DEFAULT_CATEGORY: Notes
#+FILENAME_SANITIZER: ob-sanitize-string
#+POST_SORTER: ob-sort-posts-by-title
#+OPTIONS: tex:dvipng

* Blog details
** Copyright
  :PROPERTIES:
  :SNIPPET:  t
  :END:

   The text is in the public domain. All code is copyright [[mailto:dima -at- secretsauce -dot- net][Dima Kogan]], licensed
   under the LGPL /unless otherwise noted/

** Navigation
  :PROPERTIES:
  :SNIPPET:  t
  :END:

- [[file:{lisp}(ob:path-to-root){/lisp}/tags][Tags]]
- [[file:{lisp}(ob:path-to-root){/lisp}/archives.html][Archives]]
- [[file:{lisp}(ob:path-to-root){/lisp}/index.xml][RSS]]
- [[https://www.github.com/dkogan][Github]]

* Toplevel page
  :PROPERTIES:
  :PAGE:     index.html
  :TEMPLATE: blog_static_no_title.html
  :END:

This space is meant to contain whatever Dima is thinking about at various times.
The full set of entries is in the [[file:{lisp}(ob:path-to-root){/lisp}/archives.html][Archives]]. Various coding projects/experiments
are in the [[https://www.github.com/dkogan][Github]] repostories. Contact info is at the bottom of the page (in
tiny print).

Most recent post: [[file:{lisp}(ob:link-to-post (car ALL-POSTS)){/lisp}][{lisp}(ob:post-title (car ALL-POSTS)){/lisp}]]

* Notes
** DONE First post                                             :o@blog:emacs:
  CLOSED: [2014-03-17 Mon 03:48]

So it has come to this. I'd like to know what the hell I actually do all day, so
maybe keeping a record will make that more clear. Today, I started a blog! I had
some ideas about the publishing system I wanted going in, and finding that
system was interesting. Requirements:

- Editing in emacs with org-mode
- Publishing with a simple file copy (or git push, etc)
- Static pages; no server work other than sending the files
- No javascript; no client work other than basic rendering
- Premade templates so that things look reasonable out of the box
- Does not require me to actually learn web development

Turns out you can't have everything, but you can get close. In its simplest, org
itself can push HTML without anything else. This is minimally-styled, and not
assembled into pages that talk to each other. The org-mode wiki (worg) has a
list of various publishing systems that use org as a backend:
http://orgmode.org/worg/org-blog-wiki.html. There are several exporters to
common blogging platforms, and a few specially-written things.

In the end, I was looking at two systems: [[http://renard.github.io/o-blog/][*o-blog*]] and [[https://github.com/kelvinh/org-page][*org-page*]]. Both are
/blogging/ systems, so you get RSS, tags, timelines, etc.

*** Advantages of o-blog

- Neither o-blog or org-page are used heavily, but o-blog appears to have more
  users: I could only find one org-page site that wasn't the author's personal
  page
- Org-page feels a bit rougher than o-blog, which has a much nicer-looking
  layout out of the box
- Org-page feels more boilerplaty. Each file needs lots of tags that could
  potentially conflict
- Org-page has some sort of git integration, which maybe is actually a positive,
  but I didn't dig into it. The main publishing function takes some git refs,
  the system expects a particular branching structure, etc. Those are probably
  good, but it should be obvious what the basic export-all-this-stuff command is

*** Advantages of org-page

- Org-page organizes the posts into several files, while o-blog has the whole
  thing in one file. With o-blog this probably will get slow as the posts
  accumulate. The author is currently working on an update that supposedly would
  resolve this
- The major downside of o-blog is that it produces a very heavy,
  javascript-laden site that doesn't work /at all/ with JS turned off.

I was leaning towards o-blog, so I learned some web-development. O-blog uses
LESS instead of CSS, using some runtime javascript to convert the LESS (that the
browser doesn't understand) to CSS (which the browser /does/ understand). So I
exported the LESS to CSS, scrubbed the output to get rid of the shinier bits,
and I have my blog. This look reasonable, but still not ideal. Current issues:

- The new JS-free navigation bars I wrote disappear when the browser window is
  narrower than some threshold. This is almost certainly intentional in the CSS.
  It needs to do something better than simply disappearing. The JS version /did/
  do someting better, and I should try to match that
- O-blog renders equations with MathJax, which uses javascript. Org has the
  capability to generate images for each equation, and output those. I'd like to
  do that, but o-blog can't figure that out. I'll fix it at some point
- Tables look somewhat weird. Pretty sure this is an org feature (not o-blog).
  On opera I see a full grid, except the left bar. On firefox I see the top and
  bottom bars and no others.

There're probably more, and I'll discover them as I go. In the meantime, the
code and content are on Github.
** DONE Using DEMs to get GPX elevation profiles                :hiking:data:
   CLOSED: [2014-03-18 Tue 00:49]

When considering a new hike, I often want to know the elevation profile of the
route. Usually all I have is a 2D elevation track, from [[http://www.openstreetmap.org][OpenStreetMap]] for
instance; clearly this lacks elevation information.

Unrelatedly we have access to gridded elevation data. This primarily comes from
the [[http://en.wikipedia.org/wiki/SRTM][SRTM]] project: data available here: http://dds.cr.usgs.gov/srtm/version2_1/.
The raw SRTM data is pretty good, but there are some gaps. Some people have
cleaned up the raw data, to make clean tiles available. One such data source is
here: http://www.viewfinderpanoramas.org/dem3/.

So we have 2D track data and topography. We can thus combine these into a full
3D track. This isn't perfect since DEM data is granular, but it's way better
than nothing.

I just found out that there's a route to [[http://www.openstreetmap.org/#map=15/34.1662/-117.9293][Fish Canyon Falls]] that goes around the
rock quarry, and thus is open year-round. Bypassing the quarry requires climbing
up a steep hillside to gain a ridge, then descending the other side of the ridge
to the bottom of the canyon behind the quarry. Just how much extra climbing is
involved here? To find out, I wrote this:

#+CAPTION: =gpxSampleDEM.pl=
#+begin_src perl
#!/usr/bin/perl
use strict;
use warnings;

use Getopt::Euclid;
use feature ':5.10';
use autodie;

use Geo::Gpx;
use PDL;


my $W = 1201; # I use 3-minute DEMs, so each DEM is 1201 x 1201

my $gpx_fh;
if( $ARGV{'<input>'} eq '-' )
{
    $gpx_fh = \*STDIN;
}
else
{
  open $gpx_fh, '<', $ARGV{'<input>'};
}

my $gpx = Geo::Gpx->new( input => $gpx_fh );

my $iter = $gpx->iterate_points();
while( my $pt = $iter->() )
{
    say join( ' ', $pt->{lon}, $pt->{lat}, elevation( $pt->{lon}, $pt->{lat} ) );
}



sub elevation
{
    my ($lon, $lat) = @_;

    state %DEMs;
    my $demfileE = floor $lon;
    my $demfileN = floor $lat;

    $DEMs{$demfileE}{$demfileN} //= readDEM($demfileE, $demfileN);
    my $dem = $DEMs{$demfileE}{$demfileN};
    return 0 if( !ref($dem) );

    # use PDL::Graphics::Gnuplot;
    # gplot( with => 'image', $dem );
    # sleep(20);

    # the DEMs start in the NW corner
    my $ilon =      ($lon - $demfileE)  * $W;
    my $ilat = (1 - ($lat - $demfileN)) * $W;

    return 100.0/2.54/12.0 * $dem->interpND( pdl[$ilon, $ilat] );
}

sub readDEM
{
    my ($demfileE, $demfileN) = @_;

    my $path;
    if   ($demfileN >= 0 && $demfileE >= 0){ $path = sprintf("$ARGV{'--demdir'}/N%.2dE%.3d.hgt", $demfileN,  $demfileE); }
    elsif($demfileN >= 0 && $demfileE <  0){ $path = sprintf("$ARGV{'--demdir'}/N%.2dW%.3d.hgt", $demfileN, -$demfileE); }
    elsif($demfileN  < 0 && $demfileE >= 0){ $path = sprintf("$ARGV{'--demdir'}/S%.2dE%.3d.hgt", -$demfileN, $demfileE); }
    else                                   { $path = sprintf("$ARGV{'--demdir'}/S%.2dW%.3d.hgt", -$demfileN, -$demfileE); }

    say STDERR "Reading DEM '$path'";
    if( ! -e $path )
    {
        warn "DEM '$path' not found. All of its elevations will read as 0";
        return 0;
    }

    # I read the DEM on disk into the piddle, then flip the endianness of the
    # data. I wouldn't have to copy anything if the data was little-endian to
    # start with; I'd just mmap into the piddle.
    open my $fd, '<', $path;
    my $dem = zeros(short, $W, $W);
    sysread( $fd, ${$dem->get_dataref}, $W*$W*2, 0 );
    ${$dem->get_dataref} = pack( "s*", unpack("s>*", ${$dem->get_dataref}));

    # I also convert to floating point. Turns out the PDL interpolation routines
    # don't work with integers
    return $dem->float;
}



__END__

=head1 NAME

gpxSampleDEM.pl - Samples SRTM DEM data to compute elevations for a GPX track

=head1 OPTIONAL ARGUMENTS

=over

=item --demdir <demdir>

Directory that contains the DEM files

=for Euclid:
  demdir.type: string, -d demdir && -e demdir
  demdir.default: '.'

=item <input>

GPX input. If omitted or '-', the input is read from standard input

=for Euclid:
  input.type: readable
  input.default: '-'

=back

=head1 AUTHOR

Dima Kogan, C<< <dima@secretsauce.net> >>
#+end_src

The script is fairly straightforward. It examines every track point in the GPX,
finds the appropriate elevation using plain bilinear interpolation, and outputs
a (lon,lat,ele) tuple on STDOUT. On Debian the dependencies are

- =libgetopt-euclid-perl=
- =libgeo-gpx-perl=
- =pdl=

You need to pre-download 3" DEMs, and pass the directory to the script (1" would
certainly work better, but I haven't tried). Given the [[file:files/FishCanyonFalls/FishCanyonFallsTrail.gpx][gpx file]] scraped from an
OpenStreetMap way (itself traced from the satellite imagery), you can do this:

#+begin_src sh
gpxSampleDEM.pl --demdir DEMs FishCanyonFallsTrail.gpx | \
  feedgnuplot --domain --3d --lines --square_xy          \
     --xlabel 'lon(deg)' --ylabel 'lat(deg)' --zlabel 'Elevation(m)'
#+end_src

This makes an interactive 3D plot of the route. For a more traditional elevation
profile that's monotonic in distance, you can do something like this:

#+begin_src sh
gpxSampleDEM.pl --demdir DEMs FishCanyonFallsTrail.gpx | \
  awk '{print $3}'                                     | \
  feedgnuplot --lines                                    \
     --xlabel 'Monotonic with distance' --ylabel 'Elevation(m)'
#+end_src

I actually did go see this waterfall today (which is really nice). Here's a plot
of the elevation profile I gathered with my GPS unit today overlaid over the
elevation profile from the DEM:

#+begin_comment
Following plot made by exporting each data source, and plotting with gnuplot

gpx_xyz.pl ~/hiking/gpx/FishCanyonFalls.gpx | awk '!/#/ {print $3}' > real
gpxSampleDEM.pl --demdir ~/projects/horizon/DEMs_SRTM3.bak/ FishCanyonFallsTrail.gpx | awk '{print $3}' > fake

set xlabel "Monotonic with distance"
set ylabel "Elevation (m)"
set terminal svg
set output "FishCanyonFalls.svg"
plot "real" using ($0/1101):1 with lines title "Actual track from a hike", "fake" using ($0/1400):1 with lines title "Generated from a DEM"
set output
#+end_comment

#+ATTR_HTML: :width 80%
[[file:files/FishCanyonFalls/FishCanyonFalls.svg]]

Immediately several issues are noticeable[fn:1]. First of all, while each curve
is monotonic with distance, the relationship of the domain with distance is
different. This plot assumes they're both /linear/ with distance. It's not
really true, but close enough I suppose.

Second, we see that the DEM curve has some high-frequency oscillations. Those
are switchbacks that sample the DEM in a way that the DEM data is too coarse to
represent. The trail does not really oscillate like that, which is confirmed by
the GPS track. This effect would probably be mitigated with finer DEM data (1"
DEMs are available), but I haven't attempted this.

Third, we see that during the initial climb the DEM-derived elevation
consistently underreports the elevation. I suspect this is another artifact of
the coarseness of the DEM. If we're walking on a ridge, a bilinear interpolation
would take into account neighboring DEM pixels, which would be lower in
elevation (since it's a ridge). So on a ridge I would expect the DEM-derived
elevations to be under-reported, and in a canyon I'd expect them to be
over-reported. In this particular track, the initial climb and the initial
descent are on ridges, while the second climb is in a canyon. This brings us to
the next point.

The data in the second climb doesn't match /at all/. Here it's the GPS data
that's at fault. The canyon walls block the GPS signal, so GPS readings are
unreliable there.

So the grand conclusion of all this would appear to be that you can use 3" DEM
data to derive an elevation profile, but one should not expect this profile to
be terribly accurate. Still it's useful. Based purely on the DEM, I can see that
a round-trip on this route would entail 2800ft of net elevation gain. Seeing the
real track, this probably is an underestimate of ~200ft. Not bad.


[fn:1] The above analysis assumes that the implementation of the DEM sampler is
bug-free and that the DEM data is correct. While I don't know of any bugs, there
could be some. Same for the DEM data

** DONE X11 urgency hint and notifications                    :tools:desktop:
   CLOSED: [2014-03-19 Wed 00:20]

#+begin_o_blog_alert info Follow-up posts
[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Already-running process notifications")){/lisp}][Already-running process notifications]]

[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Even better notifications")){/lisp}][Even better notifications]]
#+end_o_blog_alert

X11 has a common system for window notifications: the urgency hint. The relevant
section of the [[http://tronche.com/gui/x/icccm/sec-4.html#s-4.1.2.4][ICCCM standard]]:

#+begin_quote
The UrgencyHint flag, if set in the flags field, indicates that the client deems
the window contents to be urgent, requiring the timely response of the user. The
window manager must make some effort to draw the user's attention to this window
while this flag is set.
#+end_quote

Some window managers are uncompliant and don't support this. Possibly as a
result, people really like to reinvent this particular wheel: [[http://www.linuxjournal.com/content/tech-tip-get-notifications-your-scripts-notify-send][notify-send]],
[[http://mattn.github.io/growl-for-linux/][growl]], and more. My WM ([[http://notion.sourceforge.net/][notion]]) /does/ support this very well, with some really
nice UI integration. Thus applications can request to be drawn as urgent. This
really begs for a commandline tool so shells can request the user's attention at
key points. For instance I really want to say something like

#+begin_src sh
make; seturgent
#+end_src

I.e. this would launch a source build, and when the build completes, this
particular terminal emulator window would request the user's attention. The
build could take a long, time, and the user may want to do stuff with the build
products, but in the meantime they can go do something else.

This =seturgent= tool didn't exist, so I wrote one:

#+CAPTION: =seturgent=
#+begin_src perl
#!/usr/bin/perl

# Copyright 2012,2013 Dima Kogan
# License: GPL 3 or later

use strict;
use warnings;
use feature qw(say);

use X11::Protocol;
use X11::Protocol::WM;
use X11::WindowHierarchy;

# if no arguments are given, sets urgency on the current window
#
# if an argument is given, uses it as a regex on the window name (all matches
# are set as urgent)

my $usage = "$0 [regex on the window name]";
die $usage if @ARGV > 1;


my $x = X11::Protocol->new()
  or die "Couldn't open display";

my @ids;
if( ! @ARGV )
{
  @ids = ($ENV{WINDOWID});
}
else
{
  my @windows = x11_filter_hierarchy( filter => qr{$ARGV[0]} )
    or die "No matching windows found";

  say "Found " . scalar(@windows) . " matching windows";
  @ids = map {$_->{id}} @windows;
}

foreach my $id(@ids)
{
  die "No window id" unless $id;
  X11::Protocol::WM::change_wm_hints( $x, $id,
                                      urgency => 1 );
}
#+end_src

This uses [[https://metacpan.org/pod/X11::WindowHierarchy][X11::WindowHierarchy]] to find the window, and [[https://metacpan.org/pod/X11::Protocol::WM][X11::Protocol::WM]] to set
the urgency hint. Both are available in Debian. Usage is very straightforward:
with no arguments, the current window is set urgent. Otherwise, the one and only
argument is treated like a regex on the window title. If a single match is
found, that window is set urgent.

Now I /can/ say

#+begin_src sh
make; seturgent
#+end_src
** DONE Already-running process notifications                 :tools:desktop:
   CLOSED: [2014-03-20 Thu 22:35]

#+begin_o_blog_alert info Follow-up posts
[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Even better notifications")){/lisp}][Even better notifications]]
#+end_o_blog_alert

The tool described in the last post ([[file:{lisp}(ob:link-to-post (ob:get-post-by-title "X11 urgency hint and notifications")){/lisp}][X11 urgency hint and notifications]]) works
well, but there's a common use case it does not support: completion notification
of already-running process. That post describes how to be notified when a build
completes:

#+begin_src sh
make; seturgent
#+end_src

But what if we already started the build? Another helper tool is required. Here
it is:

#+BEGIN_SRC sh

# As is, this can't be an external utility since it uses the shell builtin
# 'wait', which only works on direct children of this shell. An external utility
# creates another shell, so this doesn't work
function waitfor()
{
    # waits for a process to exit, and sets urgency when that happens. Expects a
    # single pgrep-able argument on the commandline. If no argument is given,
    # it'll look for the only child process.

    # if this process is a child of this shell, I use a blocking wait.
    # Otherwise, I poll.

    PID_ALL=$(pgrep -s0 -f $1)

    # filter out the current process (the shell) and 'xclip'. I have xclip
    # zombies apparently
    PID=$(comm -23 <(echo $PID_ALL | sort) <(echo $$ `pidof xclip` | xargs -n1 | sort))
    N=$(echo $PID | wc -w)

    if [[ $N -eq 1 ]]; then
        echo "Found unique process with pid $PID"
        kill -CONT $PID # resume this process, since it's almost certainly
                        # paused right now
        wait $PID;
        seturgent
    elif [[ $N -ne 0 ]]; then
        echo "Found more than one matching process. Doing nothing";
    elif [[ -z $1 ]]; then
        echo "No children of the current shell to wait on. Doing nothing";
    else
        echo "Found no matching processes in this shell. Looking globally.";
        PID=$(pgrep -f $1)
        N=$(echo $PID | wc -w)
        if [[ $N -eq 0 ]]; then
            echo "Found no matching global process either. Giving up.";
        elif [[ $N -ne 1 ]]; then
            echo "Found more than one global process. Giving up";
        else
            echo "Found unique process with pid $PID"
            while (ps -p $PID > /dev/null) { sleep 10; }
            seturgent;
        fi
    fi
}

#+END_SRC

This is a =zsh= shell script that lives in my =.zshrc=.

- with no argument, it acts on the only child of this shell
- with an argument, it uses =pgrep= to find a matching process, first in the
  local shell, then outside of the local shell

Once the target process is identified, the script waits for the process to exit,
then it sets the urgency hint on the terminal emulator window. If there's any
ambiguity about which process is being targeted, nothing is done.

The most common use case: if a long-running process is currently active, one
would temporarily suspend it with =C-z=, then issue a =waitfor=. This
re-activates the process, and sets the urgency when finished. One could also
re-implement the use case from the previous post as

#+begin_src sh
make & waitfor
#+end_src


As said previously, this is a =zsh= script. It probably needs to be tweaked a
little bit to work in =bash=, but I have not done this.

The reason this is a shell script, is that the wait-for-this-process-to-finish
operation on Linux only works from the parent of the process being waited on. As
implemented, =waitfor()= doesn't spawn a new process, and runs in the shell
process itself, which is the parent of the thing being waited on. If this was
anything other than a shell script, then the waiter would /also/ be a child of
the shell, so the process being waited on, and the process doing the waiting
would be /siblings/. The script works that case too, but it polls every 10
seconds, instead of being notified of completion.

I've been using this for a little bit. It's not perfect, and there're some warts
I'd like to fix. Still, it does the job, and it's already something I use every
day.

** DONE Cscope benchmarks                              :tools:dev:data:emacs:
   CLOSED: [2014-03-25 Tue 03:36]

#+begin_o_blog_alert info Follow-up posts
[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "GNU Global benchmarks")){/lisp}][GNU Global benchmarks]]

[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "More Cscope benchmarks")){/lisp}][More Cscope benchmarks]]
#+end_o_blog_alert

I read and write lots of C code, and I find the [[http://cscope.sourceforge.net/][cscope]] tool to be invaluable in
searching and navigating code bases. Recently I took over maintership of the
[[https://github.com/dkogan/xcscope.el][xcscope.el]] Emacs interface to cscope. There are a surprising number of different
Emacs interfaces to cscope, and this one seems to be the most mature and
full-featured (and I made it much nicer).

One feature that some other interfaces have ([[http://lists.gnu.org/archive/html/gnu-emacs-sources/2008-04/msg00021.html][ascope]] for instance) is that
instead of running a new cscope process for each query, they leave the process
running, and reuse it for each query. This keeps the database in memory, and
doesn't waste cycles reloading it every time. This is the major feature of these
interfaces, and glorious performance benefits are claimed.

Currently =xcscope= does /not/ do this, and I sometimes consider implementing
this feature. It's going to be a pain to do, so I decided to run some tests to
see if the performance benefits really are worth it.

*** Benchmark machine

All tests were run on my relatively quick server. It has a quad-core Ivy bridge
Core-i5 CPU, 4GB of RAM and a non-SSD hard disk.

*** Test description

The code base under test is the linux kernel. This should be near the upper
bound of what most people would be indexing. Sure, larger projects exist, but
you're generally working on a contained piece, rather than the whole thing at
once (this is true of the kernel too, actually).

I perform multiple discrete cscope operations using the command-line tool. Each
operation starts a new =cscope= process, which reloads the database. I.e. I
perform the operation that's supposedly slow every time.

I measure how long it takes to build the search database, then to re-build it,
then to re-build it after =touch=-ing a file. Then I measure how long it takes
to run a search, then to re-run it, then to re-run it after =touch=-ing a file.

I do all this with the default settings, then again with settings more
appropriate for a kernel:

- /kernel mode/: =-k= option. Doesn't look in =/usr/include=
- /inverted-index mode/: =-q= option. Builds an extra index for faster searches

Each search is also run with the =-d= option. This only runs the search; it does
/not/ also update the database with each search. By default, cscope /does/
update the database with every search.

Specifically, I get the list of files with 

#+begin_src sh
cscope-indexer -l -r  
#+end_src

I build an index with

#+begin_src sh
cscope -b
#+end_src

If I'm indexing in kernel mode and I'm building an inverted index, I also pass
in =-q -k=. The test search looks for all uses of the =main= symbol:

#+begin_src sh
cscope -L0 main
#+end_src

Once again, if I'm indexing in kernel mode and I'm building an inverted index, I
also pass in =-q -k=. When I want to touch an arbitrary file, I do

#+begin_src sh
touch include/drm/drm_edid.h 
#+end_src

There's no significance to this file. It's just anything that's in the index.

As one can imagine, the disk cache plays a very significant role here, and
subsequent runs of the same command complete faster than the first. For this
reason all tests are run with both a cold cache (by dumping the disk cache prior
to the test) and a warm cache (/not/ dumping the cache, and pre-running the
operation a few times before timing). I also ran these tests on an actual hard
disk, and also on a tmpfs ramdisk.

All timings were performed multiple times, with the initial few values and the
outliers thrown out. The exact script used to collect the data is described and
available in the [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "GNU Global benchmarks")){/lisp}][next post]].

*** Results

All timings in seconds.

**** Cold disk cache

|                                              | Normal mode/ext3 | Kernel mode/ext3 | Normal mode/tmpfs | Kernel mode/tmpfs |
|----------------------------------------------+------------------+------------------+-------------------+-------------------|
| Initial database build                       |             45.9 |             80.2 |              14.0 |              44.2 |
| Database re-build after touching a file      |             10.4 |             48.9 |               3.2 |              30.1 |
| Initial search                               |              7.5 |              3.0 |               0.8 |              31.2 |
| Re-search after touching a file              |             12.7 |             43.7 |               3.5 |              32.1 |
| Initial no-db-update search                  |              5.3 |              0.8 |               0.8 |               0.8 |
| No-db-update re-search after touching a file |              5.1 |              0.8 |               0.7 |               0.8 |

**** Warm disk cache

|                                              | Normal mode/ext3 | Kernel mode/ext3 | Normal mode/tmpfs | Kernel mode/tmpfs |
|----------------------------------------------+------------------+------------------+-------------------+-------------------|
| Initial database build                       |             13.8 |             49.6 |              12.9 |              44.4 |
| Database re-build after touching a file      |              3.5 |             35.5 |               2.7 |              30.8 |
| Initial search                               |              0.8 |              0.1 |               0.8 |              30.8 |
| Re-search after touching a file              |              4.0 |             33.5 |               3.5 |              31.9 |
| Initial no-db-update search                  |              0.7 |              0.0 |               0.7 |               0.7 |
| No-db-update re-search after touching a file |              0.7 |              0.0 |               0.7 |               0.7 |

*** Conclusions

I've known about the cscope inverted index for a while, but never actually tried
to use it. Looks like it works as advertised: takes significantly longer to
build, but once built the speedup it provides is substantial. It would appear
that the main benefit of the inverted index is that less data needs to be read
from disk and /not/ that less searching is required. At least on this particular
test machine the inverted index has no upside if the data is all in RAM already
(tmpfs). On a slower box maybe we'd see the search times become significant, but
not here.

It's extremely clear that the overhead of just loading the database is
immaterial. It's effectively instant to load the database and then to run a
search in an inverted index with a warm cache. It's a bit slower without an
inverted index, but all the time there is spent searching, not loading the index
into memory. I know this because I get the same no-inverted-index search timings
with the cscope interactive tool, which loads the database just once. The only
way keeping the =cscope= process running is advantageous is if this makes it
more likely the caches stay warm. This is difficult to test, but I doubt it's
true. If I run repeated queries even with a new process every time, the data
stays cached, and things run quickly. What I think is much more likely is that
the people who wrote cscope interfaces such as =ascope= only used interfaces
such as =xcscope= without the =-d= option. I.e. they were updating the database
with every query, which clearly can be slow with a large codebase. Then they
were /not/ doing this with their persistent =cscope= sessions, and attributing
the performance gains to not loading the database rather than rebuilding the
index too often. In any case, I think it's pretty clear that this feature is not
worth the work, so I'm keeping =xcscope= as is.

** DONE GNU Global benchmarks                                :tools:data:dev:
   CLOSED: [2014-03-30 Sun 00:42]

#+begin_o_blog_alert info Follow-up posts
[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "More Cscope benchmarks")){/lisp}][More Cscope benchmarks]]
#+end_o_blog_alert

The [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Cscope benchmarks")){/lisp}][last post]] reports some performance numbers for [[http://cscope.sourceforge.net][cscope]]. There's another,
similar tool that I've been curious about: [[http://www.gnu.org/s/global/global.html][GNU global]]. It's like cscope in many
ways. It doesn't have some of the nicer cscope search types (caller, callee,
assignment, etc), and cscope works fine so I've never felt the need to move.
Since I just ran some cscope benchmarks, I thought it'd be interesting to run
the exact same tests with GNU global. Here I use the =gtags-cscope= frontend.
This is a compatibility layer in GNU global that has an identical interface to
cscope (among other things this makes it trivial to use =xcscope.el= with GNU
global).

*** Test description

The test conditions are the same as before. The testing in this /and/ the
previous post was performed by a script, which appears at the end of this post.
=gtags-cscope= doesn't have a separate inverted-index mode, so just a single
test appears here.

Here I'm using GNU global 6.2.10 built from source (upstream is in some sort of
fight with the Debian maintainer, so the packages are ancient). Cscope is 15.8a.

*** Results

All timings in seconds. Timings from the previous post are re-iterated for easy
comparison.

**** Cold disk cache

|                                              | Normal mode/ext3 | Kernel mode/ext3 | GNU Global/ext3 | Normal mode/tmpfs | Kernel mode/tmpfs | GNU Global/tmpfs |
|----------------------------------------------+------------------+------------------+-----------------+-------------------+-------------------+------------------|
| Initial database build                       |             45.9 |             80.2 |            84.1 |              14.0 |              44.2 |             14.0 |
| Database re-build after touching a file      |             10.4 |             48.9 |            26.8 |               3.2 |              30.1 |              0.7 |
| Initial search                               |              7.5 |              3.0 |            23.3 |               0.8 |              31.2 |              0.2 |
| Re-search after touching a file              |             12.7 |             43.7 |            28.4 |               3.5 |              32.1 |              0.7 |
| Initial no-db-update search                  |              5.3 |              0.8 |             0.1 |               0.8 |               0.8 |              0.0 |
| No-db-update re-search after touching a file |              5.1 |              0.8 |             0.1 |               0.7 |               0.8 |              0.0 |

**** Warm disk cache

|                                              | Normal mode/ext3 | Kernel mode/ext3 | GNU Global/ext3 | Normal mode/tmpfs | Kernel mode/tmpfs | GNU Global/tmpfs |
|----------------------------------------------+------------------+------------------+-----------------+-------------------+-------------------+------------------|
| Initial database build                       |             13.8 |             49.6 |            18.0 |              12.9 |              44.4 |             13.7 |
| Database re-build after touching a file      |              3.5 |             35.5 |             1.3 |               2.7 |              30.8 |              0.6 |
| Initial search                               |              0.8 |              0.1 |             0.4 |               0.8 |              30.8 |              0.2 |
| Re-search after touching a file              |              4.0 |             33.5 |             1.3 |               3.5 |              31.9 |              0.6 |
| Initial no-db-update search                  |              0.7 |              0.0 |             0.0 |               0.7 |               0.7 |              0.0 |
| No-db-update re-search after touching a file |              0.7 |              0.0 |             0.0 |               0.7 |               0.7 |              0.0 |

*** Conclusions

During *normal* use, we'd have a warm cache and we'd be using a real hard disk.
This is the bottom-left area of the timing tables. Those timings indicate that
GNU Global is much faster than cscope. Search performance appears to be on-par
with with an inverted-index-enabled cscope, but database build times only suffer
a little bit. This is interesting, and maybe would be worth switching to at some
point.

*** Benchmark script

All the timings were performed with the following =zsh= script. It uses some
=zsh=-isms, but could be converted to =bash= if somebody cares to do it.

#+begin_src sh
#!/bin/zsh

# needed in cleandb()
setopt nonomatch

function dropcaches() {
    if [[ $warmcold == "cold" ]]; then
        sync ;
        sudo sysctl -w vm.drop_caches=3;
    fi
    sleep 2;
}

function cleandb() {
    # requires nonomatch option to ignore missing globs
    rm -f cscope.out* G*;
}

function touchfile() {
    sleep 2; # very important. cscope needs this to see the file update
    touch include/drm/drm_edid.h;
}

TIMEFMT='%E'

awktally='
BEGIN {
  skip = ENVIRON["skip"]
}

/^[0-9\.]+s$/ {
  gsub("s","");
  str = str " " $1
  if( n >= skip )
  {
    sum += $1;
  }
  n++;
}

END {
  print ENVIRON["name"] ": skipping: " skip " all: " str " mean: " sum/(n-skip)
}'

typeset -A skipcounts
skipcounts=(cold 2 warm 2)

typeset -A modeoptions
modeoptions=(normal "" kernel "-k -q")

cscope-indexer -l -r

Nrepeat=8

for mode (normal kernel global)
{
    if [[ $mode == "global" ]]; then
        cmd="gtags-cscope";
    else
        cmd="cscope $modeoptions[$mode]";
    fi

    for dotouch (0 1)
    {
        for warmcold (cold warm)
        {
            export name="$warmcold initial build; $mode mode; touching: $dotouch";
            export skip=$skipcounts[$warmcold];
            repeat $(($Nrepeat + $skip)) {
                if (($dotouch)); then
                    touchfile;
                else
                    cleandb;
                fi
                dropcaches;
                time ${(z)cmd} -b;
            } |& awk $awktally
        }
    }

    for dotouch (0 1)
    {
        for warmcold (cold warm)
        {
            export name="$warmcold initial search; $mode mode; touching: $dotouch";
            export skip=$skipcounts[$warmcold];
            repeat $(($Nrepeat + $skip)) {
                if (($dotouch)); then
                    touchfile;
                fi
                dropcaches;
                time ${(z)cmd} -L0 main > /dev/null;
            } |& awk $awktally
        }
    }

    for dotouch (0 1)
    {
        for warmcold (cold warm)
        {
            export name="$warmcold initial no-db search; $mode mode; touching: $dotouch";
            export skip=$skipcounts[$warmcold];
            repeat $(($Nrepeat + $skip)) {
                if (($dotouch)); then
                    touchfile;
                fi
                dropcaches;
                time ${(z)cmd} -d -L0 main > /dev/null;
            } |& awk $awktally
        }
    }
}
#+end_src

*** benchmark data                                                 :noexport:
**** ext3
cold initial build; normal mode; touching: 0: skipping: 2 all:  45.91 44.30 45.80 45.82 45.18 45.99 44.65 49.29 45.90 44.61 mean: 45.905
warm initial build; normal mode; touching: 0: skipping: 2 all:  14.27 13.67 14.25 14.24 14.27 13.24 13.23 13.56 14.71 13.21 mean: 13.8388
cold initial build; normal mode; touching: 1: skipping: 2 all:  9.87 9.78 10.00 9.85 9.99 13.60 9.97 9.91 10.04 10.01 mean: 10.4213
warm initial build; normal mode; touching: 1: skipping: 2 all:  3.41 3.42 3.83 3.19 3.47 3.75 3.35 3.19 3.43 3.65 mean: 3.4825
cold initial search; normal mode; touching: 0: skipping: 2 all:  7.12 7.09 7.12 7.20 7.15 7.20 7.08 10.33 7.14 7.12 mean: 7.5425
warm initial search; normal mode; touching: 0: skipping: 2 all:  0.83 0.82 0.82 0.82 0.83 0.83 0.82 0.82 0.82 0.82 mean: 0.8225
cold initial search; normal mode; touching: 1: skipping: 2 all:  11.97 11.81 11.79 12.29 14.96 13.74 12.29 12.13 12.11 12.08 mean: 12.6737
warm initial search; normal mode; touching: 1: skipping: 2 all:  3.99 4.01 3.90 4.01 3.99 3.91 4.10 4.05 3.84 3.96 mean: 3.97
cold initial no-db search; normal mode; touching: 0: skipping: 2 all:  6.06 4.06 6.15 4.16 8.56 4.07 5.71 4.05 5.79 4.07 mean: 5.32
warm initial no-db search; normal mode; touching: 0: skipping: 2 all:  0.75 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 mean: 0.74
cold initial no-db search; normal mode; touching: 1: skipping: 2 all:  5.74 4.07 5.80 4.05 5.80 4.05 6.96 4.07 5.80 4.05 mean: 5.0725
warm initial no-db search; normal mode; touching: 1: skipping: 2 all:  0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.75 0.74 mean: 0.74125
cold initial build; kernel mode; touching: 0: skipping: 2 all:  79.45 79.86 79.10 85.14 79.02 79.01 78.37 83.88 78.54 78.48 mean: 80.1925
warm initial build; kernel mode; touching: 0: skipping: 2 all:  67.54 54.28 51.28 48.01 48.80 50.04 49.71 50.04 49.12 49.78 mean: 49.5975
cold initial build; kernel mode; touching: 1: skipping: 2 all:  49.06 48.46 49.80 52.14 46.29 46.43 51.68 47.65 49.56 47.30 mean: 48.8563
warm initial build; kernel mode; touching: 1: skipping: 2 all:  47.38 37.87 36.10 38.85 35.39 34.04 33.23 37.30 33.47 35.28 mean: 35.4575
cold initial search; kernel mode; touching: 0: skipping: 2 all:  2.69 2.74 2.82 4.07 2.78 2.87 2.84 2.86 2.82 2.82 mean: 2.985
warm initial search; kernel mode; touching: 0: skipping: 2 all:  0.11 0.09 0.09 0.09 0.09 0.09 0.09 0.09 0.09 0.09 mean: 0.09
cold initial search; kernel mode; touching: 1: skipping: 2 all:  49.42 47.28 45.30 42.83 43.94 41.10 42.96 47.20 43.05 43.23 mean: 43.7013
warm initial search; kernel mode; touching: 1: skipping: 2 all:  36.59 33.33 33.77 32.52 34.47 32.23 32.93 33.60 34.35 33.92 mean: 33.4738
cold initial no-db search; kernel mode; touching: 0: skipping: 2 all:  1.15 0.56 0.94 0.62 0.92 0.61 1.05 0.61 0.93 0.59 mean: 0.78375
warm initial no-db search; kernel mode; touching: 0: skipping: 2 all:  0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 mean: 0
cold initial no-db search; kernel mode; touching: 1: skipping: 2 all:  0.90 1.28 0.91 0.59 0.94 0.59 0.87 0.61 0.94 0.61 mean: 0.7575
warm initial no-db search; kernel mode; touching: 1: skipping: 2 all:  0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 mean: 0
cold initial build; global mode; touching: 0: skipping: 2 all:  86.15 83.39 84.38 86.24 85.76 81.48 82.46 85.79 84.17 82.54 mean: 84.1025
warm initial build; global mode; touching: 0: skipping: 2 all:  17.76 18.55 17.78 17.69 18.22 18.95 17.53 17.69 18.08 17.71 mean: 17.9563
cold initial build; global mode; touching: 1: skipping: 2 all:  26.69 30.73 27.52 25.89 26.93 25.70 25.73 25.89 29.63 27.17 mean: 26.8075
warm initial build; global mode; touching: 1: skipping: 2 all:  1.32 1.31 1.31 1.31 1.38 1.36 1.32 1.31 1.30 1.27 mean: 1.32
cold initial search; global mode; touching: 0: skipping: 2 all:  23.03 26.28 24.50 22.10 23.01 22.02 22.10 23.34 22.46 26.58 mean: 23.2638
warm initial search; global mode; touching: 0: skipping: 2 all:  0.38 0.37 0.36 0.37 0.37 0.36 0.36 0.36 0.36 0.36 mean: 0.3625
cold initial search; global mode; touching: 1: skipping: 2 all:  27.16 26.11 27.19 30.34 27.49 28.63 28.26 27.84 29.41 27.84 mean: 28.375
warm initial search; global mode; touching: 1: skipping: 2 all:  1.35 1.30 1.28 1.31 1.31 1.29 1.31 1.30 1.31 1.33 mean: 1.305
cold initial no-db search; global mode; touching: 0: skipping: 2 all:  1.39 0.82 1.07 0.63 0.21 0.07 0.05 0.04 0.06 0.05 mean: 0.2725
warm initial no-db search; global mode; touching: 0: skipping: 2 all:  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 mean: 0.01
cold initial no-db search; global mode; touching: 1: skipping: 2 all:  0.05 0.04 0.03 0.05 0.04 0.04 1.90 0.41 0.22 0.03 mean: 0.34
warm initial no-db search; global mode; touching: 1: skipping: 2 all:  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 mean: 0.01

**** tmpfs
cold initial build; normal mode; touching: 0: skipping: 2 all:  14.07 14.11 14.15 13.99 13.94 14.01 14.20 14.01 14.02 14.06 mean: 14.0475
warm initial build; normal mode; touching: 0: skipping: 2 all:  12.99 12.97 12.82 12.98 12.89 13.02 12.87 12.93 13.00 12.92 mean: 12.9287
cold initial build; normal mode; touching: 1: skipping: 2 all:  3.19 3.21 3.16 3.17 3.17 3.20 3.17 3.19 3.16 3.20 mean: 3.1775
warm initial build; normal mode; touching: 1: skipping: 2 all:  2.72 2.73 2.72 2.72 2.72 2.73 2.72 2.72 2.72 2.72 mean: 2.72125
cold initial search; normal mode; touching: 0: skipping: 2 all:  1.00 0.85 0.86 0.83 0.84 0.84 0.84 0.84 0.84 0.84 mean: 0.84125
warm initial search; normal mode; touching: 0: skipping: 2 all:  0.85 0.82 0.82 0.83 0.82 0.82 0.82 0.82 0.82 0.82 mean: 0.82125
cold initial search; normal mode; touching: 1: skipping: 2 all:  3.86 3.66 3.53 3.51 3.50 3.54 3.50 3.50 3.51 3.54 mean: 3.51625
warm initial search; normal mode; touching: 1: skipping: 2 all:  3.47 3.46 3.45 3.45 3.46 3.46 3.46 3.45 3.45 3.45 mean: 3.45375
cold initial no-db search; normal mode; touching: 0: skipping: 2 all:  0.77 0.74 0.75 0.75 0.75 0.75 0.75 0.75 0.80 0.74 mean: 0.755
warm initial no-db search; normal mode; touching: 0: skipping: 2 all:  0.75 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 mean: 0.74
cold initial no-db search; normal mode; touching: 1: skipping: 2 all:  0.75 0.74 0.74 0.74 0.74 0.74 0.75 0.75 0.76 0.76 mean: 0.7475
warm initial no-db search; normal mode; touching: 1: skipping: 2 all:  0.76 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 mean: 0.74
cold initial build; kernel mode; touching: 0: skipping: 2 all:  41.84 44.43 45.34 44.74 43.31 43.62 43.44 44.84 43.48 44.99 mean: 44.22
warm initial build; kernel mode; touching: 0: skipping: 2 all:  44.53 43.35 45.38 42.49 44.83 43.90 44.55 43.17 46.30 44.33 mean: 44.3687
cold initial build; kernel mode; touching: 1: skipping: 2 all:  30.15 29.48 29.68 29.75 30.45 29.80 30.18 30.34 30.11 30.74 mean: 30.1313
warm initial build; kernel mode; touching: 1: skipping: 2 all:  29.93 30.82 30.61 29.85 30.34 29.70 31.60 32.37 30.68 31.20 mean: 30.7937
cold initial search; kernel mode; touching: 0: skipping: 2 all:  33.00 31.38 31.03 31.81 31.35 31.12 31.17 32.33 30.26 30.48 mean: 31.1937
warm initial search; kernel mode; touching: 0: skipping: 2 all:  31.13 30.00 29.20 31.73 30.28 29.70 31.97 29.27 33.26 30.98 mean: 30.7987
cold initial search; kernel mode; touching: 1: skipping: 2 all:  31.60 30.70 30.90 32.33 33.94 31.82 31.68 31.33 33.09 31.56 mean: 32.0812
warm initial search; kernel mode; touching: 1: skipping: 2 all:  30.97 31.27 31.32 31.26 32.95 32.07 31.94 31.14 33.00 31.56 mean: 31.905
cold initial no-db search; kernel mode; touching: 0: skipping: 2 all:  0.88 0.74 0.78 0.74 0.78 0.79 0.74 0.75 0.77 0.76 mean: 0.76375
warm initial no-db search; kernel mode; touching: 0: skipping: 2 all:  0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 mean: 0.74
cold initial no-db search; kernel mode; touching: 1: skipping: 2 all:  0.77 0.75 0.74 0.74 0.93 0.78 0.77 0.74 0.77 0.75 mean: 0.7775
warm initial no-db search; kernel mode; touching: 1: skipping: 2 all:  0.74 0.74 0.74 0.74 0.74 0.76 0.74 0.74 0.74 0.74 mean: 0.7425
cold initial build; global mode; touching: 0: skipping: 2 all:  14.25 13.88 14.12 14.73 13.99 13.60 13.74 14.55 13.79 13.67 mean: 14.0238
warm initial build; global mode; touching: 0: skipping: 2 all:  13.47 13.53 13.78 13.59 13.85 14.02 13.43 13.68 13.59 13.99 mean: 13.7412
cold initial build; global mode; touching: 1: skipping: 2 all:  0.96 0.64 0.64 0.61 0.62 0.60 0.63 0.96 0.89 0.65 mean: 0.7
warm initial build; global mode; touching: 1: skipping: 2 all:  0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 mean: 0.59
cold initial search; global mode; touching: 0: skipping: 2 all:  0.62 0.28 0.20 0.22 0.20 0.22 0.21 0.20 0.20 0.20 mean: 0.20625
warm initial search; global mode; touching: 0: skipping: 2 all:  0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19 mean: 0.19
cold initial search; global mode; touching: 1: skipping: 2 all:  0.61 0.60 0.60 0.60 0.60 0.60 0.61 0.63 0.96 0.69 mean: 0.66125
warm initial search; global mode; touching: 1: skipping: 2 all:  0.60 0.59 0.59 0.59 0.59 0.59 0.59 0.61 0.59 0.59 mean: 0.5925
cold initial no-db search; global mode; touching: 0: skipping: 2 all:  0.08 0.05 0.04 0.02 0.06 0.05 0.03 0.02 0.04 0.17 mean: 0.05375
warm initial no-db search; global mode; touching: 0: skipping: 2 all:  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 mean: 0.01
cold initial no-db search; global mode; touching: 1: skipping: 2 all:  0.09 0.07 0.05 0.02 0.02 0.02 0.02 0.04 0.06 0.04 mean: 0.03375
warm initial no-db search; global mode; touching: 1: skipping: 2 all:  0.02 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 mean: 0.01


**** Ext3-only data in a table, with formulas

ext3-only:
|                                              |       |       |       |       |       |       |       |       |       |       |     mean | stdev/mean |       |       |       |       |       |       |       |       |       |       |     mean |          stdev/mean |
|----------------------------------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+----------+------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+----------+---------------------|
| Initial database build                       | 45.91 | 44.30 | 45.80 | 45.82 | 45.18 | 45.99 | 44.65 | 49.29 | 45.90 | 44.61 |   45.905 |          3 | 14.27 | 13.67 | 14.25 | 14.24 | 14.27 | 13.24 | 13.23 | 13.56 | 14.71 | 13.21 | 13.83875 |                   4 |
| Database re-build after touching a file      |  9.87 |  9.78 | 10.00 |  9.85 |  9.99 | 13.60 |  9.97 |  9.91 | 10.04 | 10.01 | 10.42125 |         12 |  3.41 |  3.42 |  3.83 |  3.19 |  3.47 |  3.75 |  3.35 |  3.19 |  3.43 |  3.65 |   3.4825 |                   7 |
| Initial search                               |  7.12 |  7.09 |  7.12 |  7.20 |  7.15 |  7.20 |  7.08 | 10.33 |  7.14 |  7.12 |   7.5425 |         15 |  0.83 |  0.82 |  0.82 |  0.82 |  0.83 |  0.83 |  0.82 |  0.82 |  0.82 |  0.82 |   0.8225 |                   1 |
| Re-searchafter touching a file               | 11.97 | 11.81 | 11.79 | 12.29 | 14.96 | 13.74 | 12.29 | 12.13 | 12.11 | 12.08 | 12.67375 |          9 |  3.99 |  4.01 |  3.90 |  4.01 |  3.99 |  3.91 |  4.10 |  4.05 |  3.84 |  3.96 |     3.97 |                   2 |
| Initial no-db-update search                  |  6.06 |  4.06 |  6.15 |  4.16 |  8.56 |  4.07 |  5.71 |  4.05 |  5.79 |  4.07 |     5.32 |         30 |  0.75 |  0.74 |  0.74 |  0.74 |  0.74 |  0.74 |  0.74 |  0.74 |  0.74 |  0.74 |     0.74 |                   0 |
| No-db-update re-search after touching a file |  5.74 |  4.07 |  5.80 |  4.05 |  5.80 |  4.05 |  6.96 |  4.07 |  5.80 |  4.05 |   5.0725 |         23 |  0.74 |  0.74 |  0.74 |  0.74 |  0.74 |  0.74 |  0.74 |  0.74 |  0.75 |  0.74 |  0.74125 |                   0 |
| Initial database build                       | 79.45 | 79.86 | 79.10 | 85.14 | 79.02 | 79.01 | 78.37 | 83.88 | 78.54 | 78.48 |  80.1925 |          3 | 67.54 | 54.28 | 51.28 | 48.01 | 48.80 | 50.04 | 49.71 | 50.04 | 49.12 | 49.78 |  49.5975 |                   2 |
| Database re-build after touching a file      | 49.06 | 48.46 | 49.80 | 52.14 | 46.29 | 46.43 | 51.68 | 47.65 | 49.56 | 47.30 | 48.85625 |          5 | 47.38 | 37.87 | 36.10 | 38.85 | 35.39 | 34.04 | 33.23 | 37.30 | 33.47 | 35.28 |  35.4575 |                   5 |
| Initial search                               |  2.69 |  2.74 |  2.82 |  4.07 |  2.78 |  2.87 |  2.84 |  2.86 |  2.82 |  2.82 |    2.985 |         15 |  0.11 |  0.09 |  0.09 |  0.09 |  0.09 |  0.09 |  0.09 |  0.09 |  0.09 |  0.09 |     0.09 |                   0 |
| Re-searchafter touching a file               | 49.42 | 47.28 | 45.30 | 42.83 | 43.94 | 41.10 | 42.96 | 47.20 | 43.05 | 43.23 | 43.70125 |          4 | 36.59 | 33.33 | 33.77 | 32.52 | 34.47 | 32.23 | 32.93 | 33.60 | 34.35 | 33.92 | 33.47375 |                   2 |
| Initial no-db-update search                  |  1.15 |  0.56 |  0.94 |  0.62 |  0.92 |  0.61 |  1.05 |  0.61 |  0.93 |  0.59 |  0.78375 |         25 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |       0. | nint((0. / 0.) 100) |
| No-db-update re-search after touching a file |  0.90 |  1.28 |  0.91 |  0.59 |  0.94 |  0.59 |  0.87 |  0.61 |  0.94 |  0.61 |   0.7575 |         22 |  0.01 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |       0. | nint((0. / 0.) 100) |
| Initial database build                       | 86.15 | 83.39 | 84.38 | 86.24 | 85.76 | 81.48 | 82.46 | 85.79 | 84.17 | 82.54 |  84.1025 |          2 | 17.76 | 18.55 | 17.78 | 17.69 | 18.22 | 18.95 | 17.53 | 17.69 | 18.08 | 17.71 | 17.95625 |                   3 |
| Database re-build after touching a file      | 26.69 | 30.73 | 27.52 | 25.89 | 26.93 | 25.70 | 25.73 | 25.89 | 29.63 | 27.17 |  26.8075 |          5 |  1.32 |  1.31 |  1.31 |  1.31 |  1.38 |  1.36 |  1.32 |  1.31 |  1.30 |  1.27 |     1.32 |                   3 |
| Initial search                               | 23.03 | 26.28 | 24.50 | 22.10 | 23.01 | 22.02 | 22.10 | 23.34 | 22.46 | 26.58 | 23.26375 |          7 |  0.38 |  0.37 |  0.36 |  0.37 |  0.37 |  0.36 |  0.36 |  0.36 |  0.36 |  0.36 |   0.3625 |                   1 |
| Re-searchafter touching a file               | 27.16 | 26.11 | 27.19 | 30.34 | 27.49 | 28.63 | 28.26 | 27.84 | 29.41 | 27.84 |   28.375 |          4 |  1.35 |  1.30 |  1.28 |  1.31 |  1.31 |  1.29 |  1.31 |  1.30 |  1.31 |  1.33 |    1.305 |                   1 |
| Initial no-db-update search                  |  1.39 |  0.82 |  1.07 |  0.63 |  0.21 |  0.07 |  0.05 |  0.04 |  0.06 |  0.05 |   0.2725 |        139 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |     0.01 |                   0 |
| No-db-update re-search after touching a file |  0.05 |  0.04 |  0.03 |  0.05 |  0.04 |  0.04 |  1.90 |  0.41 |  0.22 |  0.03 |     0.34 |        190 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |     0.01 |                   0 |
#+TBLFM: $12=vmean($4..$11)::$13=round((vsdev($4..$11)/$12)*100)::$24=vmean($16..$23)::$25=round((vsdev($16..$23)/$24)*100)

**** Final table; mean-only, outliers removed

Data order same as before:
| Initial database build                       |
| Database re-build after touching a file      |
| Initial search                               |
| Re-searchafter touching a file               |
| Initial no-db-update search                  |
| No-db-update re-search after touching a file |


|        | Cold cache | Warm cache |
|--------+------------+------------|
| Normal |       45.9 |       13.8 |
| ext3   |       10.4 |        3.5 |
|        |        7.5 |        0.8 |
|        |       12.7 |        4.0 |
|        |        5.3 |        0.7 |
|        |        5.1 |        0.7 |
|--------+------------+------------|
| Kernel |       80.2 |       49.6 |
| ext3   |       48.9 |       35.5 |
|        |        3.0 |        0.1 |
|        |       43.7 |       33.5 |
|        |        0.8 |        0.0 |
|        |        0.8 |        0.0 |
|--------+------------+------------|
| Global |       84.1 |       18.0 |
| ext3   |       26.8 |        1.3 |
|        |       23.3 |        0.4 |
|        |       28.4 |        1.3 |
|        |        0.1 |        0.0 |
|        |        0.1 |        0.0 |
|--------+------------+------------|
| Normal |       14.0 |       12.9 |
| tmpfs  |        3.2 |        2.7 |
|        |        0.8 |        0.8 |
|        |        3.5 |        3.5 |
|        |        0.8 |        0.7 |
|        |        0.7 |        0.7 |
|--------+------------+------------|
| Kernel |       44.2 |       44.4 |
| tmpfs  |       30.1 |       30.8 |
|        |       31.2 |       30.8 |
|        |       32.1 |       31.9 |
|        |        0.8 |        0.7 |
|        |        0.8 |        0.7 |
|--------+------------+------------|
| Global |       14.0 |       13.7 |
| tmpfs  |        0.7 |        0.6 |
|        |        0.2 |        0.2 |
|        |        0.7 |        0.6 |
|        |        0.0 |        0.0 |
|        |        0.0 |        0.0 |

** DONE Running qemu with a custom kernel on ARM                  :tools:dev:
   CLOSED: [2014-04-07 Mon 23:38]

So I was porting [[http://www.sysdig.org][sysdig]] to ARM, and needed a target device to test the progress.
Sysdig uses syscall tracepoints, which were added to Linux relatively recently,
in version 3.7. Thus the ARM devices I had lying around were too old, and thus
weren't suitable to test on (I could forward port the kernel patches that make
them work, but this would be too much of a tangential effort).

The solution I settled on was emulation. Qemu can run in /system/ mode to
emulate a full machine. Specific instructions on how to run a vanilla-ish Debian
system with a custom kernel were hard to find, so I'm documenting them here.
Aurlien Jarno has disk images of a fresh Debian install and kernel images for
Qemu emulation here: http://people.debian.org/~aurel32/qemu/armel/. This is the
=armel= images, but he has the other arches as well.

Those images work fine. I just need to run a custom kernel I build myself.
Aurlien provides the kernel image /and/ an init ramdisk. It's not immediately
clear how to build this =initrd= image (and my various attempts weren't
fruitful). It was also not obvious how to run without =initrd=. The solution
that worked for me in the end was a monolithic kernel (all necessary drivers
compiled in) and a particular set of qemu options to workwithout a ramdisk.

I built a vanilla Linux 3.14 kernel =zImage=. The multiarch cross-toolchain
isn't in Debian proper yet, but packages are available from
http://people.debian.org/~wookey/tools/debian/.

The [[file:files/kernelstuff/versatile.config][kernel config]] was based off the vanilla =versatile_defconfig=, with a few
drivers and things built in. As usual, the kernel can be built with something
like this:

#+begin_src sh
cd linux
git reset --hard v3.14
cp /tmp/versatile.config .config
make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- -j4 zImage
#+end_src

This produces an image in =arch/arm/boot/zImage=. Everything I care about is
built-in, so I don't care about shipping modules, or building a ramdisk. A qemu
command to use this:

#+begin_src sh
qemu-system-arm -M versatilepb -kernel ~/linux/arch/arm/boot/zImage -hda debian_wheezy_armel_standard.qcow2 -append "noinitrd root=/dev/sda1 rw"
#+end_src

This appears to boot successfully, mounting everything, bringing up the network,
etc. There is a benign warning about not being able to talk to the modules from
the original kernel, but I obviously don't care. By default =eth0= is at
=10.0.2.15= with the host machine reachable at =10.0.2.2=.

** DONE Reading DWARF prototypes in ltrace                        :tools:dev:
   CLOSED: [2014-04-14 Mon 02:51]

#+begin_o_blog_alert info Follow-up posts
[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Reading DWARF prototypes in ltrace (part 2)")){/lisp}][Reading DWARF prototypes in ltrace (part 2)]]
#+end_o_blog_alert

From time to time I use the [[http://ltrace.org/][=ltrace=]] tool for introspection into user-space
processes. This is similar to =strace=, but hooks into library API calls intead
of just system calls. This is quite useful, but has some extra challenges.

With system calls you know beforehand the full set of functions you are hooking,
their prototypes, and the meaning and purpose of each argument. With general
libraries the space of all the possible APIs is huge, so you generally do /not/
know this. =ltrace= can read configuration files that define these interfaces,
so with a bit of manual effort you can provide this information. It would be
really nice to be able to trace generic function calls with no extra effort at
all. Much of the prototype data exists in debug infomation, which is often
available along with the executable binary. So by parsing this information, we
can trace API calls without needing to edit a configuration file.

*** Stock behavior

Let's say I have the following simple project. There are 3 files: =tstlib.h=,
=tstlib.c= and =tst.c=. These define a small library and an application
respectively. Let's say I have

=tstlib.h=
#+begin_src C
#pragma once

struct tree
{
    int x;
    struct tree* left;
    struct tree* right;
};
struct tree treetest(struct tree* t);

struct loop_a;
struct loop_b;
typedef struct loop_a { struct loop_b*   b; int x;} loop_a_t;
        struct loop_b {        loop_a_t* a; int x;};
void looptest( loop_a_t* a );

enum E { A,B,C };
typedef enum E E_t;
int enumtest( enum E a, E_t b );

struct witharray
{
    double x[5];
};
double arraytest( struct witharray* s );
#+end_src

=tstlib.c=
#+begin_src C
#include "tstlib.h"

struct tree treetest(struct tree* t)
{
    if(t->left  != NULL) treetest(t->left);
    if(t->right != NULL) treetest(t->right);
    t->x++;

    return *t;
}

void looptest( loop_a_t* a )
{
    a->x++;
    a->b->x++;
}

int enumtest( enum E a, E_t b )
{
    return a == b;
}

double arraytest( struct witharray* s )
{
    return s->x[0];
}
#+end_src

=tst.c=
#+begin_src C
#include "tstlib.h"
#include <unistd.h>

void main(void)
{
    struct tree d = {.x = 4};
    struct tree c = {.x = 3, .right = &d};
    struct tree b = {.x = 2};
    struct tree a = {.x = 1, .left = &b, .right = &c};
    treetest( &a );

    struct loop_a la = {.x = 5};
    struct loop_b lb = {.x = 6};
    la.b = &lb;
    lb.a = &la;
    looptest(&la);

    enum E ea = A, eb = B;
    enumtest( ea, eb );

    struct witharray s = {.x = {1.0,2.0,1.0,2.0,1.0}};
    arraytest( &s );
}
#+end_src

Now I build this with debug information, placing the library in a DSO and
setting the RPATH:

#+begin_src sh
cc -g -c -o tst.o tst.c
cc -fpic -g -c -o tstlib.o tstlib.c
cc -shared -Wl,-rpath=/home/dima/projects/ltrace/ltracetests -o tstlib.so  tstlib.o
cc -Wl,-rpath=/home/dima/projects/ltrace/ltracetests tst.o tstlib.so -o tst
#+end_src

I now run the stock =ltrace= to see calls into the =tstlib= library. I'm using
the latest =ltrace= in Debian/sid: version 0.7.3-4:

#+begin_src sh
dima@shorty:~/projects/ltrace/ltracetests$ ltrace -n2 -l tstlib.so ./tst

tst->treetest(0x7fff6b36ad30, 0x7fff6b36ada0, 0x7fff6b36ada0, 0 <unfinished ...>
  tstlib.so->treetest(0x7fff6b36acf0, 0x7fff6b36adc0, 0x7fff6b36adc0, 0) = 0
  tstlib.so->treetest(0x7fff6b36acf0, 0x7fff6b36ade0, 0x7fff6b36ade0, 0 <unfinished ...>
    tstlib.so->treetest(0x7fff6b36acb0, 0x7fff6b36ae00, 0x7fff6b36ae00, 0) = 0
  <... treetest resumed> )                                            = 0x7fff6b36acb0
<... treetest resumed> )                                              = 0x7fff6b36ad30
tst->looptest(0x7fff6b36ad90, 0x7fff6b36ae00, 0x7fff6b36ade0, 0x7fff6b36adc0) = 0x7fff6b36ad80
tst->enumtest(0, 1, 1, 0x7fff6b36adc0)                                = 0
tst->arraytest(0x7fff6b36ad50, 1, 1, 0x7fff6b36adc0)                  = 0x3ff0000000000000
+++ exited (status 0) +++
#+end_src

So we clearly see the calls, but the meaning of the arguments (and return
values) isn't clear. This is because =ltrace= has no idea what the prototypes of
anything are, and assumes that every API call is =long f(long,long,long,long)=.

*** Patched behavior

I made a patch to read in the prototypes from DWARF debugging information. The
initial version lives at https://github.com/dkogan/ltrace. This is far from
done, but it's enough to evaluate the core functionality. With the patched
=ltrace=:

#+begin_src sh
dima@shorty:~/projects/ltrace/ltracetests$ ltrace -n2 -l tstlib.so ./tst

tst->treetest({ 1, { 2, nil, nil }, { 3, nil, { 4, nil, nil } } } <unfinished ...>
  tstlib.so->treetest({ 2, nil, nil })                                = nil
  tstlib.so->treetest({ 3, nil, { 4, nil, nil } } <unfinished ...>
    tstlib.so->treetest({ 4, nil, nil })                              = nil
  <... treetest resumed> )                                            = { 5, nil, nil }
<... treetest resumed> )                                              = { 2, { 3, nil, nil }, { 4, nil, { 5, nil, nil } } }
tst->looptest({ { recurse^, 6 }, 5 })                                 = <void>
tst->enumtest(A, B)                                                   = 0
tst->arraytest({ [ 1.000000, 2.000000, 1.000000, 2.000000... ] })     = 1.000000
+++ exited (status 0) +++
#+end_src

Much better! We see the tree structure, the array and the enum values. The
return values make sense too. So this is potentially very useful.

*** Issues to resolve

Playing with this for a bit, it's becoming more clear what the issues are. The
DWARF information gives you the prototype, but an API definition is more than
just a prototype. For one thing, if a function has a pointer argument, this can
represent and input or an output. My implementation currently assumes it's an
input, but being wrong either way is problematic here:

- If a pointer is an output and ltrace interprets it as an input, then the
  output is never printed (as we can see in the loop test above). Furthermore,
  the input /will/ be printed and since there could be nested pointers, this
  could result in a segmentation fault. In this case =ltrace= can thus crash the
  process being instrumented. Oof.

- If a pointer is an input treated as an output, then again, we won't see useful
  information, and will be printing potentially bogus data at the output.

This can be remedied somewhat by assuming that an input /must/ be =const= (and
vice versa), but one can't assume that across the board.

Even if we somehow know that a pointer is an input, we still don't know how to
print it. How many integers does an =int*= point to? Currently I assume the
answer is 1, but what if it's not? Guessing too low we don't print enough useful
information; guessing too high can overrun our memory.

These are all things that =ltrace='s configuration files can take care of. So it
sounds to me like the best approach is a joint system, where both DWARF and the
config files are read in, and complementary definitions are used. It wouldn't be
fully automatic, but at least it could be /right/. In theory this is implemented
in the tree I linked to above, but it doesn't work yet.

This all needs a bit more thought, but I think I'm on to something.

** DONE Argument alignment in Linux system calls                  :tools:dev:
   CLOSED: [2014-04-16 Wed 02:08]

The last two posts talked about patches to =sysdig= and =ltrace=. This week
wouldn't be complete without patching =strace= as well. My patch series to make
=sysdig= work on ARM apparently had a bug: =preadv= and =pwritev= were not
reporting their =offset= argument properly. These two syscalls had the same
exact issue, so I'll just talk about =preadv=. The userspace prototype of this
syscall looks like this:

#+begin_src C
ssize_t preadv(int fd, const struct iovec *iov, int iovcnt, off_t offset);
#+end_src

=off_t= is a 64-bit value, so on 32-bit architectures this must be split across
two different registers when making the syscall. Some architectures also have
alignment requirements. In my case, the Linux ARM EABI requires that such values
be passed in a consecutive even/odd register pair, with a register of padding if
needed. Thus in the case of =preadv=, the values would be passed as follows:

| argument  | register |
|-----------+----------|
| fd        | r0       |
| iov       | r1       |
| iovcnt    | r2       |
| *padding* | r3       |
| offset    | r4/r5    |

The sysdig ARM code was doing this, and it worked fine for other syscalls, but
this was /not/ working for =preadv= and =pwritev=. To my surprise I discovered
that even =strace= was misreporting the value of the =offset= argument. I wrote
a small test program:

#+begin_src C
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <unistd.h>
#include <sys/uio.h>

int main(void)
{
    const off_t offset = 1234567890123456789LL;
    char buf[4];

    int fd_zero = open("/dev/zero", O_RDONLY);
    pread (fd_zero, buf, sizeof(buf), offset);
    preadv(fd_zero,
           &(struct iovec){ .iov_base = buf,
                   .iov_len = sizeof(buf)},
           1, offset );

    int fd_null = open("/dev/null", O_WRONLY);
    pwrite(fd_null, buf, sizeof(buf), offset);
    pwritev(fd_null,
            &(struct iovec){.iov_base = buf, .iov_len = sizeof(buf)},
            1, offset );

    return 0;
}
#+end_src

Then I built it with =gcc -std=gnu99 -D_FILE_OFFSET_BITS=64=, and ran it under
=strace= on ARM. The relevant parts of =strace= output:

#+begin_src C
open("/dev/zero", O_RDONLY|O_LARGEFILE) = 3
pread(3, "\0\0\0\0", 4, 1234567890123456789) = 4
preadv(3, [{"\0\0\0\0", 4}], 1, 4582412532) = 4
open("/dev/null", O_WRONLY|O_LARGEFILE) = 4
pwrite(4, "\0\0\0\0", 4, 1234567890123456789) = 4
pwritev(4, [{"\0\0\0\0", 4}], 1, 4582412532) = 4
#+end_src

Note that the =offset= parameter in =preadv= and =pwritev= is reported
as 4582412532. As you can see in the source, the offset is actually the same for
all the calls: 1234567890123456789. So something fishy is going on. Digging
through kernel source revealed the answer. Here's how the =pread= and =preadv=
system calls are defined (I'm looking at =fs/read_write.c= in Linux 3.14):

#+begin_src C
SYSCALL_DEFINE4(pread64, unsigned int, fd, char __user *, buf,
			size_t, count, loff_t, pos)
SYSCALL_DEFINE5(preadv, unsigned long, fd, const struct iovec __user *, vec,
		unsigned long, vlen, unsigned long, pos_l, unsigned long, pos_h)
#+end_src

Note that =pread= defines its =pos= argument as a 64-bit value of type =loff_t=.
This is what you'd expect and also what the userspace =pread= prototype looks
like. Now look at =preadv=. It does /not/ have a 64-bit =pos= argument. Instead
it has two separate 32-bit arguments. This is /different/ from the userspace
prototype! So as far as the kernel is concerned, there are no 64 bit arguments
here, so no alignment requirements apply. So the /actual/ register map in the
=preadv= syscall looks like

| argument  | register |
|-----------+----------|
| fd        | r0       |
| iov       | r1       |
| iovcnt    | r2       |
| offset    | r3/r4    |

So libc must know to do this translation when invoking the syscall to connect
the two different prototypes. Both =sysdig= and =strace= did not know this, and
were interpreting the syscall inputs incorrectly.

There's even an [[https://lwn.net/Articles/311630/][LWN article]] about the discussion that took place when this was
originally implemented. There are various compatibility issues, and this was the
best method, apparently.

** DONE More Cscope benchmarks                               :tools:dev:data:
   CLOSED: [2014-04-20 Sun 23:43]

A patch to [[http://cscope.sourceforge.net][cscope]] was just posted: https://sourceforge.net/p/cscope/patches/86/.
This claims to speed up the building of the inverted index by using a more
efficient search algorithm in one place, and a better sorting implementation in
another. Since I did some cscope benchmarks earler ([[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Cscope benchmarks")){/lisp}][here]] and [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "GNU Global benchmarks")){/lisp}][here]]), I can easily
evaluate this patch, so I did this.

*** Test description

The results aren't directly comparable to the timings in the previous posts,
since the project being indexed (Linux kernel) is at a very different version;
much more recent and with many more sources. The test machine is the same as
before. All the tests were done with a real ext3 hard disk, /not/ a ramdisk. The
cscope is the stock cscope 15.8a-2 from Debian.

*** Results

All timings are in seconds.

**** Cold disk cache

|                                              |   Stock | Patched |
|----------------------------------------------+---------+---------|
| Initial database build                       | 123.572 | 95.5225 |
| Database re-build after touching a file      | 57.2912 |   30.91 |
| Initial search                               | 9.11125 |   8.415 |
| Re-search after touching a file              | 59.6287 |   31.92 |
| Initial no-db-update search                  | 0.80625 |  1.2075 |
| No-db-update re-search after touching a file |   0.805 |    0.95 |

**** Warm disk cache

|                                              |   Stock | Patched |
|----------------------------------------------+---------+---------|
| Initial database build                       | 55.3537 | 29.5287 |
| Database re-build after touching a file      | 45.4975 |  18.805 |
| Initial search                               | 0.12125 |    0.12 |
| Re-search after touching a file              |  45.985 | 19.0437 |
| Initial no-db-update search                  |       0 |       0 |
| No-db-update re-search after touching a file |       0 | 0.00125 |

Note that this tests /only the timings/. I did not actually look at the results
being produced. Presumably they match, but I did not check.

*** Conclusions

Yeah. Much faster. Hopefully this produces the correct results, and gets merged
in some form.

*** Benchmark script

Here's the script that was used to get the timings. It's pretty much the same as
before, with small modifications to set what is being tested. As before, this is
a =zsh= script. It uses some =zsh=-isms, but could be converted to =bash= if
somebody cares to do it.

#+begin_src sh
#!/bin/zsh

# needed in cleandb()
setopt nonomatch

function dropcaches() {
    if [[ $warmcold == "cold" ]]; then
        sync ;
        sudo sysctl -w vm.drop_caches=3;
    fi
    sleep 2;
}

function cleandb() {
    # requires nonomatch option to ignore missing globs
    rm -f cscope.out* G*;
}

function touchfile() {
    sleep 2; # very important. cscope needs this to see the file update
    touch include/drm/drm_edid.h;
}

TIMEFMT='%E'

awktally='
BEGIN {
  skip = ENVIRON["skip"]
}

/^[0-9\.]+s$/ {
  gsub("s","");
  str = str " " $1
  if( n >= skip )
  {
    sum += $1;
  }
  n++;
}

END {
  print ENVIRON["name"] ": skipping: " skip " all: " str " mean: " sum/(n-skip)
}'

typeset -A skipcounts
skipcounts=(cold 2 warm 2)

modeoptions="-k -q"

cscope-indexer -l -r

Nrepeat=8

for mode (kernel patched)
{
    if [[ $mode == "patched" ]]; then
        cmd="/tmp/cscope-15.8a-patched/src/cscope $modeoptions";
    else
        cmd="/tmp/cscope-15.8a/src/cscope $modeoptions";
    fi

    for dotouch (0 1)
    {
        for warmcold (cold warm)
        {
            export name="$warmcold initial build; $mode mode; touching: $dotouch";
            export skip=$skipcounts[$warmcold];
            repeat $(($Nrepeat + $skip)) {
                if (($dotouch)); then
                    touchfile;
                else
                    cleandb;
                fi
                dropcaches;
                time ${(z)cmd} -b;
            } |& awk $awktally
        }
    }

    for dotouch (0 1)
    {
        for warmcold (cold warm)
        {
            export name="$warmcold initial search; $mode mode; touching: $dotouch";
            export skip=$skipcounts[$warmcold];
            repeat $(($Nrepeat + $skip)) {
                if (($dotouch)); then
                    touchfile;
                fi
                dropcaches;
                time ${(z)cmd} -L0 main > /dev/null;
            } |& awk $awktally
        }
    }

    for dotouch (0 1)
    {
        for warmcold (cold warm)
        {
            export name="$warmcold initial no-db search; $mode mode; touching: $dotouch";
            export skip=$skipcounts[$warmcold];
            repeat $(($Nrepeat + $skip)) {
                if (($dotouch)); then
                    touchfile;
                fi
                dropcaches;
                time ${(z)cmd} -d -L0 main > /dev/null;
            } |& awk $awktally
        }
    }
}
#+end_src

*** original benchmark data                                        :noexport:
cold initial build; kernel mode; touching: 0: skipping: 2 all:  126.28 126.63 124.29 125.34 122.14 121.44 124.63 122.28 122.81 125.65 mean: 123.572
warm initial build; kernel mode; touching: 0: skipping: 2 all:  89.94 62.50 56.71 55.47 55.03 54.61 55.70 55.26 54.72 55.33 mean: 55.3537
cold initial build; kernel mode; touching: 1: skipping: 2 all:  56.69 59.06 57.32 57.04 57.00 57.08 57.56 57.46 57.27 57.60 mean: 57.2912
warm initial build; kernel mode; touching: 1: skipping: 2 all:  52.52 44.44 45.47 44.71 45.16 44.60 46.76 44.70 45.61 46.97 mean: 45.4975
cold initial search; kernel mode; touching: 0: skipping: 2 all:  8.33 8.27 8.30 11.44 9.70 8.50 8.28 8.38 9.96 8.33 mean: 9.11125
warm initial search; kernel mode; touching: 0: skipping: 2 all:  0.13 0.13 0.12 0.12 0.12 0.13 0.12 0.12 0.12 0.12 mean: 0.12125
cold initial search; kernel mode; touching: 1: skipping: 2 all:  60.87 61.72 62.23 59.06 59.06 60.08 58.66 58.50 57.91 61.53 mean: 59.6287
warm initial search; kernel mode; touching: 1: skipping: 2 all:  50.66 48.51 47.33 46.55 45.50 45.18 44.43 46.96 47.43 44.50 mean: 45.985
cold initial no-db search; kernel mode; touching: 0: skipping: 2 all:  0.98 0.65 0.96 0.65 0.97 0.65 0.97 0.64 0.96 0.65 mean: 0.80625
warm initial no-db search; kernel mode; touching: 0: skipping: 2 all:  0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 mean: 0
cold initial no-db search; kernel mode; touching: 1: skipping: 2 all:  0.97 0.64 0.96 0.64 0.97 0.65 0.95 0.65 0.97 0.65 mean: 0.805
warm initial no-db search; kernel mode; touching: 1: skipping: 2 all:  0.02 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 mean: 0
cold initial build; patched mode; touching: 0: skipping: 2 all:  95.11 97.38 95.83 97.90 95.01 95.20 93.65 94.51 95.92 96.16 mean: 95.5225
warm initial build; patched mode; touching: 0: skipping: 2 all:  30.03 29.29 29.68 29.13 29.57 29.33 29.92 29.01 29.34 30.25 mean: 29.5287
cold initial build; patched mode; touching: 1: skipping: 2 all:  31.32 30.97 30.92 30.80 30.78 31.09 32.26 30.75 29.89 30.79 mean: 30.91
warm initial build; patched mode; touching: 1: skipping: 2 all:  18.05 18.20 18.46 18.94 18.68 18.43 18.92 19.12 18.86 19.03 mean: 18.805
cold initial search; patched mode; touching: 0: skipping: 2 all:  9.68 8.12 8.12 8.11 9.28 8.17 8.15 7.95 8.19 9.35 mean: 8.415
warm initial search; patched mode; touching: 0: skipping: 2 all:  0.13 0.13 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 mean: 0.12
cold initial search; patched mode; touching: 1: skipping: 2 all:  28.92 29.93 31.87 33.01 31.26 34.48 31.39 30.79 31.38 31.18 mean: 31.92
warm initial search; patched mode; touching: 1: skipping: 2 all:  18.63 18.58 18.62 19.00 18.61 18.51 19.34 18.36 19.06 20.85 mean: 19.0437
cold initial no-db search; patched mode; touching: 0: skipping: 2 all:  1.11 0.67 1.09 0.66 1.06 0.67 3.29 0.68 1.54 0.67 mean: 1.2075
warm initial no-db search; patched mode; touching: 0: skipping: 2 all:  0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 mean: 0
cold initial no-db search; patched mode; touching: 1: skipping: 2 all:  1.04 0.66 1.02 0.65 1.02 0.77 1.28 0.81 1.22 0.83 mean: 0.95
warm initial no-db search; patched mode; touching: 1: skipping: 2 all:  0.02 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 mean: 0.00125

** DONE Even better notifications                             :tools:desktop:
   CLOSED: [2014-05-01 Thu 14:39]

Two previous posts ([[file:{lisp}(ob:link-to-post (ob:get-post-by-title "X11 urgency hint and notifications")){/lisp}][X11 urgency hint and notifications]] and [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Already-running process notifications")){/lisp}][Already-running
process notifications]]) talked about ways to notify the user about terminating
shell processes. I've been living with this setup for a little while, and I just
thought of a better way to do this. Instead of the user asking for notifications
about particular processes, why not get notifications about /all/ processes?

As before, I'm using the X11 urgency hint. This hint is automatically removed by
the window manager when the hinted window is focused. Thus if you set an urgency
hint on an already-focused window, nothing will happen. Thus setting urgency on
completion of every single command won't generate too much noise, since most of
the time we're in the same terminal window at the start /and/ the stop of the
command. You /will/ see a notification when you move to a different window
before the process exits, which is /exactly/ what you want here.

=zsh= has a convenient hook that can be used for this: =precmd= is called right
before the shell prompt is printed. So to notify on all completions, you can put
into your =.zshrc=:

#+begin_src sh
function precmd {
  seturgent
}
#+end_src

This works, with one caveat: as described previously, =seturgent= is a perl
script, and calling it this way one can feel the overhead. It feels slower than
it should be. Since =seturgent= isn't doing any searching here, I rewrote the
chunk of it we're using in C. As one would think, it's way quicker:

=seturgent_fast.c=
#+begin_src C
#include <stdio.h>
#include <stdlib.h>
#include <X11/Xlib.h>
#include <X11/Xutil.h>

int main(void)
{
    const char* window_idstring = getenv("WINDOWID");
    if( window_idstring == NULL )
    {
        fprintf(stderr, "No WINDOWID set\n");
        return 1;
    }
    Window w = atoi(window_idstring);
    if( w <= 0 )
    {
        fprintf(stderr, "Couldn't parse window id '%s'\n",
                window_idstring);
        return 1;
    }


    Display* display;
    const char* displaystring = getenv("DISPLAY");
    if( displaystring == NULL )
    {
        fprintf(stderr, "No DISPLAY set\n");
        return 1;
    }

    display = XOpenDisplay(displaystring);
    if( display == NULL )
    {
        fprintf(stderr, "Couldn't open display '%s\n", displaystring);
        return 1;
    }

    XWMHints* hints = XGetWMHints(display, w);
    if( hints == NULL )
    {
        fprintf(stderr, "Couldn't retrieve hints\n");
        return 1;
    }

    hints->flags |= XUrgencyHint;
    XSetWMHints(display, w, hints);

    XFree(hints);
    XFlush(display);
    XCloseDisplay(display);
    return 0;
}
#+end_src

This can be built simply with

#+begin_src sh
gcc -lX11 -o seturgent_fast{,.c}
#+end_src

Running this for a bit the main discovery is that it's a bit easier to maintain
focus. Previously, I'd start a build or APT update (or whatever), then go do
something else, checking on the progress of the long task periodically. This
punctuated workflow is fairly inefficient, and the notification system help to
minimize it as much as is possible.

So yeah. I'll run this for a bit more, and we'll see if there's more to improve.
   
** DONE Emacs-snapshot package hosting                                :emacs:
   CLOSED: [2014-06-07 Sat 17:29]

A few months ago, Julian Danjou stopped updating his bleeding-edge GNU Emacs
Debian packages (http://emacs.naquadah.org/). I've been using those for a while,
and I'd like to continue doing so. Thus, I'm now building and hosting my own
bleeding-edge packages: http://emacs.secretsauce.net/.

There's nothing particularly noteworthy about the building or hosting of these.
The =/etc/apt/sources.list= entries are

#+BEGIN_EXAMPLE
deb     [arch=amd64] http://emacs.secretsauce.net unstable main
deb-src [arch=amd64] http://emacs.secretsauce.net unstable main
#+END_EXAMPLE

In other news, it turns out that web site hosting is now incredibly cheap.

** DONE Tab completion for sysdig                                     :tools:
   CLOSED: [2014-06-23 Mon 18:10]

I just implemented =zsh= tab-completion functionality for =sysdig=:

 https://raw.githubusercontent.com/dkogan/sysdig/master/scripts/completions/zsh/_sysdig

The patch was merged to =sysdig= upstream.

It's fairly nice, and makes =sysdig= easier to use for those who don't yet have
all the knobs memorized, such as myself. I complete on

- commandline options
- commandline option arguments
- chisel names
- chisel arguments
- filter field names

Some of those are hard-coded in the completion script, and some are reported by
the =sysdig= executable itself. Having written this I'm now acutely aware of
missing similar functionality in =tcpdump= and =perf=. Both of those have some
tab completion, but do not complete on event types. If they did, writing things
like =tcpdump= filters would be much easier. That's a good thing to add at some
point.

Another interesting discovery is that it is apparently normal for =zsh=
completion scripts to live in the =zsh= repository, /not/ in the repository of
the thing being completed. So in this case I apparently went against to grain by
contributing my script to =sysdig= instead of =zsh=. This feels right, though.
But if I make those additions to =tcpdump= and/or =perf= completions, those will
go to the =zsh= people.

** DONE Ltrace filtering details                                      :tools:
   CLOSED: [2014-06-25 Wed 16:51]
   
In an [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Reading DWARF prototypes in ltrace")){/lisp}][earlier post]] I talked about teaching ltrace to read function prototypes
from DWARF data. I'm making more progress on that front, and the initial code
has been merged into the upstream ltrace repository. One point of confusion for
me was the difference between ltrace's various filtering commandline options
=-x=, =-e=, =-l= and =-L=. I added a more thorough description and an example to
the ltrace manpage, and I'm discussing this here.

The ltrace filters specify which functions should be instrumented. Since ltrace
introduces non-negligible overhead to the running process, it's very desirable
to instrument only the functions you care about. Otherwise the process can be
slowed significantly.

Broadly speaking

- =-x= is *show me what calls these symbols (including local calls)*
- =-e= is *show me what calls these symbols (inter-library calls only)*
- =-l= is *show me what calls into this library*

Inter-library and intra-library calls are treated separately because they are
implemented differently in the binary. Calls into a shared object use the PLT
mechanism, while local calls do not.

If no =-e= or =-l= filtering options are given, ltrace assumes a default filter
of =-e @MAIN= (trace all non-local calls into the main executable). If only a
=-x= is given, this default filter is /still/ present, and it can be turned off
by passing =-L=. In my experience, if you're using =-x=, you pretty much always
want =-L= as well.

*** Example

Suppose I have a library defined with this header =tstlib.h=:

#+BEGIN_SRC C
#pragma once
void func_f_lib(void);
void func_g_lib(void);
#+END_SRC

and this implementation =tstlib.c=:

#+BEGIN_SRC C
#include "tstlib.h"
void func_f_lib(void)
{
    func_g_lib();
}
void func_g_lib(void)
{
}
#+END_SRC

Note that =func_f_lib()= and =func_g_lib()= are both external symbols. I have an
executable that uses this library defined like this =tst.c=:

#+BEGIN_SRC C
#include "tstlib.h"
void func_f_main(void)
{
}
void main(void)
{
    func_f_main();
    func_f_lib();
}
#+END_SRC

Note that =func_f_main()= is an external symbol as well.

If linking with =-Bdynamic= (the default for pretty much everybody), the
internal =func_g_lib()= and =func_g_main()= calls use the PLT like external
calls, and thus ltrace says:

#+BEGIN_EXAMPLE
$ gcc -Wl,-Bdynamic -shared -fPIC -g -o tstlib.so tstlib.c

$ gcc -Wl,-rpath=$PWD -g -o tst tst.c tstlib.so

$ ltrace -x 'func*' -L ./tst

func_f_main()                             = <void>
func_f_lib@tstlib.so( <unfinished ...>
func_g_lib@tstlib.so()                    = <void>
<... func_f_lib resumed> )                = <void>
+++ exited (status 163) +++


$ ltrace -e 'func*' ./tst

tst->func_f_lib( <unfinished ...>
tstlib.so->func_g_lib()                   = <void>
<... func_f_lib resumed> )                = <void>
+++ exited (status 163) +++


$ ltrace -l tstlib.so ./tst

tst->func_f_lib( <unfinished ...>
tstlib.so->func_g_lib()                   = <void>
<... func_f_lib resumed> )                = <void>
+++ exited (status 163) +++
#+END_EXAMPLE

By contrast, if linking the shared library with =-Bsymbolic=, then the internal
=func_g_lib()= call bypasses the PLT, and ltrace says:

#+BEGIN_EXAMPLE
$ gcc -Wl,-Bsymbolic -shared -fPIC -g -o tstlib.so tstlib.c

$ gcc -Wl,-rpath=$PWD -g -o tst tst.c tstlib.so

$ ltrace -x 'func*' -L ./tst

func_f_main() = <void>
func_f_lib@tstlib.so( <unfinished ...>
func_g_lib@tstlib.so()                    = <void>
<... func_f_lib resumed> )                = <void>
+++ exited (status 163) +++


$ ltrace -e 'func*' ./tst

tst->func_f_lib()                         = <void>
+++ exited (status 163) +++


$ ltrace -l tstlib.so ./tst

tst->func_f_lib()                         = <void>
+++ exited (status 163) +++
#+END_EXAMPLE

Note that the =-x= traces are the same in both cases, since =-x= traces local
/and/ external calls. However =-e= and =-l= trace only external calls, so with
=-Bsymbolic=, local calls to =func_g_lib()= do not appear there.

** DONE Reading DWARF prototypes in ltrace (part 2)               :tools:dev:
   CLOSED: [2014-07-10 Thu 01:20]

As mentioned [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Reading DWARF prototypes in ltrace")){/lisp}][earlier]], I'm adding functionality to ltrace to read function
prototypes from DWARF debugging information. The bulk of this work was merged
upstream. I'm now hunting corner cases and various details in this whole system
before moving on to implement more features. Unsurprisingly, trying to trace
calls in libc is a rich source of corner cases. Some of these are discussed here
in no particular order.

*** Missing features
    
Ltrace currently chokes (crashes!) when encountering prototypes with particular
features. Some of these are

- Complex numbers
- =void= variables
- =union= fields
- bit fields

Most of the time these aren't used, but glibc has them somewhere, and ltrace can
get confused when the new DWARF-reading code parses glibc.


*** C++ symbol names

Some DWARF symbol DIEs have a =DW_AT_linkage_name= tag in addition to the normal
=DW_AT_name= tag. The purpose of this wasn't entirely obvious until I tried to
ltrace a C++ program. Suppose I have this trivial C++ program:

=tst.cc=
#+BEGIN_SRC C
class C
{
    void f(void);
};

void C::f(void)
{
}
#+END_SRC

I compile it, and dump the debug info:

#+begin_example

$ g++ -g -o tst.o -c tst.cc && readelf -w tst.o
....
 <2><37>: Abbrev Number: 3 (DW_TAG_subprogram)
    <38>   DW_AT_external    : 1
    <38>   DW_AT_name        : f
    <3a>   DW_AT_decl_file   : 1
    <3b>   DW_AT_decl_line   : 3
    <3c>   DW_AT_linkage_name: (indirect string, offset: 0x4e): _ZN1C1fEv
    <40>   DW_AT_declaration : 1
    <40>   DW_AT_object_pointer: <0x44>
....
#+end_example

Note that for my method =f= the =DW_AT_name= is =f=, but the
=DW_AT_linkage_name= is =_ZN1C1fEv=. The linker does not know C++, and it only
seems symbol names. Here this symbol name is the mangled =_ZN1C1fEv=, so as far
as ltrace is concerned, this is the name of this function and thus it should use
=DW_AT_linkage_name= here. One could think that the parsing rule in ltrace
should be "use =DW_AT_linkage_name= if it exists, otherwise use
=DW_AT_linkage_name=". One would be wrong, since the next section shows that
this logic is too simple.

*** Aliased symbols (different symbol, same address)

Trying to ltrace this simple program doesn't work when reading the DWARF
prototypes automatically:

=tst.c=
#+begin_src C
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <time.h>
int main(void)
{
    nanosleep( &(struct timespec){.tv_sec=0,.tv_nsec=33}, NULL);
    usleep(44);
    return 0;
}
#+end_src

I get this:

#+begin_example
$ gcc -o tst tst.c
$ ltrace -l 'libc.so*' -L ./tst
tst->__libc_start_main(0x40054d, 1, 0x7fffc04253f8, 0x400590 <unfinished ...>
tst->nanosleep(0x7fffc0425300, 0, 0x7fffc0425408, 0)                 = 0
tst->usleep(44)                                                      = <void>
+++ exited (status 0) +++
#+end_example

Note that the =nanosleep()= call does not have the correct prototype. This is
because we call =nanosleep()=, but the DWARF defines =__nanosleep= and
=__GI___nanosleep=:

#+begin_example
$ nm -D tst | grep nanosleep

                 U nanosleep


$ nm -D /lib/x86_64-linux-gnu/libc-2.18.so | grep nanosleep

00000000000f26f0 T __clock_nanosleep
00000000000b7070 W __nanosleep
00000000000f26f0 W clock_nanosleep
00000000000b7070 W nanosleep


$ readelf -w /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.18.so | grep nanosleep

    <20c7cf>   DW_AT_name        : (indirect string, offset: 0x13a95): __nanosleep
    <20c7d5>   DW_AT_linkage_name: (indirect string, offset: 0x13a90): __GI___nanosleep
    <280d67>   DW_AT_name        : (indirect string, offset: 0x13a95): __nanosleep
    <280d6d>   DW_AT_linkage_name: (indirect string, offset: 0x13a90): __GI___nanosleep
    <2dc871>   DW_AT_name        : (indirect string, offset: 0x1d940): __clock_nanosleep
    <3b0b59>   DW_AT_name        : (indirect string, offset: 0x13a95): __nanosleep
    <3b0b5f>   DW_AT_linkage_name: (indirect string, offset: 0x13a90): __GI___nanosleep
#+end_example

We can resolve this discrepancy by noting that the =nanosleep= symbol in the
libc symbol table has the same address as =__nanosleep=, and use =__nanosleep='s
DWARF prototype. I implemented this, and the patch is currently in review.

*** Aliased addresses (same symbol, different address)

Testing further, I discovered that in the libc on my machine (Debian/sid amd64)
some symbols appear at multiple addresses:

#+begin_example
$ nm -D /lib/x86_64-linux-gnu/libc-2.18.so | awk '{print $NF}' | sort | uniq -d
_sys_errlist
_sys_nerr
_sys_siglist
memcpy
nftw
nftw64
posix_spawn
posix_spawnp
pthread_cond_broadcast
pthread_cond_destroy
pthread_cond_init
pthread_cond_signal
pthread_cond_timedwait
pthread_cond_wait
realpath
regexec
sched_getaffinity
sched_setaffinity
sys_errlist
sys_nerr
sys_sigabbrev
sys_siglist
#+end_example

This can make the DWARF parser confused. Looking into it, it looks like those
are versioned symbols, with different implementation for different libc
versions. This same-symbol-different-address idea doesn't fit into the data
structures, as I've currently defined them. Currently I simply take the first
such symbol I encounter and ignore the rest. I probalby should parse this out
fully, but it hardly seems worth the effort.

** DONE Closures and cookies in C                                       :dev:
   CLOSED: [2014-07-17 Thu 17:43]

I recently discovered something that's /very/ old news to functional programming
people, but was new to me, especially as being applied to C. It is common
practice in C coding to use callback functions when a general routine needs to
do something specific that the caller knows about. Furthermore, a =void* cookie=
is generally used to pass context to this callback.

Here's a simple C99 example of a linked-list structure and a iterator that calls
a callback function for each element of the list. The iterator takes a =cookie=
argument, which it passes on untouched to the callback. This =cookie= means
something to the caller of the iterator and to the callback, but it means
nothing to the iterator itself. This is the usual idiom. Furthermore, the
example contains a simple use of this iterator, to print all node values to a
particular =FILE=:

#+begin_src c
#include <stdio.h>

struct node
{
    int x;
    struct node* next;
};

typedef void (*foreach_callback)(const struct node* node, void* cookie);

static void foreach(const struct node* list,
                    const foreach_callback cb, void* cookie)
{
    while(list != NULL)
    {
        cb(list, cookie);
        list = list->next;
    }
}




static void print_node(const struct node* node, FILE* fp)
{
    fprintf(fp, "%d\n", node->x);
}

static void print_nodes(const struct node* list, FILE* fp)
{
    foreach(list, (foreach_callback)print_node, fp);
}

int main(void)
{
    struct node list =
        {.x = 10,
         .next = &(struct node){.x = 11,
                                .next = &(struct node){.x = 12,
                                                       .next = NULL}}};

    print_nodes(&list, stdout);
    return 0;
}
#+end_src

This works fine, and things have been done this way for a very long time. As
written, =print_node()= is visible to most of the source file, even though it is
only used by =print_nodes()=. It would be nice if =print_node()= was visible
/only/ from that one function that uses it. This is not possible in standard C.
However GCC has a [[https://gcc.gnu.org/onlinedocs/gcc/Nested-Functions.html][non-standard extension]] that allows such things: nested
functions. With that in mind, we can rewrite the example like so:

#+begin_src c
#include <stdio.h>

struct node
{
    int x;
    struct node* next;
};

typedef void (*foreach_callback)(const struct node* node, void* cookie);

static void foreach(const struct node* list,
                    const foreach_callback cb, void* cookie)
{
    while(list != NULL)
    {
        cb(list, cookie);
        list = list->next;
    }
}




static void print_nodes(const struct node* list, FILE* fp)
{
    void print_node(const struct node* node, FILE* fp)
    {
        fprintf(fp, "%d\n", node->x);
    }


    foreach(list, (foreach_callback)print_node, fp);
}

int main(void)
{
    struct node list =
        {.x = 10,
         .next = &(struct node){.x = 11,
                                .next = &(struct node){.x = 12,
                                                       .next = NULL}}};

    print_nodes(&list, stdout);
    return 0;
}
#+end_src

That's nicer. =print_nodes()= is now self-contained, and none of its
implementation details leak out. At this point we're not using the nested
function as anything more than just syntactic sugar. However, these aren't
simply /nested functions/; they're full /closures/, i.e. the nested function has
access to the local variables of its surrounding scope. This means that
=print_node()= can see the =fp= argument to =print_nodes()=, and doesn't need to
be passed it. Thus *we do not need the cookie!* The state maintained by the
nested function takes on the work that the cookie did for us previously. As
such, we can rewrite this example with no cookies at all:


#+begin_src c
#include <stdio.h>

struct node
{
    int x;
    struct node* next;
};

typedef void (*foreach_callback)(const struct node* node);

static void foreach(const struct node* list, const foreach_callback cb)
{
    while(list != NULL)
    {
        cb(list);
        list = list->next;
    }
}




static void print_nodes(const struct node* list, FILE* fp)
{
    void print_node(const struct node* node)
    {
        fprintf(fp, "%d\n", node->x);
    }


    foreach(list, print_node);
}

int main(void)
{
    struct node list =
        {.x = 10,
         .next = &(struct node){.x = 11,
                                .next = &(struct node){.x = 12,
                                                       .next = NULL}}};

    print_nodes(&list, stdout);
    return 0;
}
#+end_src


Neat! Clearly this is non-portable. It also is potentially unsafe since
internally the compiler generates a bit of code on the stack and runs it. Still,
the code looks nicer and we don't need cookies.

** DONE Debian cross-gcc snapshot packages                        :tools:dev:
   CLOSED: [2014-07-20 Sun 01:55]

#+begin_o_blog_alert info Note
This is largely out-of-date. These packages are now in Debian/unstable, and I
shut down the server described here in favor of the packages in the main
archive.
#+end_o_blog_alert

For a while, getting a cross-compiler on Debian was much more complicated than
simply running an =apt-get install=. The /current/ situation is that
cross-compilers are mostly ready-to-build, but for uninteresting reasons,
packages are still not available in the main Debian repository. I am now
building these packages every week, and hosting them on my APT server:

http://toolchains.secretsauce.net/

I attempt to build compilers targeting

- armel
- armhf
- mips
- mipsel
- powerpc

Compilers for the following languages are built:

- C
- C++
- Fortran
- Java
- Go
- Objective C
- Objective C++

Hopefully we'll get cross-compilers into Debian proper at some point, so that
using my unofficial repo becomes unnecessary

** DONE Decoding P25 with RTL-SDR on Debian                             :SDR:
   CLOSED: [2014-07-25 Fri 17:31]

I wanted to play with an [[http://en.wikipedia.org/wiki/Software_defined_radio][software-defined radio]] for a while now. A simple one
can be had for about $10 by repurposing a USB TV adapter:
http://sdr.osmocom.org/trac/wiki/rtl-sdr. I bought one, and looked into using it
as a police scanner. Suprisingly to me, there's quite a bit of information out
there about the protocols and frequencies used by LAPD:
http://harrymarnell.net/lapd-freqs.htm. So they're using [[http://en.wikipedia.org/wiki/P25][P25]]-encoded digital
signals, which are unencrypted, apparently.

There are some guides out there on how to decode these with an RTL-SDR, but
they're all highly Windows-centric (and look like a pain in the butt, to be
honest). This post is a set of notes on getting this working on a Debian box.

*** Obtaining the tools

The core RTL-SDR libraries, GNU Radio and UI tools such as [[http://gqrx.dk/][GQRX]] are already in
Debian, so getting them is trivial. There is a tool for decoding P25, =dsd=;
it's not in Debian, so we have to build it. First we get and build =mbelib=, a
library it uses. We check out the code, roll bakc to the latest tag and build:


#+begin_example

dima@shorty:/tmp$ git clone https://github.com/szechyjs/mbelib
...
dima@shorty:/tmp$ cd mbelib

dima@shorty:/tmp/mbelib$ git tag -l
v1.2.1
v1.2.3
v1.2.4
v1.2.5

dima@shorty:/tmp/mbelib$ git reset --hard v1.2.5
HEAD is now at 316bab6 Bump version to v1.2.5

dima@shorty:/tmp/mbelib$ mkdir build

dima@shorty:/tmp/mbelib$ cd build

dima@shorty:/tmp/mbelib/build$ cmake ..
...

dima@shorty:/tmp/mbelib/build$ make
...
Linking C static library libmbe.a

#+end_example

OK. We built =mbelib=, now we can build =dsd=. Same as before, except we tweak
the =Makefile= to find and use the library we just built, and to use the
statically-linked version so that we don't need to mess with RPATHs.

#+begin_example

dima@shorty:/tmp$ git clone https://github.com/szechyjs/dsd
...

dima@shorty:/tmp$ cd dsd

dima@shorty:/tmp/dsd$ git tag -l
v1.3
v1.4.1
v1.6.0

dima@shorty:/tmp/dsd$ git reset --hard v1.6.0
HEAD is now at 5d147c9 version 1.6.0

dima@shorty:/tmp/dsd$ perl -p -i -e 's{/usr/local/include}{/tmp/mbelib/}g; s{-lmbe}{/tmp/mbelib/build/libmbe.a}' Makefile

dima@shorty:/tmp/dsd$ make
...
gcc -O2 -Wall -o dsd dsd_main.o dsd_symbol.o dsd_dibit.o dsd_frame_sync.o dsd_file.o dsd_audio.o dsd_serial.o dsd_frame.o dsd_mbe.o dsd_upsample.o p25p1_hdu.o p25p1_ldu1.o p25p1_ldu2.o p25p1_tdulc.o p25_lcw.o x2tdma_voice.o x2tdma_data.o dstar.o nxdn_voice.o nxdn_data.o dmr_voice.o dmr_data.o provoice.o -L/usr/local/lib -lm /tmp/mbelib/build/libmbe.a 

#+end_example

*** Decoding the stream

Now we can think about listening in. The overall data flow is

- Tune in, demodulate the narrow-band FM signal into a 48KHz-sampled signal
- Use =dsd= to decode this 48KHz-sampled signal to produce 8KHz-sampled audio

**** FM

There are several basic tools one can use for this. I'd prefer to use the
commandline =rtl_sdr= or =rtl_fm= from the [[https://packages.debian.org/sid/rtl-sdr][rtl-sdr]] Debian package. The issue I
ran into was that we're tuning into a relatively narrow-band signal, so the
tuning is sensitive, and small tuning errors make you miss the signal you want
entirely. RTL-SDR is a cheap device, and its tuning inaccuracy alone is enough
to break this. There exists an [[https://github.com/steve-m/kalibrate-rtl][RTL-SDR calibration tool]] to compensate for the
hardware inaccuracy, but I still wasn't able to successfully tune into the
frequencies, as defined in the LAPD channel list linked above. I didn't push on
this very hard, so this could very well be my fault.

So instead of the commandline tools, I ended up GQRX. Pretty much all the LAPD
frequencies are in the 484MHz range or the 506MHz range. I set the tuner into
the right neighborhood, then the FFT waterfall plot in GQRX visually shows you
which frequencies are active. You can roughly tune in simply by looking at the
plot, and you can fine-tune by listening to the demodulated signal, trying to
find the characteristic digital buzz and no static. There are multiple
digital-sounding channels and multiple types of encoding are present (sound
different). You can play around to find a signal that =dsd= knows how to decode.
Note that since we're now looking for channels empirically, we compensate for
tuning inaccuracies, but the LAPD frequency list becomes useless, and we don't
even know what specifically we're listening to.

The GQRX window looks like this:

[[file:files/SDR/gqrx_dsd.png]]

We're clearly listening to an active transmission: we're tuned to the channel
indicated by the red line, and the waterfall plot shows intermittent activity
there. The signal is intermittent because the transmitter is only active when
there's data to send, i.e. when the human talking into the radio is pressing the
button.

**** P25

We now need to get the data out of GQRX and into =dsd=. =dsd= wants to get its
input from (and send its output to) =/dev/audio=. Even if my input was coming
from a sound device, it wouldn't be =/dev/audio= on my box. That's a holdover
from some ancient system that ALSA doesn't provide by default, and I want to
avoid it if possible. Turns out =dsd= just looks at raw samples, so we can
simply send it appropriately-formatted bits (16 bits per sample, little endian,
48KHz sample rate). GQRX has several export capabilities, one of them being raw
UDP output. This is perfect for this application, and I turn on that GQRX mode
by pressing the appropriate button (bottom of the screenshot; two computers are
pictured).

We now have raw 48KHz samples coming out on UDP port 7355. We can make a named
pipe, or better yet, we can pass the data to =dsd= on standard input:

#+begin_src sh
socat UDP-RECV:7355 - | ./dsd -i /dev/stdin
#+end_src

Almost done. We can now tune interactively with GQRX and decode the demodulated
FM data on the fly with =dsd=. =dsd= says lots of stuff about signals it's
receiving. When successfully decoding audio, I see things like this:

#+begin_example
Sync:  +P25p1     mod: C4FM inlvl:  7% nac:  466 src:   180359 tg:     1  LDU1  e:========================
Sync:  +P25p1     mod: C4FM inlvl:  7% nac:  467 src:   180359 tg:     1  LDU2  e:=========
Sync:  +P25p1     mod: C4FM inlvl:  7% nac:  466 src:   180359 tg:     1  LDU1  e:=====
Sync:  +P25p1     mod: GFSK inlvl:  7% nac:  466 src:   180359 tg:     1  LDU2  e:======R================R=========
Sync:  +P25p1     mod: C4FM inlvl:  7% nac:  466 src:   180359 tg:     1  LDU1  e:==================
Sync:  +P25p1     mod: C4FM inlvl:  7% nac:  466 src:   180359 tg:     1  LDU2  e:===
Sync:  +P25p1     mod: C4FM inlvl:  7% nac:  466 src:   180359 tg:     1  LDU1  e:=====================
Sync:  +P25p1     mod: C4FM inlvl:  7% nac:  466 src:  1228951 tg:     1  LDU2  e:========
Sync:  +P25p1     mod: C4FM inlvl:  7% nac:  466 src:  1228951 tg:     1  LDU1  e:====
Sync:  +P25p1     mod: GFSK inlvl:  7% nac:  466 src:   180359 tg:     1  LDU2  e:==================
#+end_example

We still can't hear the results because =dsd= doesn't write them anywhere
useful. We can send those to ALSA with a named pipe and =aplay=:

#+begin_src sh
# In one shell
mkfifo /tmp/pipe
socat UDP-RECV:7355 - | ./dsd -i /dev/stdin -o /tmp/pipe

# In another shell, in parallel
aplay -r 8000 -f S16_LE -t raw -c 1 < /tmp/pipe
#+end_src

So this setup works for me. Now one can go back, and fix stuff; stuff like
inaccurate tuning. It'd be nice to automatically tune into valid channels, of
better yet to follow the trunking signals, but that's more work than I'm willing
to put into this.


*** Commandline-only listening (no GQRX)

Once we find a channel we like, using GQRX to interactively tune the radio (as
described above), we can run the whole pipeline with one command (possibly
zsh-only):

#+begin_src sh
./dsd -f1 -mc -i <(rtl_fm -F1 -o4 -g32 -f 484.7918M -s48000 -) -o >(aplay -r 8000 -f S16_LE -t raw -c 1)
#+end_src

Here 484.7918Mhz is the frequency I found by poking around with GQRX. =-F1 and
-o4= are tuning parameters (possibly highly suboptimal). The =-f1 -mc= options
to =dsd= indicate what signal should be expected; this would vary if listening
to something other than LAPD. Seems to work. And the total CPU comsumption is
about 1/3 of what gqrx requires.

** DONE Org-mode for invoices                                         :emacs:
   CLOSED: [2014-10-01 Wed 10:11]

Like many people I work as a contractor, so I need to keep track of my hours and
to generate monthly invoices. Org-mode already has a [[http://orgmode.org/manual/Clocking-work-time.html][nice way to track hours]] and
a way to [[http://orgmode.org/manual/Exporting.html][export to a PDF]]. What's missing is a reasonable way to bridge those two
functions, to generate invoices, and the way I do this is described in this
post.

The main approach here is to maintain a =timecard.org= file that contains all
the timing information. As I work, I clock in and out of tasks in this file.
Then when an invoice needs to be prepared I simply export this file as a PDF,
and I get out a finished invoice. Before I get into the details, here's a sample
=timecard.org=:

#+BEGIN_SRC org :exports code

 #+STARTUP: showall
 #+LaTeX_CLASS_OPTIONS: [letterpaper,10pt]
 #+LATEX_HEADER: \usepackage[letterpaper,tmargin=0.5in,bmargin=1.0in,lmargin=1.0in,rmargin=1.0in,headheight=0in,headsep=0in,footskip=0.0in]{geometry}
 #+LATEX_HEADER: \usepackage{lmodern}
 #+LATEX_HEADER: \usepackage[labelformat=empty,textformat=empty]{caption}
 #+LATEX_HEADER: \parindent 0in
 #+LATEX_HEADER: \parskip 0.1in
 #+LATEX_HEADER: \setlength\LTleft{0pt} \setlength\LTright\fill
 #+OPTIONS: toc:nil num:nil 
 #+AUTHOR:
 #+DATE:
 #+TITLE: INVOICE


 #+CONSTANTS: rate=100.0

 #+BEGIN_LATEX
 \thispagestyle{empty}
 #+END_LATEX


 * Invoice number: 1
 * Invoice date: [2014-09-01 Mon]

 | / | <                    | >                     |
 |---+----------------------+-----------------------|
 |   | *Contractor*         | *Client*              |
 |---+----------------------+-----------------------|
 |   | Billy Bob Johnson    | WidgetWorks Inc       |
 |   | 21 N. First Ave      | 12 Main St.           |
 |   | Widgettown, CA 91234 | Gadgetville, CA 91235 |
 |   | william@isp.net      |                       |
 |---+----------------------+-----------------------|

 #+NAME: summary
 | / |            |             |
 |   | *Rate*     | *Total due* |
 |   | $100.00    | _$941.67_   |
 | ^ | ratetarget | totaltarget |
 #+TBLFM: $ratetarget=$rate;$%.2f::$totaltarget=remote(clocktable, "@II$>");_$%.2f_


 *Please make checks payable to _William Johnson_*

 #+TBLNAME: clocktable
 #+BEGIN: clocktable :maxlevel 3 :tcolumns 4 :scope file :block 2014-08 :narrow 60
 #+CAPTION: Clock summary at [2014-09-01 Mon 09:44], for August 2014.
 | <60>                                                         |        |      |      |           |
 | Headline                                                     | Time   |      |      | Amount($) |
 |--------------------------------------------------------------+--------+------+------+-----------|
 | *Total time*                                                 | *9:25* |      |      |    941.67 |
 |--------------------------------------------------------------+--------+------+------+-----------|
 | Tasks                                                        | 9:25   |      |      |    941.67 |
 | \__ Foo the bar                                              |        | 3:20 |      |    333.33 |
 | \_____ Implementing foo                                      |        |      | 3:20 |    333.33 |
 | \__ Frobnicate the baz                                       |        | 6:05 |      |    608.33 |
 #+TBLFM: @3$5..@>$5=vsum($2..$4)*$rate;t::@2$5=string("Amount($)")
 #+END:



 * Tasks                                                            :noexport:
 ** Foo the bar
 *** Meeting about the nature of bar
     CLOCK: [2014-09-07 Sun 00:24]--[2014-09-07 Sun 01:00] =>  0:36
 *** Implementing foo
     CLOCK: [2014-08-28 Thu 19:40]--[2014-08-28 Thu 23:00] =>  3:20
 ** Frobnicate the baz
     CLOCK: [2014-08-25 Mon 10:55]--[2014-08-25 Mon 17:00] =>  6:05


 * local lisp stuff                                                 :noexport:
 Local Variables:
 eval: (progn
   (set (make-local-variable 'org-time-clocksum-format)
        '(:hours "%d" :require-hours t :minutes ":%02d" :require-minutes t))
   (setq org-latex-tables-centered nil
         org-latex-default-table-environment "longtable")
   (local-set-key
    (kbd "<f5>")
    (lambda ()
      (interactive)
      ;;
      ;; Bump up the invoice number
      (beginning-of-buffer)
      (re-search-forward "Invoice number: \\([0-9]+\\)")
      (let ((n (string-to-number (match-string 1))))
        (kill-region (match-beginning 1) (match-end 1))
        (insert (format "%d" (1+ n))))
      ;;
      ;; Set the invoice date
      (beginning-of-buffer)
      (re-search-forward "Invoice date: *")
      (kill-region (point)
                   (save-excursion
                     (end-of-line) (point)))
      (org-insert-time-stamp (current-time) nil t)
      ;;
      ;;
      ;; Update the main clock table
      (beginning-of-buffer)
      (search-forward "#+BEGIN: clocktable")
      ;;
      ;; Here an advice is needed to make sure the Amount column is added
      ;; This advice is made unnecessary by this patch:
      ;; http://lists.gnu.org/archive/html/emacs-orgmode/2014-10/msg00002.html
      (unwind-protect
          (progn
            (defadvice org-table-goto-column
                (before
                 always-make-new-columns
                 (n &optional on-delim force)
                 activate)
              "always adds new columns when we move to them"
              (setq force t))
            ;;
            (org-clocktable-shift 'right 1))
        ;;
        (ad-deactivate 'org-table-goto-column))
      ;;
      ;; Update the summary table
      (beginning-of-buffer)
      (search-forward "| totaltarget")
      (org-table-recalculate t))))
 End:

#+END_SRC

As described in the [[http://orgmode.org/manual/Clocking-work-time.html][manual]], the time-tracking in org works with the user
producing an outline of tasks and then clocking in and out of them. Org can then
generate a table to summarize the hours spent on various tasks in a particular
period.

The =timecard.org= has

- some Latex commands to determine how the invoices look
- some specific information for /that/ invoice (invoice number, date, totals)
- the clock-table that contains the time and $ summaries
- the task outline that the user clocks in and out of
- some emacs lisp to update all these things in unison

The contracting rate is defined in a =#+CONSTANTS= at the top of the file. The
task outline itself is /not/ exported, but the clock-table it produces is. The
clock-table that org makes contains only timing information and nothing about
money, so I have a formula in that table that adds a column about how much each
task cost.

Every month before generating a PDF the data all needs to be updated, and the
emacs-lisp at the bottom does that. It's a bit more complicated than I'd like it
to be, but it works well. It exports the new clock-table, updates the totals,
the data, invoice number, etc. Normally I simply hit =F5=, and this invokes the
lisp and updates everything. The end-result currently looks like [[file:files/invoice/invoice.pdf][this]].

Not the prettiest thing in the world, but it serves the purpose just fine. One
could fine-tune the org exporter far more to generate prettier invoices if they
care enough to do so.

** DONE ZNC and ERC                                             :emacs:tools:
   CLOSED: [2014-10-08 Wed 14:16]

I use [[http://www.gnu.org/software/emacs/manual/erc.html][ERC]] in Emacs as my IRC client. An extremely common issue I have is that
when my laptop disconnects from the IRC server (due to the laptop going to sleep
or due to it losing a network connection), the IRC communication that happened
during that time is lost. People had this issue since the dawn of time, and a
solution exists: IRC bouncers. You run this on a dedicated server, and it acts
as a proxy between the real IRC server and your machine with its flaky network.
When you connect to the bouncer, it spews everything you missed at you. I set up
a bouncer yesterday, and it was surprisingly painful. This post summarizes the
procedure.

I'm using the [[http://www.znc.in][ZNC]] bouncer. There are others, and I'm not using this one for any
particular reason. I installed it from Debian/sid, so I'm running version
=1.4-1+b2=. Debian/wheezy has a much older package (=0.206-2=); I don't know if
it would be hugely problematic to use this older ZNC.

ZNC refuses to run as root, so I made an arbitrary user for it: =zncman=. The
procedure you're supposed to follow is

- use the =znc= binary to interactively generate a configuration
- use interactive IRC commands to configure servers and such

This is a pain in the butt. A slightly easier method:

- log in as =zncman=
- use the interactive configurator (=znc --makeconf=) to generate an arbitrary
  configuration
- kill =znc=
- edit the configuration
- restart =znc=

The configuration syntax is nominally described at
http://en.znc.in/wiki/Configuration, but this document is poor at best. This is
probably a big reason why upstream doesn't recommend editing this file. It's
much easier, though. Here's my =~/.znc/configs/znc.conf= file. It's pretty clear
what needs to be customized:

#+BEGIN_EXAMPLE
// WARNING
//
// Do NOT edit this file while ZNC is running!
// Use webadmin or *controlpanel instead.
//
// Altering this file by hand will forfeit all support.
//
// But if you feel risky, you might want to read help on /znc saveconfig and /znc rehash.
// Also check http://en.znc.in/wiki/Configuration

AnonIPLimit = 10
ConnectDelay = 5
#LoadModule = webadmin
LoadModule = fail2ban
MaxBufferSize = 500
ProtectWebSessions = true
ServerThrottle = 30
Skin = _default_
StatusPrefix = *
Version = 1.4

<Listener listener0>
        AllowIRC = true
#       AllowWeb = true
        IPv4 = true
        IPv6 = true
        Port = 5555
        SSL = false
</Listener>

<User dima>
        Admin = true
        Allow = *
        AltNick = dima_
        AppendTimestamp = true
        AutoClearChanBuffer = true
        Buffer = 50000
        ChanModes = +stn
        DenyLoadMod = false
        DenySetBindHost = false
        Ident = dima
        JoinTries = 10
#       LoadModule = webadmin
        MaxJoins = 0
        MaxNetworks = 1
        MultiClients = true
        Nick = dima
        PrependTimestamp = true
        QuitMsg = ZNC - http://znc.in
        RealName = Got ZNC?
        TimestampFormat = [%H:%M:%S]

        <Network oftc>
                Nick = dima5
                FloodBurst = 4
                FloodRate = 1.00
                IRCConnectEnabled = true
                Server = irc.oftc.net 6667
        </Network>

        <Network freenode>
                Nick = dima5
                FloodBurst = 4
                FloodRate = 1.00
                IRCConnectEnabled = true
                Server = irc.freenode.net 6667
        </Network>

        <Pass password>
                Hash = xxxxx
                Method = yyyyy
                Salt = zzzzz
        </Pass>
</User>

#+END_EXAMPLE

So with that file, ZNC runs an IRC server on port 5555 and the ZNC user is
called =dima=. ZNC itself talks to oftc and freenode using the Nick =dima5= for
both. The Debian package for ZNC is not currently integrated into the init
system, so you start the daemon with just =znc=. Clearly this doesn't happen on
every boot, and you have to set that up yourself. I haven't bothered yet, but
it'll come up at some point.

When logging into the ZNC IRC server, you have to be very clean on what is the
ZNC nick and what is the IRC server nick. Same with passwords. On top of that,
the ZNC password contains the ZNC nick, the target server and the ZNC password.
So in my case I start up ERC thusly:

#+BEGIN_SRC emacs-lisp
  (erc :server "my_znc_server.com" :port 5555 :nick "dima5" :password "dima/freenode:zncpassword")
  (erc :server "my_znc_server.com" :port 5555 :nick "dima5" :password "dima/oftc:zncpassword")
#+END_SRC

This all does the right thing. Currently there's an issue in that
=erc-autojoin-channels-alist= now sees both the freenode and oftc connection as
the same one (since it uses the hostname to differentiate, and the hostname is
now =my_znc_server.com= for both). Otherwise, this works fine.

** DONE Mu4e and desktop notifications                  :emacs:tools:desktop:
   CLOSED: [2014-12-12 Fri 20:54]

[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Even better notifications")){/lisp}][Some previous posts]] talked about desktop notifications via the X11 urgency hint.
Here I talk specifically about how I handle mail notifications specifically.

I use [[http://www.djcbsoftware.nl/code/mu/mu4e.html][mu4e]] to read mail in Emacs. This is great for reading mail, but it leaves
some tasks to external tools (I consider this a good thing):

- interacting with mail servers instead of a local [[http://en.wikipedia.org/wiki/Maildir][maildir]]
- automatically receiving mail

The former is generally done with [[http://offlineimap.org][offlineimap]] or [[http://isync.sourceforge.net/mbsync.html][mbsync]]. For the latter,
everybody seems to do something different.

To handle main receiving and notifications I use the [[http://en.wikipedia.org/wiki/IMAP_IDLE][IMAP IDLE]] command to handle
event-based (/not/ timer-based) receiving of mail, and I use the X11 UrgencyHint
(described for instance here: [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "X11 urgency hint and notifications")){/lisp}][X11 urgency hint and notifications]]) to notify me
of incoming messages. As any other UrgencyHint-based system, support from one's
window manager is crucial. I use [[http://notion.sourceforge.net][notion]] as my WM, which has /fantastic/ support
for this, so this all works /really/ well for me.

If I want event-based notifications, I run this =mailalert.pl= script:

#+begin_src perl
#!/usr/bin/perl
use strict;
use warnings;
use feature qw(say);

use Getopt::Euclid;

use Mail::IMAPClient;
use IO::Stty;
use X11::Protocol;
use X11::Protocol::WM;
use X11::WindowHierarchy;

use autodie;

use Parallel::ForkManager;

my $passwd = getPassword();

my %imapOptions    =
  ( Server         => 'mail.xxxxx.com',
    User           => 'username',
    Password       => $passwd,
    Ssl            => 1,
    Socketargs     => [SSL_verify_mode => "SSL_VERIFY_NONE"],
    Debug          => 0,
    Uid            => 1,
    Keepalive      => 1,
    Reconnectretry => 3,
 );

my $folders = getFolders( \%imapOptions );

say STDERR "Got folder list. Idling on each";

my $pm = new Parallel::ForkManager(1000);
for my $folder (@$folders)
{
  my $pid = $pm->start and next;

  my $imap = Mail::IMAPClient->new(%imapOptions) or die "Couldn't connect to imap";
  $imap->select($folder)                         or die "Couldn't select '$folder'";

  my %ids_saw;
  while(1)
  {
    my @unseen = $imap->unseen;
    my @newsubjects;
    for my $id( @unseen )
    {
      next if $ids_saw{$id};
      $ids_saw{$id} = 1;
      push @newsubjects, $imap->subject($id);
    }

    if( @newsubjects )
    {
      alert();
      my $date = `date`;
      chomp $date;
      say "$date; Pid $pid Saw unread email in '$folder':";
      print join('', map {"  $_\n"} @newsubjects);

      sleep(60*$ARGV{'--min'}) if $ARGV{'--min'};
    }

    my $IDLEtag     = $imap->idle           or die "idle failed: $@\n";
    my $idle_result = $imap->idle_data(250) or die "idle_data failed: $@\n";
    $imap->done($IDLEtag);
  }

  $pm->finish;
}
$pm->wait_all_children;



sub getPassword
{
  say "Enter password: ";

  my $stty_old = IO::Stty::stty(\*STDIN,'-g');
  IO::Stty::stty(\*STDIN,'-echo');
  $passwd = <>;
  IO::Stty::stty(\*STDIN,$stty_old);

  chomp $passwd;

  return $passwd;
}

sub getFolders
{
  my $opts = shift;

  my $imap = Mail::IMAPClient->new(%$opts) or die "Couldn't connect to imap";
  say STDERR "Connected. Getting folder list.";

  my $folders = $imap->folders
    or die "List folders error: ", $imap->LastError, "\n";
  $imap->disconnect;

  return $folders;
}

sub alert
{
  # I got mail! Alert the user

  # I try to set urgency on a mu4e window if there is one. Otherwise, I set the
  # urgency on the mailalert window itself

  my $x = X11::Protocol->new()
    or die "Couldn't open X11 display";

  # by default, set it to the mailalert ID
  my $xid = $ENV{WINDOWID};

  my @mu4e = x11_filter_hierarchy( filter => qr/emacs.*mu4e/ );
  if( @mu4e )
  {
    # found some mu4e windows. Alert the first one
    $xid = $mu4e[0]{id};

    # there's a mu4e window already. Get the mail
    system(qw(emacsclient -a '' -e), '(mu4e-update-mail-and-index t)');
  }

  X11::Protocol::WM::change_wm_hints( $x, $xid,
                                      urgency => 1 );
}


__END__

=head1 NAME

mailalert.pl - IMAP IDLE mail checker

=head1 SYNOPSIS

 ./mailalert.pl
 ... sits there until mail comes in

=head1 DESCRIPTION

This tool uses IMAP IDLE to wait for new email without polling. When a message
comes in, it tries to find the mail window and set the urgency hint on it

=head1 OPTIONAL ARGUMENTS

=over

=item --min <minimum_interval>

If given, do not alert the user more often than this many minutes.

=for Euclid:
  minimum_interval.type: int > 0

=back

=head1 AUTHOR

Dima Kogan, C<< <dima@secretsauce.net> >>

#+end_src

This is (clearly) a perl script; all the dependencies are available in Debian:

- libgetopt-euclid-perl
- libmail-imapclient-perl
- libio-stty-perl
- libx11-protocol-perl
- libx11-protocol-other-perl
- libx11-windowhierarchy-perl

To use it, fill in the IMAP server and username details. The script then queries
one for the password when it is executed. This script connects to the IMAP
server, and waits for new mail on all folders. When new mail arrives to any
folder, it calls =alert()=, which does 2 things:

- Finds the mu4e Emacs window, and sets the UrgencyHint on it
- Tells Emacs to contact the server and download, reindex the mail

The server operations are handled by evaluating

#+begin_src emacs-lisp
(mu4e-update-mail-and-index t)
#+end_src

as Emacs Lisp. This is a mu4e function that carries out the obvious operations.
Mu4e is told how to receive the mail by a bit of configuration the Emacs init
files. In my case:

#+begin_src emacs-lisp
(setq mu4e-get-mail-command "offlineimap -q")
#+end_src

This works for me. The only real downside is that due to the way IMAP is
implemented, only a single folder can be monitored for updates at a time. The
script above thus makes a connection to the server for each folder that exists.
If you have a lot of folders, this is quite a few simultaneous connections! A
consequence of this is that my script is silly, and looks at each folder in a
separate fork, with the forks not talking to each other. Thus if mail arrives to
more than one folder at the same time (as happens often when you initially start
the script), multiple =(mu4e-update-mail-and-index t)= are made at the same
time. Fortunately, this simply generates a warning, and doesn't do anything
bad, so my script can remain silly, and I can get on with my life.

** DONE Word-oriented navigation in emacs-lisp                        :emacs:
   CLOSED: [2015-01-01 Thu 18:03]

I recently hit a [[http://debbugs.gnu.org/17558][bug]] in a recent build of GNU Emacs. The crux of the matter was
that word-relative functions such as =forward-word= now respect =subword-mode=
and =superword-mode=. This is good for interactive use, but can have unintended
consequences in existing code, which is what happened with ERC: ERC expected
=forward-word= to move consistently, but now it behaves differently if
=subword-mode= is active.

The solution seems to be to forgo =forward-mode= and friends for interactive
use, and to use more low-level functions in programs. For instance, I replaced
=(upcase-word 1)= with

#+BEGIN_SRC emacs-lisp
 (skip-syntax-forward "^w")
 (let*
     ((word-start (point))
      (word-end
       (progn (skip-syntax-forward "w") (point))))
   (upcase-region word-start word-end))
#+END_SRC

Way more verbose than I would like, but it works.

** DONE User-space introspection with Linux perf                  :tools:dev:
   CLOSED: [2015-01-28 Wed 19:42]

The Linux kernel comes with a performance counter/profiler: [[https://perf.wiki.kernel.org/index.php/Main_Page][=perf=]]. This was
originally a kernel-only tool, but it can now do some userspace stuff as well.
=perf= is very powerful, but annoyingly under-documented. Plenty was written on
the topic, so here I'll mention only some hangups and strange behaviors I've
observed trying to use it. If I figure out enough of this, this could be used to
improve the docs.

For the below I'm using =perf= version 3.16.0 from Debian package
=linux-tools-3.16= version 3.16-2 on an amd64 box running a Debian vanilla
kernel 3.16-3-amd64 package version 3.16.5-1.

*** Basic userspace introspection

Let's say I have a tiny test program: =tst.c=:

#+BEGIN_SRC C
#include <stdio.h>
#include <stdlib.h>

int func(int xxx)
{
    int zzz = xxx;

    printf("zzz: %d\n", zzz);
    return zzz+5;
}
int main(int argc, char* argv[])
{
    int i=0;
    for( i=0; i<10; i++)
        printf("yyy: %d\n", func(argc + i));

    return 0;
}
#+END_SRC

One can run it, and get the obvious results:

#+BEGIN_EXAMPLE
dima@shorty:/tmp$ gcc -g -o tst tst.c && ./tst

zzz: 1
yyy: 6
zzz: 2
yyy: 7
zzz: 3
yyy: 8
zzz: 4
yyy: 9
zzz: 5
yyy: 10
zzz: 6
yyy: 11
zzz: 7
yyy: 12
zzz: 8
yyy: 13
zzz: 9
yyy: 14
zzz: 10
yyy: 15
#+END_EXAMPLE

Building with =-g= is significant since it allows =perf= to read the DWARF
information to know about symbols and variables.

The main command to to manipulate arbitrary probes, such as userspace ones, is
=perf probe=. The main command to get information from each probe hit
individually (instead of as an aggregate) is =perf script=. Let's do some basic
probing: let's see all the function returns from =func=:

#+BEGIN_EXAMPLE
dima@shorty:/tmp$ sudo perf probe -x tst --add 'out=func%return $retval'                         

Added new event:
  probe_tst:out        (on func%return in /tmp/tst with $retval)

You can now use it in all perf tools, such as:

        perf record -e probe_tst:out -aR sleep 1


dima@shorty:/tmp$ sudo perf record -g -e probe_tst:out -aR ./tst      
zzz: 1
yyy: 6
zzz: 2
yyy: 7
zzz: 3
yyy: 8
zzz: 4
yyy: 9
zzz: 5
yyy: 10
zzz: 6
yyy: 11
zzz: 7
yyy: 12
zzz: 8
yyy: 13
zzz: 9
yyy: 14
zzz: 10
yyy: 15
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.712 MB perf.data (~31090 samples) ]


dima@shorty:/tmp$ sudo perf report --stdio                                              

Failed to open /tmp/perf-20159.map, continuing without symbols
# Samples: 10  of event 'probe_tst:out'
# Event count (approx.): 10
#
# Children      Self  Command  Shared Object                 Symbol
# ........  ........  .......  .............  .....................
#
   100.00%     0.00%      tst  libc-2.19.so   [.] __libc_start_main
                |
                --- __libc_start_main

   100.00%   100.00%      tst  tst            [.] main             
                |
                --- main
                    __libc_start_main



dima@shorty:/tmp$ sudo perf script         

Failed to open /tmp/perf-20159.map, continuing without symbols
tst 20159 [001] 629384.650622: probe_tst:out: (400506 <- 400561) arg1=0x6
                  400561 main (/tmp/tst)
            7fda0633eb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)

tst 20159 [001] 629384.650653: probe_tst:out: (400506 <- 400561) arg1=0x7
                  400561 main (/tmp/tst)
            7fda0633eb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)

tst 20159 [001] 629384.650675: probe_tst:out: (400506 <- 400561) arg1=0x8
                  400561 main (/tmp/tst)
            7fda0633eb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)

....
#+END_EXAMPLE

So things basically work. We made a probe called =out= to fire when =func=
returns (=func%return=). We asked to record the actual return value at that time
(=$retval=). The we looked at the aggregate call graph with =perf report=.
Finally, we used =perf script= to look at detailed output for each time we hit
this probe. In particular, we get the return value, given to us as =arg1=.

*** Pitfall: incorrect reading of function argument

Let put in a probe at the start of =func=, and print out the value of the
argument:

#+BEGIN_EXAMPLE

dima@shorty:/tmp$ sudo perf probe -x tst --add 'in=func xxx'                                     

Added new event:
  probe_tst:in         (on func in /tmp/tst with xxx)

You can now use it in all perf tools, such as:

        perf record -e probe_tst:in -aR sleep 1


dima@shorty:/tmp$ sudo perf record -g -e probe_tst:in -aR ./tst      
zzz: 1
yyy: 6
zzz: 2
yyy: 7
....


dima@shorty:/tmp$ sudo perf script         

Failed to open /tmp/perf-20159.map, continuing without symbols
tst 20159 [001] 629384.650566: probe_tst:in: (400506) xxx=0
                  400506 func (/tmp/tst)
            7fda0633eb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)

tst 20159 [001] 629384.650639: probe_tst:in: (400506) xxx=1
                  400506 func (/tmp/tst)
            7fda0633eb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)

tst 20159 [001] 629384.650661: probe_tst:in: (400506) xxx=2
                  400506 func (/tmp/tst)
            7fda0633eb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)
....

#+END_EXAMPLE


This is wrong! It says the passed-in value is 0 then 1 then 2. Actually it's 1
then 2 then 3. Let's put in two more probes to examine this:

- Another probe at =func=, but looking at the =di= register. The calling
  convention dictates that this is where the argument would go
- A probe in the middle of =func=, after =zzz= was set. At that point, I'd like
  to look at both =xxx= and =zzz=

We ask =perf= about what it thinks line numbers are in function =func= (line
numbers here are relative to the start of the function not the start of the
file):

#+BEGIN_EXAMPLE
dima@shorty:/tmp$ sudo perf probe -x tst -L 'func'  

<func@/tmp/tst.c:0>
      0  int func(int xxx)
      1  {
      2      int zzz = xxx;
         
      4      printf("zzz: %d\n", zzz);
      5      return zzz+5;
      6  }
         int main(int argc, char* argv[])
         {
             int i=0;
#+END_EXAMPLE

So I place my probe on line 4:

#+BEGIN_EXAMPLE

dima@shorty:/tmp$ sudo perf probe -x tst --add 'inreg=func %di'

Added new event:
  probe_tst:inreg      (on func in /tmp/tst with %di)

You can now use it in all perf tools, such as:

        perf record -e probe_tst:inreg -aR sleep 1


dima@shorty:/tmp$ sudo perf probe -x tst --add 'mid=func:4 xxx zzz'                           

Added new event:
  probe_tst:mid        (on func:4 in /tmp/tst with xxx zzz)

You can now use it in all perf tools, such as:

        perf record -e probe_tst:mid -aR sleep 1


dima@shorty:/tmp$ sudo perf record -g -e probe_tst:inreg,probe_tst:mid -aR ./tst      

zzz: 1
yyy: 6
zzz: 2
yyy: 7
....


dima@shorty:/tmp$ sudo perf script         

dima@shorty:/tmp$ sudo perf script
Failed to open /tmp/perf-20335.map, continuing without symbols
tst 20335 [000] 629951.439663: probe_tst:inreg: (400506) arg1=0x1
                  400506 func (/tmp/tst)
            7f61a293fb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)

tst 20335 [000] 629951.439681: probe_tst:mid: (400517) xxx=1 zzz=1
                  400517 func (/tmp/tst)
            7fffffffe000 [unknown] (/tmp/perf-20335.map)
            7f61a293fb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)

tst 20335 [000] 629951.439720: probe_tst:inreg: (400506) arg1=0x2
                  400506 func (/tmp/tst)
            7f61a293fb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)

tst 20335 [000] 629951.439725: probe_tst:mid: (400517) xxx=2 zzz=2
                  400517 func (/tmp/tst)
            7fffffffe000 [unknown] (/tmp/perf-20335.map)
            7f61a293fb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)

tst 20335 [000] 629951.439733: probe_tst:inreg: (400506) arg1=0x3
                  400506 func (/tmp/tst)
            7f61a293fb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)

tst 20335 [000] 629951.439738: probe_tst:mid: (400517) xxx=3 zzz=3
                  400517 func (/tmp/tst)
            7fffffffe000 [unknown] (/tmp/perf-20335.map)
            7f61a293fb45 __libc_start_main (/lib/x86_64-linux-gnu/libc-2.19.so)
....
#+END_EXAMPLE

Aha. So looking at the register =di= instead of the variable =xxx= makes it
work. Or I can look at the variable a little later; that works too. This is an
easy pitfall to get caught in. I'll try to investigate more and file a bug.

*** Pitfall: rebuilding

When using =perf= to introspect one's own code, you hit another issue early.
Suppose we just did all the probing above. Now we rebuild the program under test
(with or without modifications), and probe again:

#+BEGIN_EXAMPLE
dima@shorty:/tmp$ gcc -g -o tst tst.c

dima@shorty:/tmp$ sudo perf record -g -e probe_tst:inreg,probe_tst:mid -aR ./tst

zzz: 1
yyy: 6
zzz: 2
yyy: 7


dima@shorty:/tmp$ sudo perf report --stdio                                                 

Error:
The perf.data file has no samples!
#+END_EXAMPLE

Whoa! This just worked. What happened? It turns out =perf= records the build-id
that a particular probe corresponds to. So when you rebuild, the build-id
changes, and the probe no longer triggers. I haven't yet seriously looked into
disabling and/or fixing this. The easiest workaround is to simply remove all the
probes with

#+BEGIN_EXAMPLE
sudo perf probe -x tst --del "*"
#+END_EXAMPLE

Then when you re-add the probes, they will use the new build-id. This /really/
needs better handling upstream as well. I'll patch when I get the time.

** DONE Gnuplot for numpy                             :tools:python:data:dev:
   CLOSED: [2015-01-31 Sat 20:24]

#+begin_o_blog_alert info Follow-up posts
I did much more work on this: [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Gnuplot for numpy. For real this time")){/lisp}][Gnuplot for numpy. For real this time]]
#+end_o_blog_alert

I've been using [[http://pdl.perl.org][PDL]] for numerical computation. It works ok, but is crufty and
incomplete in many ways. I'm thus starting to look at numpy as an alternative,
as much as I hate switching languages. Such transitions are full of dealing with
people's NIH ambitions, and one has to pick one's battles. One battle I refuse
to concede is switching away to numpy's preferred NIH plotting system:
matplotlib. I've been using gnuplot for something like 20 years at this point,
and I'm not moving.

Python land appears to have a reasonably functional gnuplot interface:
[[http://gnuplot-py.sourceforge.net/][=gnuplot.py=]]. It works, but is very clunky to use with numpy. So I wrote
[[https://github.com/dkogan/python_gplot][=python_gplot=]], a wrapper around =gnuplot.py= that provides an interface very
similar to my original design for [[https://github.com/dkogan/PDL-Graphics-Gnuplot][PDL::Graphics::Gnuplot]]. Examples (ASCII plots
just as a demo):

#+BEGIN_EXAMPLE
dima@shorty:~/projects/python_gplot$ cat test.py

#!/usr/bin/python2

from numpy import *
from gplot import *

x = arange(100)
y = x ** 2


gplot( x,y, cmd="set terminal dumb" )

g2 = python_gplot("set terminal dumb")
g2.plot({'with': 'lines'},
        y, x)
g2.plot( (x-100, y),
         ({'with': 'lines'},
          -x,y) )




dima@shorty:~/projects/python_gplot$ ./test.py



 100.000 +-+----+-----+------+-----+------+------+-----+------+-----+----+-+
         +      +     +      +     +      +      +     +      +   ++++++   +
  90.000 +-+                                               ++++-++       +-+
         |                                           ++-+++                |
  80.000 +-+                                    +++++                    +-+
         |                                 +++++                           |
  70.000 +-+                          +++++                              +-+
         |                        ++++                                     |
  60.000 +-+                  ++++                                       +-+
  50.000 +-+              ++++                                           +-+
         |            ++++                                                 |
  40.000 +-+        +++                                                  +-+
         |       +++                                                       |
  30.000 +-+   +++                                                       +-+
         |   ++                                                            |
  20.000 +-++                                                            +-+
         |++                                                               |
  10.000 +-+                                                             +-+
         +      +     +      +     +      +      +     +      +     +      +
   0.000 +-+----+-----+------+-----+------+------+-----+------+-----+----+-+
         0     1000  2000   3000  4000   5000   6000  7000   8000  9000  10000




 10000.000 +-+----------+------------+-----------+------------+----------+A+
           ++++         +            +           +            +         AAA+
  9000.000 +-+++                                                       AA+-+
           |   +++                                                   AAA   |
  8000.000 +-+   +++                                               AAA   +-+
           |       +++                                           AAA       |
  7000.000 +-+       +++                                       AAA       +-+
           |           +++                                   AAA           |
  6000.000 +-+            ++                               AA            +-+
  5000.000 +-+              +++                         AAA              +-+
           |                  +++                     AAA                  |
  4000.000 +-+                   +++               AAA                   +-+
           |                       +++           AAA                       |
  3000.000 +-+                        +++     AAA                        +-+
           |                             +AAAA                             |
  2000.000 +-+                         AAAA ++++                         +-+
           |                       AAAA         ++++                       |
  1000.000 +-+                AAAAA                 +++++                +-+
           +          AAAAAAAA       +           +       ++++++++          +
     0.000 AAAAAAAAAAA--+------------+-----------+------------+----------+-+
         -100          -80          -60         -40          -20           0

                                                                                                  


 10000.000 +-+---+------+-----+------+-----+-----+------+-----+------+---+A+
           +     +      +     +      +     +     +      +     +      +  AAA+
  9000.000 +-+                                                         AA+-+
           |                                                         AAA   |
  8000.000 +-+                                                     AAA   +-+
           |                                                     AAA       |
  7000.000 +-+                                                 AAA       +-+
           |                                                 AAA           |
  6000.000 +-+                                             AA            +-+
  5000.000 +-+                                          AAA              +-+
           |                                          AAA                  |
  4000.000 +-+                                     AAA                   +-+
           |                                     AAA                       |
  3000.000 +-+                                AAA                        +-+
           |                              AAAA                             |
  2000.000 +-+                         AAAA                              +-+
           |                       AAAA                                    |
  1000.000 +-+                AAAAA                                      +-+
           +     +    AAAAAAAA+      +     +     +      +     +      +     +
     0.000 AAAAAAAAAAA--+-----+------+-----+-----+------+-----+------+---+-+
           0     10     20    30     40    50    60     70    80     90   100
#+END_EXAMPLE

*** Brief description

Here you can plot into a global =gnuplot= instance using the =gplot()= function.
Or you can create a new instance by instantiating =class python_gplot=. In
either case, you can pass in plot parameters for a single set of data /or/ a
tuple of such parameters if we want to plot multiple pieces of data on the same
plot.

Each set of plot parameters is a list that's an =ndarray= of =y= values or =x=,
=y=. Optionally, the first element of this list can be a =dict= that's passed to
=gnuplot.py= unmodified.

Lastly, arbitrary =gnuplot= commands can be given with

#+BEGIN_SRC python
gplot( ...., cmd="gnuplot command!!!")
#+END_SRC

or in a constructor:

#+BEGIN_SRC python
g = python_gplot("gnuplot command!!!")
#+END_SRC

*** Explained examples

Let's say you have two =ndarray= objects: =x= and =y=.

In its most simple form you can plot =y= versus =x=:

#+BEGIN_SRC python
gplot( x,y )
#+END_SRC

If you want to pick a different terminal, say:

#+BEGIN_SRC python
gplot( x,y, cmd="set terminal dumb" )
#+END_SRC

If you just want to plot =y= against integers, it's even simpler:

#+BEGIN_SRC python
gplot( y )
#+END_SRC

If you want to make such a plot but with points /and/ lines:

#+BEGIN_SRC python
gplot( {'with': 'linespoints'}, y )
#+END_SRC

If you want to plot two curves on the same plot:

#+BEGIN_SRC python
gplot( (x,y),
       ({'with': 'linespoints'}, y,x) )
#+END_SRC

*** Bugs

This is an extremely early alpha. I think it works, but haven't used it very
much yet. I'll improve this as I need features. 3D plotting will happen at some
point (maybe it works already). Also, this is my first python effort, and the
code quality will improve. Documentation is extremely lacking right now. This
will likewise improve as I use this.

*** License

Copyright 2015, Dima Kogan. Distributed under the terms of GNU LGPL, like
=gnuplot.py=

** DONE Bike headlight circuitry                                    :data:EE:
   CLOSED: [2015-02-20 Fri 20:57]

#+begin_o_blog_alert info Follow-up posts
I redid the circuitry: [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Bike headlight circuit continued")){/lisp}][Bike headlight circuit continued]] and [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Bike headlight circuit. Again")){/lisp}][Bike headlight circuit. Again]]
#+end_o_blog_alert

I just bought a bright headlight for my bicycle: [[http://www.dorcy.com/p-594-41-4001-3aa-led-bicycle-light-personal-light.aspx][Dorcy 41-4001]]. It's fairly
bright and beefy, which is good. It also runs on 3 AA alkaline batteries, which
isn't so much. I want to convert this headlight to run on a Li-ion cell instead.
This would give it a longer runtime and make it rechargeable.

*** Overview

Li-ion cells produce a higher voltage than alkaline ones (nominally 3.7V instead
of 1.5V), so this isn't necessarily a drop-in replacement. The headlight uses
the 3 AA cells in series to get 4.5V nominal. The headlight description says

#+BEGIN_EXAMPLE
LED: USA Made CREE XML (T6) High Power White LED
Power Driven:5.0Watt (3.10~3.15V 1500~1600MA  5%)
#+END_EXAMPLE

The [[http://www.cree.com/LED-Components-and-Modules/Products/XLamp/Discrete-Directional/XLamp-XML][LED manufacturer description]] lists a typical forward voltage of 3.1V and a
maximum current of 3A, so this is all consistent.

To replace the power source I need to know how the driving circuit works. I
naively assumed that there's a switching regulator being used, feeding back on
the current to drive the LED efficiently and to maintain a constant current (and
thus constant light output) in a range of voltages. To test this theory I ran
the light from my benchtop power supply instead of the AA batteries. I expected
to see the input current track the input voltage inversely (keeping the input
power roughly constant). Instead, I saw them moving together, with the light
brightness varying noticeably with input voltage. This is what you'd see if
there was a simple resistor used to limit the LED current. Seriously???

*** LED characterization

First, I gather what I know: the LED characteristics themselves. These are on
page 5 of the datasheet linked [[http://www.cree.com/LED-Components-and-Modules/Products/XLamp/Discrete-Directional/XLamp-XML][here]]. I extracted the [[file:files/Dorcylight/diode.dat][i-V data]], and the i-V curve
of the LED under nominal conditions looks like this ([[file:files/Dorcylight/diode.gp][source]]):

#+ATTR_HTML: :width 80%
[[file:files/Dorcylight/cree_characteristics.svg]]

*** Headlight body characterization

The headlight is composed of

- the main housing (contains the LED and the battery pack)
- battery cap (contains ON switch)

The initial assumption was that everything we care about lives in the housing,
so I characterized that first. I scanned a range of input voltages, taking note
of the input currents drawn. Let me assume a trivial resistor-diode driver
circuit and try to fit my [[file:files/Dorcylight/iv_body.dat][observed input i-V data]] ([[file:files/Dorcylight/iv_body.gp][source]])

#+ATTR_HTML: :width 80%
[[file:files/Dorcylight/iv_body.svg]]

I didn't go to the nominal triple-alkaline voltage (4.5V) because my power
supply can't produce more than 3A. The fit isn't perfect, so there's likely
something else going on. The fitted resistor value is 0.28 Ohms! Could this
really be true? The alligator clips could have resistances in this range.
Furthermore, the LED datasheet says that it produces 280 lumens at 0.7A, but we
get this at a very low voltage /and/ the headlight is rated for 220 lumens.
/This/ is a highly inconsistent piece of data. Something else is going on.

*** Headlight body /and/ battery cap characterization

What if the battery cap is more than a dumb switch? It's beefy and sealed, so
there /could/ be something in there. I hooked everything up cables, and scanned
the voltages again. Once again, let me assume a trivial resistor-diode driver
circuit and try to fit my [[file:files/Dorcylight/iv_full.dat][observed input i-V data]] ([[file:files/Dorcylight/iv_full.gp][source]])

#+ATTR_HTML: :width 80%
[[file:files/Dorcylight/iv_full.svg]]

Much better! The inferred resistance is 1.9 Ohms. Low, but I can believe it. The
body was /just/ the LED, and the resistances were my (poor) connections.
Alkalines generally start at around 1.6V, then decay to 1.0V or so as you use
them. Ballpark average: 1.3V, so 3 of those are at ~4V. The data we just
gathered puts this current draw at 600mA, which is a bit below 700mA; this makes
sense since the rated light output is 220 lumens, a bit lower than the 280
lumens we're supposed get at 700mA.

*** Musings

I'm now confident I know what's going on. I'm satisfied that Li-ion won't break
anything, but it will be dim. Li-ion batteries have varying discharge curves;
generally they start at 4.2V or so, then drop to 3.0V-3.5V as you use them. This
will result in a dramatic drop in the current and thus light intensity.

This is just lame. Without regulation the light gets dimmer as the batteries are
used up /and/ it's just inefficient. Taking their nominal operating point of 4V
you get 3.1V in the LED and you throw away 0.9V in the resistor for an
efficiency of ~75%. In this scheme the efficiency gets worse at higher voltages
(brighter light). I guess you could do worse, but it's just dumb.

My particular rechargable plan won't produce great results. I guess I can lower
the resistance by installing something in parallel. Maybe I will, but I will
complain the whole time.

** DONE Bike headlight circuit continued                                 :EE:
   CLOSED: [2015-03-14 Sat 02:34]

#+begin_o_blog_alert info Follow-up posts
I finally laid out a PCB: [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Bike headlight circuit. Again")){/lisp}][Bike headlight circuit. Again]]
#+end_o_blog_alert

In the [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Bike headlight circuitry")){/lisp}][last post]] I complained about the poor regulation of a flashlight I
bought. Apparently I was willing to dump unreasonable amounts of time to right
this wrong, so I bought some parts, hacked them in and I now have a regulated
flashlight driven by a big Li-ion rechargable cell.

The battery is a single 3500 mAh MNKE IMR 26650 cell. Apparently these are
popular in the vaping community. Ok then.

Very little is required to add regulation. I'm using an [[http://www.st.com/web/en/catalog/sense_power/FM142/CL1854/SC1575/PF253333][LED2000]] driver IC to do
all the work. This is a buck switching regulator that feeds back on current in
order to drive an LED with a particular current. The [[file:files/Dorcylight/schematics.pdf][circuit]] I built is the
reference design for this IC. I added a TVS diode to absorb the voltage spikes
that could result if the LED is disconnected as it is being driven; this is a
potentially poor mechanical connection, so this is important. I added a PTC
resistor to protect against short circuits. Furthermore, I'm using a switch
controller IC and a MOSFET to interact with the on/off button. The circuit is
not at all interesting.

What /is/ interesting is the construction. I never built a board, so this is all
free-formed and then encased in hot glue at the end. I'm using 22-gauge magnet
wire for everything. This is nicely thick and low impedance, but stripping it is
a pain in the butt. In fact, this whole free-forming exercise was really
time-consuming, and I don't feel particularly good about the results. The thing
works right now, but I can easily imagine that it'll stop working at any point.
At that point, I could make a PCB to construct something more reliable, but I've
already put way too much time into this, so simply buying another light would be
the answer.

Before I realized that the button assembly in the cap could be opened, all the
circuitry was meant to go in the gap between the battery and the housing:

#+ATTR_HTML: :width 80%
[[file:files/Dorcylight/R0023853.jpg.scaled.jpg]]
#+ATTR_HTML: :width 80%
[[file:files/Dorcylight/R0023862.jpg.scaled.jpg]]

After I figured out that I could get to the on/off button circuitry, I put
everything into the cap:

#+ATTR_HTML: :width 80%
[[file:files/Dorcylight/R0023864.jpg.scaled.jpg]]

Then encase in hot glue, and done:

#+ATTR_HTML: :width 80%
[[file:files/Dorcylight/R0023867.jpg.scaled.jpg]]
#+ATTR_HTML: :width 80%
[[file:files/Dorcylight/R0023868.jpg.scaled.jpg]]

** DONE Linux tracepoints for 32-bit code on a 64-bit kernel      :tools:dev:
   CLOSED: [2015-04-03 Fri 15:28]

So I was trying to use [[http://www.sysdig.org][sysdig]] to see what a Windows application running under
[[http://www.winehq.org][wine]] was doing, and sysdig was telling me nothing about it. A [[https://github.com/draios/sysdig/issues/278][bug report]] and
some investigating yielded the answer: Linux tracepoints do not work for 32-bit
processes running on a 64-bit kernel. As a trivial example, you can build tst.c:

#+BEGIN_SRC C
#include <stdio.h>
#include <stdlib.h>

#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>

int main(int argc, char* argv[])
{
    while(1)
    {
        int fd = open("/dev/null", O_RDONLY);
        close(fd);
        sleep(1);
    }

    return 0;
}
#+END_SRC

natively: =gcc -o tst tst.c=, and sysdig will see the 3 syscalls here just fine.
But building it in 32-bit mode with =gcc -m32 -o tst tst.c= makes sysdig blind.
One doesn't even have to use sysdig. I tried to use tracepoints through the
interface in =/sys= with the same results: events are seen without =-m32=, but
cannot be seen with it:

#+BEGIN_EXAMPLE

root@shorty:/home/dima# cd /sys/kernel/debug/tracing

root@shorty:/sys/kernel/debug/tracing# echo 'syscalls:sys_enter_open' >> /sys/kernel/debug/tracing/set_event 

root@shorty:/sys/kernel/debug/tracing# echo 'common_pid == 16211' > events/syscalls/sys_enter_open/filter

root@shorty:/sys/kernel/debug/tracing# cat trace_pipe
^C

#+END_EXAMPLE

This may or may not be easy to fix, but this rabbithole probably runs deep, so
I'm stopping here.

** DONE Steepest streets in Los Angeles                            :data:GIS:
   CLOSED: [2015-05-03 Sun 00:05]

A century ago, city planners didn't have the restraint that modern planners do,
and as a result some older LA neighborhoods have some exceptionally steep
streets. Random people on the internet usually claim that some combination of
Fargo St, Baxter St (both in Silver Lake) and Eldred St (climbing Mt Washington
from Highland Park) are the steepest, with Eldred barely taking the crown. I've
never seen any justification of this, and being skeptical of things random
people on the internet say, I decided to check.

The basic strategy is the same as the [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Using DEMs to get GPX elevation profiles")){/lisp}][last time]], but using real tools. I want to
get a detailed-enough DEM, and to sample it along given street paths (from [[http://www.openstreetmap.org][OSM]]).
The SRTM data I used the last time isn't detailed enough: the higher-res SRTM
data has cell about 30 meters wide. LA county has a [[http://egis3.lacounty.gov/dataportal/2011/01/26/2006-10-foot-digital-elevation-model-dem-public-domain/][publicly-available dataset]]
with a higher resolution: cells about 3m wide. This should be sufficient.

After downloading the 2GB file, the DEM can be read into [[http://www.qgis.org][QGIS]] by opening the
=dem_10ft/hdr.adf= file as a raster layer. Note that it takes QGIS a bit of time
to load the whole thing. The =Quick OSM= plugin works reasonably well to import
OSM data into QGIS (can be installed through the Plugin manager in the =Plugins=
directory in QGIS). Once the DEM and the street geometry are loaded, we can
generate the elevation profile. There are several plugins that do this. With
some coaxing, I was able to get the "Profile tool" plugin to do what I needed
here.

*** Results

I checked Eldred, Fargo and Baxter. The term "steepest street" is
poorly-defined, so based on a completely arbitrary measure or "steepest over a
reasonable length" we have

- Eldred and Fargo tied for 1st
- Baxter 3rd

The sampled elevation-vs-horizontal travel data is here (everything in ft):

- [[file:files/la_hills/eldred.dat][Eldred]]
- [[file:files/la_hills/fargo.dat][Fargo]]
- [[file:files/la_hills/baxter.dat][Baxter]]

The elevation profiles for the 3 streets in their steepest sections looks like
this (Baxter, Fargo starting at the 2 fwy, and going East; [[file:files/la_hills/profiles_full.gp][source]]):

#+ATTR_HTML: :width 80%
[[file:files/la_hills/profiles_full.svg]]

We can see that as you travel West from Ave 50, Eldred St loses elevation, and
then regains it quickly, getting more steep as it goes. We can also see that
while the steepest section of Fargo is a bit steeper than Baxter, Baxter keeps
going and has several more slightly-less-steep bumps.

If we plot the steepest sections of all 3 streets on top of one another, we get
this ([[file:files/la_hills/profiles_relative.gp][source]]):


#+ATTR_HTML: :width 80%
[[file:files/la_hills/profiles_relative.svg]]

Once again, Fargo is steeper than Baxter. The steepest section of Fargo is very
similar to Eldred, but Fargo retains is steepness longer than Eldred does.

One could try to split hairs about whether Fargo or Baxter are steeper, but
based on this data, they're even for all purposes.

Clearly this all is only valid if the source data is valid. It looks mostly
reasonable. The DEM is detailed enough to show each street in a little valley,
and this aligns well with Eldred. Fargo and Baxter lie in an area with a natural
valley, but the street alignment ignores it cutting at an angle, which is
consistent with the USGS topo. The absolute heights are fairly consistent with
the USGS topo. I believe these results.

It's also possible that there's some other candidate steep street out there.
Some random internet person claimed 28th Street in San Pedro had a steep
section, but none was comparable to these 3. This is good enough for me and I'm
stopping here.


** DONE Poles of Inaccessibility in the San Gabriel Mountains :hiking:data:GIS:
   CLOSED: [2015-05-06 Wed 17:04]

So I was out hiking with a friend, and a question came up about where the least
accessible point of the San Gabriel Mountains was, with "accessible" defined as
having a road or trail nearby. I decided to answer this question. The resulting
code is in a fresh repository: [[https://github.com/dkogan/inaccessibility]].

This is called the [[http://en.wikipedia.org/wiki/Pole_of_inaccessibility][Pole of Inaccessibility]]: a point that is as far away as
possible from a given set of objects. Locations of such poles are known for the
most landlocked spot on earth or most far away from land. Here we limit
ourselves to the San Gabriel Mountains, and try to stay away from roads and
trails.

*** Approach

**** Input data processing

[[http://www.openstreetmap.org][OpenStreetMap]] has open data I can use to map out all the roads and trails. This
is the input dataset.

For 2D geometry, the best approach to compute the Pole of Inaccessibility
appears to be to construct a [[http://en.wikipedia.org/wiki/Voronoi_diagram][Voronoi diagram]] of the geometry we're trying to
stay away from, and to find the Voronoi vertex corresponding to the
furthest-away point.

Our world is not 2D. Instead, it has varying elevation sitting on top of an
ellipsoid. The grand purpose here is to compute a location that hardy people can
visit and to tell everybody they did it, so extreme accuracy is not required.
Thus I claim that assuming the world is locally-flat and using the
Voronoi-diagram-based method is sufficient. So I construct a plane that best
describes my query area and project all my input points to this plane. I use a
plane that is tangent to the Earth's surface at the center of the query area.
This clearly wouldn't work if trying to find the pole of inaccessibility of
something as large as an ocean, for instance, but it works here.

To compute the tangent plane, I assume the Earth is spherical. As I move along
the tangent plane away from the point of tangency, the elevation error grows:

 E = sqrt(R_earth^2 + d^2) - R_earth

The San Gabriels are about 80km across, and the tangent plane sits in the
middle, so at worst d = 40km and the error is about 125m. That's plenty good
enough. Plot ([[file:files/inaccessibility/plot_flat_earth_error.gp][source]]):

[[file:files/inaccessibility/plot_flat_earth_error.svg]]

I ignore the ellipsoid shape of the Earth outright. I ignore the topography as
well, since including it in my distance metrics would require a fancier
algorithm than making a Voronoi diagram, and it would make the notion of
"inaccessibility" more ambiguous.

**** Pole of Inaccessibility computation

I want to use the most basic Voronoi algorithm, so I represent my input as a set
of points only; no line segments. To get reasonable accuracy, I make sure to
sample each road at least every 100m.

Now that I have my set of dense-enough points in 2D, I construct the Voronoi
diagram. Without constraints the furthest-away point would be infinitely far off
to one side, so generally people constrain the solution to lie within the convex
hull of the input points. This means that the Pole of Inaccessibility lies
either on a Voronoi vertex or at an intersection of a Voronoi edge and the
convex hull of the input. In my case there are generally more roads at the edges
of my query area that in the interior (less stuff in the mountains than in the
flats), so I simply assume that the Pole of Inaccessibility is not on the convex
hull. This simplifies my implementation since I simply ignore all the Voronoi
vertices that are outside of the query region.

So I need to look at every Voronoi vertex, check the distance between it and an
adjacent input point, and return the vertex with the largest such distance.

*** Implementation

Each step in the process lives in its own program. This simplifies
implementation and makes it easy to work on each piece separately.

**** Data import

First we query OSM. This is done with the =query.sh= script. It takes in corners
of the query area, constructs the query, sends it off to the server, and stores
the result. =query.sh= takes 4 arguments; lat0, lon0, lat1, lon1, and stores its
output in a file called =query_$lat0_$lon0_$lat1_$lon1.json=. The query uses the
[[http://wiki.openstreetmap.org/wiki/Overpass_API/Overpass_QL][OSM Overpass query language]]. By default I simply look at all the roads, trails
(everything with a =highway= tag):

#+BEGIN_EXAMPLE
[out:json];

way ["highway"] ($lat0,$lon0,$lat1,$lon1);

(._;>;);

out;
#+END_EXAMPLE

If I want to only consider roads in my computation (allow trails), then I can
exclude trails from the query:

#+BEGIN_EXAMPLE
[out:json];

way ["highway"] ["highway" != "footway" ] ["highway" != "path" ] ($lat0,$lon0,$lat1,$lon1);

(._;>;);

out;
#+END_EXAMPLE

Sample invocation:

#+BEGIN_EXAMPLE
$ ./query.sh 34.1390884 -118.4944153 34.5020298 -117.5852966

  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 28.3M    0 28.3M    0   138  72803      0 --:--:--  0:06:48 --:--:--  138k


$ ls -lh query*

-rw-r--r-- 1 dkogan dkogan 29M May  6 04:12 query_34.1390884_-118.4944153_34.5020298_-117.5852966.json
#+END_EXAMPLE

**** Data massaging

Next, I take the lat/lon pairs, map them to the tangent plane and make sure the
data is sufficiently dense. This is done by the =massage_input.pl= script. It
takes in the =query_....json= file we just obtained, and generates a
=points_$lat0_$lon0_$lat1_$lon1.dat= file that is a list of (x,y) tuples in my
plane. There's a small header of 4 values, representing the bounds of my data so
that I can reject outlying vertices, as described earlier.

Sample invocation:

#+BEGIN_EXAMPLE
$ ./massage_input.pl query_34.1390884_-118.4944153_34.5020298_-117.5852966.json


$ ls -lh points*

-rw-r--r-- 1 dkogan dkogan 4.3M May  6 04:20 points_34.1390884_-118.4944153_34.5020298_-117.5852966.dat
#+END_EXAMPLE

**** Pole of Inaccessibility computation

Now we can compute the Voronoi diagram. I use [[http://www.boost.org/doc/libs/1_57_0/libs/polygon/doc/index.htm][boost::polygon]] to do this. I had
concerns that this step would be prohibitively slow, but the algorithm and this
implementation are quick-enough such that this "just works".

The =points_....dat= file is inputs on standard input. Note that this is
different from the other tools that read a file on the commandline instead.

For each Voronoi vertex I get an arbitrary neighboring edge, and an arbitrary
neighboring cell. The distance between the vertex and the cell center is
identical for any such edge, cell by definition of a Voronoi vertex. I keep
track of the cell with the largest distance between the vertex and the cell
center, and I report the vertex with the largest such distance as my Pole of
Inaccessibility.

Sample invocation:

#+BEGIN_EXAMPLE
$ ./voronoi < points_34.1390884_-118.4944153_34.5020298_-117.5852966.dat 

furthest point center, surrounding points:
25541 -78
25308 4259
21223 -543
26931 -4192
distance: 4342.873206
#+END_EXAMPLE

Bam! So the Pole of Inaccessibility is about 4.3 km from the nearest trail/road.
The coordinates here are in my 2D tangent plane, which isn't super useful. Now I
convert them to lat/lon and I'm done.

**** Unmapping the planar coordinates

I do this with the massaging script as before simply by passing the coords in on
the commandline:

#+BEGIN_EXAMPLE
$ ./massage_input.pl query_34.1390884_-118.4944153_34.5020298_-117.5852966.json 25541 -78 25308 4259 21223 -543 26931 -4192

34.3206972918426,-117.761740671673
34.3597096140465,-117.764149633831
34.3165155855012,-117.808770212857
34.2837076589351,-117.746734473897
#+END_EXAMPLE

OK. Done.

*** Results

I did this twice: once avoiding all roads, trails and again avoiding roads only.
Both Poles of Inaccessibility are above the East Fork of the San Gabriel River,
by Ross Mountain:

| pole         | lat,lon               | distance to nearest (m) |
|--------------+-----------------------+-------------------------|
| roads,trails | 34.3206973,-117.76174 |                    4343 |
| roads only   | 34.3107784,-117.74736 |                    5677 |

This is shown nicely on the map:

http://caltopo.com/m/4N7A

[[file:files/inaccessibility/poles.png]]

Looks like the bounding spots for the roads,trails point are the road up to
South Mt Hawkins, the PCT on top of Mt. Baden-Powell and the trail at the Bridge
to Nowhere.

The bounding spots for the roads-only point is the same road up to South Mt
Hawkins, the Cabin Flat Campground and Shoemaker Canyon Road.

** DONE Gnuplot for numpy. For real this time         :tools:python:data:dev:
   CLOSED: [2015-07-02 Thu 15:05]

In the [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Gnuplot for numpy")){/lisp}][last post]] I talked about a gnuplot backend for numpy to make it possible
to live without matplotlib. I just did quite a bit of work to port my [[https://github.com/dkogan/PDL-Graphics-Gnuplot][PDL
plotting library]] to python and numpy. The result: [[https://github.com/dkogan/gnuplotlib][gnuplotlib]]. This is a fairly
direct port, so the API and the design goals are similar. The module tries to be
a thin shim between python and gnuplot, so if the user wants to do something
fancy, they should read the gnuplot docs to figure out how to get the fancy
thing done, and then communicate it to gnuplotlib. I see this as a good thing.
Some basic examples from the main documentation:

#+BEGIN_SRC python
 import numpy      as np
 import gnuplotlib as gp
 from scipy.constants import pi

 x = np.arange(101) - 50
 gp.plot(x**2)
 [ basic parabola plot pops up ]


 g1 = gp.gnuplotlib(title = 'Parabola with error bars',
                    _with = 'xyerrorbars')
 g1.plot( x**2 * 10, np.abs(x)/10, np.abs(x)*5,
          legend    = 'Parabola',
          tuplesize = 4 )
 [ parabola with x,y errobars pops up in a new window ]


 x,y = np.ogrid[-10:11,-10:11]
 gp.plot( x**2 + y**2,
          title     = 'Heat map',
          cmds      = 'set view map',
          _with     = 'image',
          tuplesize = 3)
 [ Heat map pops up where first parabola used to be ]


 theta = np.linspace(0, 6*pi, 200)
 z     = np.linspace(0, 5,    200)
 g2 = gp.gnuplotlib(_3d = True)
 g2.plot( (np.cos(theta),  np.sin(theta), z),
          (np.cos(theta), -np.sin(theta), z))
 [ Two 3D curves together in a new window: spirals ]
#+END_SRC

See the main docs for more. During the course of this exercise I now have a
fully-formed opinion of python from a perl perspective (meh). And one of numpy
from a PDL perspective (also meh). But at least they're now "standard" for some
meaning of that word, so we'll see.

** DONE Validating a CRC computation on an AVR                       :dev:EE:
   CLOSED: [2015-08-01 Sat 16:38]

Recently I implemented a self-reprogramming feature for an AVR XMEGA-E5 cpu.
Naturally one wants to have some validation logic to make sure that what was
burned to the flash is right. This is a common want, so Atmel implemented in
hardware a chunk of logic to compute the CRC checksum of a block of flash
memory. This is nice. What is less nice is their documentation, which is lacking
to put it nicely. To use their hardware CRC, I need to make sure it matches a
CRC that I compute in software. This was needlessly difficult, and hopefully
this will serve as a guide for somebody in the future.

The AVR supports a CRC16 checksum (CCITT) and a CRC32 checksum (IEEE 802.3). I
use the bigger 32-bit checksum here.

The *XMEGA E MANUAL* describes in section "29.11.2.6" how to compute the CRC of
a block of flash memory. It says

#+BEGIN_EXAMPLE
The CRC checksum will be available in the NVM DATA register
#+END_EXAMPLE

This is a lie. On my partiular CPU, there are 24 bits worth of NVM.DATA, so this
cannot be true for a 32-bit checksum. The checksum /really/ ends up in the
CRC.CHECKSUM registers.

In Section 24.3 the manual says

#+BEGIN_EXAMPLE
when CRC-32 polynomial is used, the final checksum read is bit reversed and complemented

#+END_EXAMPLE

I'm not 100% sure what's going on here; I /think/ that "bit reversed and
complemented" simply means "binary NOT", but I'm not certain. In any case, there
also seems to be a difference in behavior if we're checksumming flash memory
(=CRC_SOURCE_FLASH_gc=) or if we're looking at =CRC.DATAIN= input
(=CRC_SOURCE_IO_gc=).

By default, the CRC module resets from zero. However to match other CRC32
implementations, it is apparently necessary to reset from 1 instead
(=CRC_RESET_RESET1_gc=). Oh, and this reset must happen /before/ the CRC module
is turned on.

Section 24.7.2 says

#+BEGIN_EXAMPLE
When running CRC-32 and appending the checksum at the end
of the packet (as little endian), the final checksum should be 0x2144df1c, and
not zero. However, if the checksum is complemented before it is appended (as
little endian) to the data, the final result in the checksum register will be
zero
#+END_EXAMPLE

This is a lie also. The constant 0x2144df1c is indeed there. However if you
append a complemented (meaning binary NOT instead of a 2-complement) CRC then
you get 0xFFFFFFFF and not 0.

So in the end, if I have a flash of size =SIZE_APP_FLASH_BYTES=, then I compute
the CRC32 of the first =SIZE_APP_FLASH_BYTES-4= bytes, and append a binary NOT
of this CRC to the end. I can then validate by making sure that this CRC matches
0xFFFFFFFF. On the AVR:

#+BEGIN_SRC C

  bool CRC_matches(void)
  {
      CRC.CTRL |= CRC_RESET_RESET1_gc;
      CRC.CTRL  = CRC_CRC32_bm | CRC_SOURCE_FLASH_gc;
      nvm_issue_flash_range_crc(0, SIZE_APP_FLASH_BYTES-1);
      nvm_wait_until_ready();
      while( CRC.STATUS & CRC_BUSY_bm ) ;

      return
        CRC.CHECKSUM0 == '\xFF' &&
        CRC.CHECKSUM1 == '\xFF' &&
        CRC.CHECKSUM2 == '\xFF' &&
        CRC.CHECKSUM3 == '\xFF';
  }

#+END_SRC

When preparing this image, I have perl pad, compute the CRC, binary-NOT and
append:

#+BEGIN_SRC perl
use Digest::CRC 'crc32';

sub prepareImage
{
    my ($rawimage) = @_;

    my $Npad = $SIZE_APP_FLASH_BYTES-4 - length($rawimage);
    my $ff   = pack('C', 0xFF);
    my $pad  = $ff x $Npad;

    my $crc = crc32($rawimage . $pad);
    return $rawimage . $pad . pack('V', 0xFFFFFFFF & ~$crc);
}

#+END_SRC

** DONE Rendering OpenStreetMap tiles in gnuplot         :tools:data:GIS:dev:
   CLOSED: [2015-08-13 Thu 00:39]

I use gnuplot heavily to plot things. I also use OpenStreetMap heavily to map
other things. Sometimes I want to draw a map using OSM tiles, and to plot
something on top of it. Gnuplot has the core functionality, but some glue code
needs to be written to actually make this available. I just wrote this glue
code, and it lives in a new repository: https://github.com/dkogan/osmgnuplot

The repository contains the documentation and usage examples. The [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Least convenient location in Los Angeles (from Koreatown)")){/lisp}][next post]] uses
this extensively to visualize mapping data.

** DONE Least convenient location in Los Angeles (from Koreatown) :biking:data:GIS:
   CLOSED: [2015-08-16 Sun 00:10]

Talking to a friend, a question came up about finding the point in LA's road
network that's most inconvenient to get to, with /inconvenient/ being a vague
notion describing a closed residential neighborhood full of dead ends; the
furthest of these dead ends would be most inconvenient indeed. I decided to
answer that question. All the code lives in a new repo:
https://github.com/dkogan/culdesacs

I want /inconvenient/ to mean

#+BEGIN_QUOTE
Furthest to reach via the road network, but nearest as-the-crow-flies.
#+END_QUOTE

Note that this type of metric is not a universal one, but is relative to a
particular starting point. This makes sense, however: a location that's
inconvenient from one location could be very convenient from another.

This metric could be expressed in many ways. I keep it simple, and compute a
relative inefficiency coefficient:

[[file:files/culdesacs/coeff_define.png]]

# o-blog v1 can only export equations as mathjs, but I want a JS-less page. I
# just rendered the below (C-c C-x C-l) and copied the image manually
# \[
# c_\mathrm{inefficiency} \equiv \frac{d_\mathrm{road} - d_\mathrm{direct}}{d_\mathrm{direct}}
# \]

Thus the goal is to find a location within a given radius of the starting point
that maximizes this relative inefficiency.

*** Approach

I use [[http://www.openstreetmap.org][OpenStreetMap]] for the road data. This is all aimed at bicycling, so I'm
looking at all roads except freeways and ones marked private. I /am/ looking at
footpaths, trails, etc.

Once I have the road network, I run [[https://en.wikipedia.org/wiki/Dijkstra's_algorithm][Dijkstra's Algorithm]] to compute the shortest
path from my starting point to every other point on the map. Then I can easily
compute the inefficiency for each such point, and pick the point with the
highest inefficiency. I use OSM nodes as the "points". It is possible that the
location I'm looking for is inbetween a pair of nodes, but the nodes will really
be close enough. Also, the "distance" between adjacent nodes can take into
account terrain type, elevation, road type and so on. I ignore all that, and
simply look at the distance.

*** Implementation

Each step in the process lives in its own program. This simplifies
implementation and makes it easy to work on each piece separately.

**** Data import

First I query OSM. This is done with the =query.pl= script. It takes in the
center point and the query radius. The query uses the [[http://wiki.openstreetmap.org/wiki/Overpass_API/Overpass_QL][OSM Overpass query
language]]. I use this simple query, filling in the center point and radius:

#+BEGIN_EXAMPLE
[out:json];

way
 ["highway"]
 ["highway" !~ "motorway|motorway_link" ]
 ["access" !~ "private" ]
 ["access" !~ "no" ]
 (around:$rad,$lat,$lon);

(._;>;);

out;
#+END_EXAMPLE

Sample invocation:

#+BEGIN_EXAMPLE
$ ./query.pl --center 34.0690448,-118.292924 --rad 20miles
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  .....

$ ls -lhrt *(om[1])
-rw-r--r-- 1 dima dima 81M Aug 14 00:44 query_34.0690448_-118.292924_20miles.json

#+END_EXAMPLE

**** Data massaging

Now I need to take the OSM query results, and manipulate them into a form
readable by the Dijkstra's algorithm solver. This is done by the
=massage_input.pl= script. This script does nothing interesting, but it doesn it
inefficiently, so it's CPU and RAM-hungry and takes a few minutes. Sample
invocation:

#+BEGIN_EXAMPLE
$ ./massage_input.pl query_34.0690448_-118.292924_20miles.json > query_34.0690448_-118.292924_20miles.net
#+END_EXAMPLE

***** Neighbor list representation

An implementation choice here was how to represent the neighbor list for a node.
I want the main computation (next section) to be able to query this very
quickly, and I don't want the list to take much space, and I don't want to
fragment my memory with many small allocations. Thus I have a single contiguous
array of integers =neighbor_pool=. Each node has a single integer index into
this pool. At this index the =neighbor_pool= contains a list of node indices
that are neighbors of the node in question. A special node index of -1 signifies
the end of the neighbor list for that node.

**** Inefficiency coefficient computation

I now feed the massaged data to Dijkstra's algorithm implemented in =compute.c=.
I need a priority queue where elements can be inserted, removed and updated.
Apparently most heap implementations don't have an 'update' mechanism, so it
took a little while to find a working one. I ended up using [[https://en.wikipedia.org/wiki/B-heap][phk's b-heap]]
implementation from the [[https://www.varnish-cache.org/trac/browser/lib/libvarnish/binary_heap.c][varnish source tree]]. It stores arbitrary pointers
(64-bit on my box); 32-bit indices into a pool would be more efficient, but this
is fast enough.

Sample invocation:

#+BEGIN_EXAMPLE
$ ./compute < query_34.0690448_-118.292924_20miles.net > query_34.0690448_-118.292924_20miles.out

$ head -n 2 query_34.0690448_-118.292924_20miles.out
34.069046 -118.292923 0.000000 0.000000
34.070034 -118.292931 109.863564 109.863564
#+END_EXAMPLE

The output is all nodes, sorted by the road distance to the node. The columns
are lat,lon,d_road,d_direct.

***** Distance from latitude/longitude pairs

One implementation note here is how to compute the distance between two
latitude/longitude pairs. The most direct way is to convert each
latitude/longitude pair into a unit vector, compute the dot product, take the
arccos and multiply by the radius of the Earth. This requires 9 trigonometric
operations and relies on the arccos of a number close to 1, which is inaccurate.
One could instead compute the arcsin of the magnitude of the cross-product, but
this requires even more computation. I want something simpler:

[[file:files/culdesacs/latlon_distance_approx.png]]

# As before, this is a render of...
#
# \begin{align*}
# d &= R_\mathrm{earth} \alpha \\
# \\
# \theta &\equiv \mathrm{longitude} \\
# \phi &\equiv \mathrm{latitude} \\
# \\
# \cos(\alpha) &= \vec v_0 \cdot \vec v_1 = \\
# &= \left[ \begin{matrix}
#  \cos(\theta_0) \cos(\phi_0) \\
#  \sin(\theta_0) \cos(\phi_0) \\
#  \sin(\phi_0) \\
# \end{matrix} \right] \cdot
# \left[ \begin{matrix}
#  \cos(\theta_1) \cos(\phi_1) \\
#  \sin(\theta_1) \cos(\phi_1) \\
#  \sin(\phi_1)
# \end{matrix} \right] = \\
# &= \cos(\phi_0) \cos(\phi_1) \left( \cos(\theta_0) \cos(\theta_1) + \sin(\theta_0) \sin(\theta_1) \right) + \sin(\phi_0) \sin(\phi_1) = \\
# &= \cos(\phi_0) \cos(\phi_1) \cos(\Delta_\theta) + \sin(\phi_0) \sin(\phi_1) \\
# \\
# \cos(\Delta_\theta) & \approx 1 - {\Delta_\theta^2 \over 2} \rightarrow \\
# \cos(\alpha) & \approx \cos(\phi_0) \cos(\phi_1) + \sin(\phi_0) \sin(\phi_1) - {\Delta_\theta^2 \over 2} \cos(\phi_0) \cos(\phi_1) = \\
# &= \cos(\Delta_\phi) - {\Delta_\theta^2 \over 2} \cos(\phi_0) \cos(\phi_1) \approx \\
# & \approx 1 - {\Delta_\phi^2 \over 2} - {\Delta_\theta^2 \over 2} \cos(\phi_0) \cos(\phi_1) \\
# \\
# \cos(\alpha) & \approx 1 - {\alpha^2 \over 2} \rightarrow \\
# \alpha^2 & \approx \Delta_\phi^2 + \Delta_\theta^2 \cos(\phi_0) \cos(\phi_1) \\
# \\
# \alpha & \approx \sqrt{\Delta_\phi^2 + \Delta_\theta^2 \cos(\phi_0) \cos(\phi_1)}
# \end{align*}


This is nice and simple. Is it sufficiently accurate? This python script tests
it:

#+BEGIN_SRC python
import numpy as np
lat0,lon0 = 34.0690448,-118.292924  # 3rd/New Hampshire
lat1,lon1 = 33.93,-118.4314         # LAX

lat0,lon0,lat1,lon1 = [x * np.pi/180.0 for x in lat0,lon0,lat1,lon1]

Rearth = 6371000

v0 = np.array((np.cos(lat0)*np.cos(lon0), np.cos(lat0)*np.sin(lon0),np.sin(lat0)))
v1 = np.array((np.cos(lat1)*np.cos(lon1), np.cos(lat1)*np.sin(lon1),np.sin(lat1)))

dist_accurate = np.sqrt( (lat0-lat1)**2 + (lon0-lon1)**2 * np.cos(lat0)*np.cos(lat1) ) * Rearth
dist_approx   = np.arccos(np.inner(v0,v1)) * Rearth

print dist_accurate
print dist_approx
print dist_accurate - dist_approx
#+END_SRC

Between Koreatown and LAX there's quite a bit of difference in both latitude and
longitude. Both methods say the distance is about 20km, with a disagreement of
3mm. This is plenty good enough.

*** Results

I want to find the least convenient location from the intersection of New
Hampshire and 3rd street in Los Angeles within 20 miles or so.

All the inconvenience coefficients computed from this data look like this ([[file:files/culdesacs/all_coefficients.gp][source]]):

[[file:files/culdesacs/all_coefficients.png]]

As expected, straight roads away from the starting point are highly efficient,
and we see this in the Vermont corridor, 3rd street, and to a lesser extent 6th
street going East. Also as expected, routes that do not align with the street
grid are inefficient: we see inefficiency bumps going NW and SW from the
starting point. Eastward from the start the street grid tilts, so things are
more complicated in that direction.

We also see that hilly neighborhoods stand out: winding streets are not
efficient. The Santa Monica mountains, Verdugos, Mount Washington and the San
Gabriel Mountains clearly stand out. One can also make out the river paths in
the bottom-right as ridges of inconvenience: their limited access nature makes
it necessary to travel longer distance to get to them.

Onwards. The output of =compute= is sorted by road distance from the start. I
prepend the coefficient of inconvenience, re-sort the list and take 50 most
inconvenient locations by invoking

#+BEGIN_EXAMPLE
$ <query_34.0690448_-118.292924_20miles.out
   awk '$4 {printf "%f %f %f %f %f\n",($3-$4)/$4,$1,$2,$3,$4}' |
   sort -n -k1 -r | head -n 50
#+END_EXAMPLE

The output is this:

| Inconvenience |  Latitude |   Longitude | Road distance (m) | Direct distance (m) |
|---------------+-----------+-------------+-------------------+---------------------|
|      1.142052 | 34.068104 | -118.290382 |        549.216980 |          256.397583 |
|      1.139839 | 34.071629 | -118.288956 |        994.499390 |          464.754242 |
|      1.139147 | 34.068066 | -118.290436 |        542.721497 |          253.709305 |
|      1.136799 | 34.068130 | -118.290329 |        554.962891 |          259.716919 |
|      1.127631 | 34.068031 | -118.290466 |        537.980652 |          252.854279 |
|      1.120537 | 34.068153 | -118.290253 |        562.437012 |          265.233337 |
|      1.106771 | 34.067982 | -118.290504 |        531.442017 |          252.254257 |
|      1.103518 | 34.068169 | -118.290184 |        568.985352 |          270.492218 |
|      1.083344 | 34.067940 | -118.290527 |        526.321899 |          252.633179 |
|      1.079027 | 34.068176 | -118.290100 |        576.762024 |          277.419189 |
|      1.041816 | 34.067883 | -118.290543 |        519.805908 |          254.580200 |
|      1.034252 | 34.070259 | -118.291237 |        418.454498 |          205.704315 |
|      1.019096 | 34.071594 | -118.287888 |       1097.392212 |          543.506653 |
|      0.974731 | 34.068214 | -118.289680 |        617.407532 |          312.654022 |
|      0.970095 | 34.068176 | -118.289719 |        611.899475 |          310.593842 |
|      0.917598 | 34.068111 | -118.289383 |        656.267517 |          342.234131 |
|      0.910048 | 34.068165 | -118.289383 |        650.329041 |          340.477783 |
|      0.902491 | 34.068214 | -118.289383 |        644.814758 |          338.931915 |
|      0.770809 | 34.067570 | -118.290543 |        485.023560 |          273.899414 |
|      0.760711 | 34.068214 | -118.288643 |        712.981384 |          404.939484 |
|      0.753344 | 34.068214 | -118.288597 |        717.197876 |          409.045654 |
|      0.750541 | 34.033188 | -118.279716 |       7297.569824 |         4168.751465 |
|      0.747349 | 34.031826 | -118.279968 |       7526.415039 |         4307.333008 |
|      0.743357 | 34.067772 | -118.289474 |        606.347107 |          347.804382 |
|      0.741902 | 34.067787 | -118.289436 |        610.249084 |          350.334900 |
|      0.740024 | 34.067749 | -118.289505 |        602.555115 |          346.291290 |
|      0.739944 | 34.031769 | -118.279823 |       7511.619141 |         4317.161621 |
|      0.738388 | 34.031582 | -118.280746 |       7499.802734 |         4314.228516 |
|      0.737889 | 34.067795 | -118.289398 |        613.863831 |          353.223755 |
|      0.737716 | 34.031742 | -118.279800 |       7507.977051 |         4320.601562 |
|      0.736297 | 34.031372 | -118.280258 |       7550.486816 |         4348.613770 |
|      0.735083 | 34.068108 | -118.288734 |        693.459473 |          399.669403 |
|      0.734607 | 34.067730 | -118.289520 |        600.010803 |          345.905945 |
|      0.732851 | 34.031685 | -118.279747 |       7499.933105 |         4328.088379 |
|      0.730817 | 34.067795 | -118.289352 |        618.080322 |          357.103241 |
|      0.730543 | 34.031654 | -118.279732 |       7496.259766 |         4331.739746 |
|      0.728622 | 34.031628 | -118.279724 |       7493.208496 |         4334.787109 |
|      0.727123 | 34.067707 | -118.289536 |        597.103455 |          345.721344 |
|      0.726802 | 34.031601 | -118.279724 |       7490.239258 |         4337.637207 |
|      0.724309 | 34.031563 | -118.279739 |       7485.770508 |         4341.315430 |
|      0.723138 | 34.067791 | -118.289307 |        622.318115 |          361.153992 |
|      0.722826 | 34.031540 | -118.279755 |       7482.862793 |         4343.366211 |
|      0.722384 | 34.094849 | -118.236145 |      10273.032227 |         5964.425293 |
|      0.721979 | 34.094719 | -118.235779 |      10309.708008 |         5987.128906 |
|      0.721011 | 34.094639 | -118.235474 |      10339.187500 |         6007.625977 |
|      0.720812 | 34.094620 | -118.235405 |      10345.856445 |         6012.193359 |
|      0.720105 | 34.031498 | -118.279778 |       7477.742188 |         4347.258789 |
|      0.720078 | 34.094543 | -118.235138 |      10371.867188 |         6029.880859 |
|      0.719789 | 34.031509 | -118.279755 |       7475.278809 |         4346.624512 |
|      0.719616 | 34.095020 | -118.236320 |      10248.023438 |         5959.484863 |


There are 3 clusters of data. All the stuff < 500m away from the start is mostly
degenerate and uninteresting ([[file:files/culdesacs/montage_34.0691_-118.290_300m_16.gp][source]]):

[[file:files/culdesacs/atstart.png]]

Most of the points are in walkways in Shatto Recreation Center. They're all so
close to the start that any inefficiency is exaggerated by the small direct
distance. I make the rules, so I claim these aren't the least convenient point.


Next we have the points about 4.2km away as the crow flies ([[file:files/culdesacs/montage_34.0324_-118.280_50m_18.gp][source]]):

[[file:files/culdesacs/atsaintjamespark.png]]

These all appear in an improperly-mapped group of sidewalks around Saint James
park: http://www.openstreetmap.org/#map=18/34.03173/-118.27892.

Here the sidewalks appear as separate ways that don't connect with the roads
they abut. So according to the data, connecting to the network of sidewalks can
only happen in one location, making these appear less convenient than they
actually are. (I think these should be removed from OSM, but it looks like the
OSM committee people think that mapping sidewalks as separate ways is
acceptable. OK; it'll be fixed eventually in some way).

The next cluster of data is about 6km away as the crow flies ([[file:files/culdesacs/montage_34.094719_-118.235779_300m_16.gp][source]]):

[[file:files/culdesacs/attayloryard.png]]

These are all at the road connecting to the Metrolink maintenance facility at
Taylor Yard: http://www.openstreetmap.org/#map=17/34.09371/-118.23463. This
makes sense! This location is on the other side of the LA river from Koreatown,
so getting here requires a lengthy detour to the nearest bikeable bridge. The
nearest one (Riverside Drive) is 2.5km by road away, but this is in the opposite
direction from Koreatown. The nearest one in the other direction is Fletcher
Drive, 3.8km by road.

So the least convenient point from New Hampshire / 3rd is at lat/lon
34.094849,-118.236145. This location is 10.3km away by road, but only 6.0km as
the crow flies, for an inconvenience coefficient of 0.72.

** DONE A Kernel Debugging Story                                  :tools:dev:
   CLOSED: [2015-09-05 Sat 14:50]

I was asked by a client to investigate an issue they observed where the
performance of some hardware became dramatically degraded after a kernel update
on the server this hardware was connected to. This device is an external unit
that communicates with the server using an FTDI usb-serial converter. The
program running on the server that talks to this device is a proprietary binary
blob I'll call the =frobnicator=. This blob came from some vendor, and the
client did not have access to sources, or had any real idea about how this
=frobnicator= communicates or what it expects.

For years they were using a stock Linux 3.5 kernel shipped by Ubuntu with no
issues. But upgrading to a stock 3.13 kernel was apparently causing the device
to exhibit glitches, and generally misbehave.

*** Initial investigation

When asked to look into this, I first manipulated the server in various ways to
see how the issue manifests, and what triggers it. I could see that

- The =frobnicator= reports communication integrity (CI) values, and those were
  noticeably reduced on the newer kernel, which would explain the degraded
  performance
- Raising the system CPU load correlated with higher CI degradation, so a loose
  theory could be resource contention, where other tasks are taking resources
  away from the =frobnicator=
- periodically, errors would appear in the frobnicator log file
  =/var/log/frobnicator.log=, and these corresponded with periods of poor
  performance

Now that there was a concrete event that coincided with the poor performance,
this could be traced with a tool such as [[http://www.sysdig.org][sysdig]]. The hope was that one would see
what happened leading up to the reported error, and investigate that. So; first
I recorded a log

#+BEGIN_EXAMPLE
$ sudo sysdig -w frobnicator.scap proc.name = frobnicator
#+END_EXAMPLE

Then found instances where it writes complaints into its log:

#+BEGIN_EXAMPLE
$ sysdig -r frobnicator.scap fd.name contains frobnicator.log

371858 12:01:43.587694261 0 frobnicator (21343) < open fd=10(<f>/var/log/frobnicator.log) name=frobnicator.log(/var/log/frobnicator.log) flags=15(O_APPEND|O_CREAT|O_RDWR) mode=0 
371859 12:01:43.587713415 0 frobnicator (21343) > fstat fd=10(<f>/var/log/frobnicator.log) 
371860 12:01:43.587714435 0 frobnicator (21343) < fstat res=0 
371863 12:01:43.587748893 0 frobnicator (21343) > write fd=10(<f>/var/log/frobnicator.log) size=50 
371864 12:01:43.587779337 0 frobnicator (21343) < write res=51 data=[254542.588] ERROR! OH NO! COULDN'T COMMUNICATE!!! 
371865 12:01:43.587780740 0 frobnicator (21343) > close fd=10(<f>/var/log/frobnicator.log) 
371866 12:01:43.587781852 0 frobnicator (21343) < close res=0 
371872 12:01:43.587824754 0 frobnicator (21343) < open fd=10(<f>/var/log/frobnicator.log) name=frobnicator.log(/var/log/frobnicator.log) flags=15(O_APPEND|O_CREAT|O_RDWR) mode=0 
371873 12:01:43.587831903 0 frobnicator (21343) > fstat fd=10(<f>/var/log/frobnicator.log) 
371874 12:01:43.587832417 0 frobnicator (21343) < fstat res=0 
371877 12:01:43.587838779 0 frobnicator (21343) > write fd=10(<f>/var/log/frobnicator.log) size=48 
371878 12:01:43.587843915 0 frobnicator (21343) < write res=40 data=[254542.588] NOOO!! SOMETHING ELSE WENT WRONG!!! 
371879 12:01:43.587844635 0 frobnicator (21343) > close fd=10(<f>/var/log/frobnicator.log) 
371880 12:01:43.587845018 0 frobnicator (21343) < close res=0 
#+END_EXAMPLE

And then looked at what happened leading up to it, searching for anything
noteworthy:

#+BEGIN_EXAMPLE
$ sysdig -r frobnicator.scap evt.num \>= $((371858-10000)) and evt.num \<= 371858

...
365555 12:01:43.584116007 0 frobnicator (21343) > write fd=7(<f>/dev/ttyUSB2) size=7 
365556 12:01:43.584120946 0 frobnicator (21343) < write res=7 data=....... 
365557 12:01:43.584121497 0 frobnicator (21343) > fcntl fd=7(<f>/dev/ttyUSB2) cmd=5(F_SETFL) 
365558 12:01:43.584121792 0 frobnicator (21343) < fcntl res=0(<f>/dev/pts/3) 
365559 12:01:43.584123089 0 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
365560 12:01:43.584124530 0 frobnicator (21343) < read res=0 data= 
365561 12:01:43.584125440 0 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
365562 12:01:43.584125967 0 frobnicator (21343) < read res=0 data= 
365563 12:01:43.584126441 0 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
365564 12:01:43.584126830 0 frobnicator (21343) < read res=0 data= 
..... lots more hammering read() that returns 0
371853 12:01:43.587643084 0 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
371854 12:01:43.587643466 0 frobnicator (21343) < read res=0 data= 
371855 12:01:43.587651900 0 frobnicator (21343) > stat 
371856 12:01:43.587660887 0 frobnicator (21343) < stat res=0 path=frobnicator.log(/var/log/frobnicator.log) 
371857 12:01:43.587665751 0 frobnicator (21343) > open 
371858 12:01:43.587694261 0 frobnicator (21343) < open fd=10(<f>/var/log/frobnicator.log) name=frobnicator.log(/var/log/frobnicator.log) flags=15(O_APPEND|O_CREAT|O_RDWR) mode=0 
#+END_EXAMPLE

So we wrote something to the device at =/dev/ttyUSB2=, then hammered the port
waiting for a reply, then gave up reading the port without getting any data, and
complained into the log. (This hammering is embarrassing. Apparently the authors
of =frobnicator= have never heard of =select= or =poll=. This yet again supports
my theory that most proprietary software is proprietary not to protect some
brilliant IP from theft, but rather to avoid embarrassment). So presumably some
timeout expired; the =frobnicator= likely expected to get a reply from the
hardware before a certain amount of time elapsed, and this took too long. How
long /did/ it take?

#+BEGIN_EXAMPLE
$ echo $((.587651900 - .584120946))
0.0035309540000000306
#+END_EXAMPLE

So after about 3.5ms, we gave up. The serial device is set at 115200 baud. Let's
say you need 10-bits-worth of time to transmit a single byte (this is about
right probably because of the start and stop bits). To write 7 bytes and get at
least 1 byte back you need

#+BEGIN_EXAMPLE
$ echo $(( 8.*10/115200 ))
0.00069444444444444447
#+END_EXAMPLE

0.7ms just for the communication. So I guess it's not crazy to want a reply
within 3.5ms. Presumably it doesn't fail this way every time? Do we ever read
anything from USB2? Under what circumstances?

#+BEGIN_EXAMPLE
$ sysdig -r frobnicator.scap evt.type = read and fd.name contains USB2 and evt.rawres \!= 0 | head -n 10

10190 12:01:41.803108311 1 frobnicator (21343) < read res=1 data=. 
16753 12:01:41.834119153 1 frobnicator (21343) < read res=1 data=. 
23252 12:01:41.865108212 1 frobnicator (21343) < read res=1 data=. 
29817 12:01:41.896112925 1 frobnicator (21343) < read res=1 data=. 
42142 12:01:41.959126061 1 frobnicator (21343) < read res=1 data=. 
46319 12:01:41.989105762 1 frobnicator (21343) < read res=1 data=. 
52241 12:01:42.020106289 3 frobnicator (21343) < read res=1 data=. 
58206 12:01:42.051112845 3 frobnicator (21343) < read res=1 data=. 
64759 12:01:42.082126350 3 frobnicator (21343) < read res=1 data=. 
71562 12:01:42.113106478 3 frobnicator (21343) < read res=1 data=. 


$ sysdig -r frobnicator.scap evt.type = write and fd.name contains USB2 and evt.num \< 42142 | tail -n1

37288 12:01:41.957115614 1 frobnicator (21343) < write res=7 data=....... 


$ sysdig -r frobnicator.scap evt.num \>= 37288 and evt.num \<= 42142

37288 12:01:41.957115614 1 frobnicator (21343) < write res=7 data=....... 
37289 12:01:41.957116233 1 frobnicator (21343) > fcntl fd=7(<f>/dev/ttyUSB2) cmd=5(F_SETFL) 
37290 12:01:41.957116440 1 frobnicator (21343) < fcntl res=0(<f>/dev/pts/3) 
37291 12:01:41.957117828 1 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
37292 12:01:41.957118640 1 frobnicator (21343) < read res=0 data= 
37293 12:01:41.957119433 1 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
37294 12:01:41.957119972 1 frobnicator (21343) < read res=0 data= 
37295 12:01:41.957120373 1 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
37296 12:01:41.957120901 1 frobnicator (21343) < read res=0 data= 
... again. we hammer the read()
42133 12:01:41.959120974 1 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
42134 12:01:41.959121368 1 frobnicator (21343) < read res=0 data= 
42135 12:01:41.959121769 1 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
42136 12:01:41.959122160 1 frobnicator (21343) < read res=0 data= 
42137 12:01:41.959122719 1 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
42138 12:01:41.959123119 1 frobnicator (21343) < read res=0 data= 
42139 12:01:41.959123690 1 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
42140 12:01:41.959124311 1 frobnicator (21343) < read res=0 data= 
42141 12:01:41.959124846 1 frobnicator (21343) > read fd=7(<f>/dev/ttyUSB2) size=32767 
42142 12:01:41.959126061 1 frobnicator (21343) < read res=1 data=. 
#+END_EXAMPLE

So that time, we wrote to =/dev/ttyUSB2=, but did receive a response of exactly
one byte. The delay there was

#+BEGIN_EXAMPLE
$ echo $((.959126061 - .957115614 ))
0.0020104469999999708
#+END_EXAMPLE

about 2ms. OK. That's reasonable too. So it very well could be that we complain
if the response comes after 3.5ms. What's the distribution of these response
times?

#+BEGIN_EXAMPLE
$ sysdig -t r -r frobnicator.scap fd.name contains frobnicator.log or \
  \( fd.name contains ttyUSB2 and \
    \( \( evt.type = read and evt.dir = '<' and evt.rawres \!= 0\) or \
       \( evt.type = write and evt.dir = '>' \) \) \) | \
  perl -anE 'if(/write.*USB2/) { $t0 = $F[1]; }
             elsif(defined $t0 && /read|frobnicator.log/ ) { $d = $F[1] - $t0; say $d*1000; $t0 = undef; }' | \
  feedgnuplot --histo 0 --binwidth 0.1 --with boxes --set 'style fill solid border -1' \
              --title "Histogram of /dev/ttyUSB2 reply times" --xlabel "Reply (ms)" -ylabel Count
#+END_EXAMPLE

OK, so we look at the time interval between a write() to =/dev/ttyUSB2= and
either when we read() something from it, or touch =frobnicator.log= in any way.
Looks like the usual time is 1.5ms or so, and we give up at 3.5ms, as expected:

[[file:files/kernel_frobnicator/response_histogram.svg]]

I did the same thing on a working machine running the known-good 3.5 kernel: no
=frobnicator.log= error messages were observed and a response histogram made
this way is clean, and does not ever break 3.5ms. So this is consistent with the
theory that these 3.5ms timeouts are involved in the poor performance we are
seeing.

I should say that we are running vanilla Linux kernel from Ubuntu. It appears
that the =frobnicator= is expecting realtime performance from this kernel, but
*this realtime performance was never guaranteed*. So it's unlikely that the
kernel is doing anything more "wrong" now than it was before, and the
=frobnicator= just has unreasonable expectations. Anyway...

*** Initial kernel tracing

We see that an expected response from the USB device does not arrive, or arrives
too late. Many things could be causing this. I was hoping this is purely a
software issue, so I dug into the kernel. This isn't something that =sysdig= can
do, so I switched to =perf= here. I placed lots of probes into the path from the
time when we write() to =/dev/ttyUSB2= to the time when we either receive a
response or give up. Eventually I ended up with this =recordall= script:

#+BEGIN_SRC sh
#!/bin/bash

set -e

VMLINUX=/usr/lib/debug/boot/vmlinux-3.13.0-58-generic
USBSERIALDIR=/usr/lib/debug/lib/modules/3.13.0-58-generic/kernel/drivers/usb/serial
USBSERIAL=$USBSERIALDIR/usbserial.ko
FTDI=$USBSERIALDIR/ftdi_sio.ko
SOURCE=/chattel/linux

sudo perf probe --del '*' || true # let this fail

sudo perf probe -k $VMLINUX -s $SOURCE -m $FTDI      --add 'ftdi_process_read_urb urb->actual_length urb->status urb->transfer_buffer_length'
sudo perf probe -k $VMLINUX -s $SOURCE -m $FTDI      --add 'ftdi_process_packet len'
sudo perf probe -k $VMLINUX -s $SOURCE               --add 'tty_insert_flip_string_fixed_flag flag size'
sudo perf probe -k $VMLINUX -s $SOURCE               --add 'tty_schedule_flip'
sudo perf probe -k $VMLINUX -s $SOURCE               --add 'tty_schedule_flip_ret=tty_schedule_flip:6 %ax'
sudo perf probe -k $VMLINUX -s $SOURCE               --add 'flush_to_ldisc'
sudo perf probe -k $VMLINUX -s $SOURCE               --add 'receive_buf'
sudo perf probe -k $VMLINUX -s $SOURCE               --add 'n_tty_receive_buf2'
sudo perf probe -k $VMLINUX -s $SOURCE               --add 'n_tty_receive_buf_common'
sudo perf probe -k $VMLINUX -s $SOURCE               --add 'copy_from_read_buf'
sudo perf probe -k $VMLINUX -s $SOURCE               --add tty_flush_to_ldisc


sudo perf record \
     -esched:sched_{kthread_stop,kthread_stop_ret,wakeup,wakeup_new,switch,migrate_task,process_free,process_exit,wait_task,process_wait,process_fork,process_exec,stat_wait,stat_sleep,stat_iowait,stat_blocked,stat_runtime,pi_setprio,process_hang} \
     -eirq:irq_handler_{entry,exit} \
     -eirq:softirq_{entry,exit} \
     -e cs \
     -e syscalls:sys_enter_write --filter "fd==7" \
     -e syscalls:sys_enter_read  --filter "fd==7" \
     -e syscalls:sys_enter_ppoll \
     -e syscalls:sys_exit_ppoll \
     -e syscalls:sys_exit_read  --filter "ret==0 || ret==1" \
     -eprobe:ftdi_process_read_urb \
     -eprobe:ftdi_process_packet \
     -eprobe:tty_insert_flip_string_fixed_flag \
     -eprobe:tty_schedule_flip{,_ret} \
     -eprobe:copy_from_read_buf \
     -eprobe:{flush_to_ldisc,receive_buf{,_1}} \
     -eprobe:n_tty_receive_buf{2,_common} \
     -eprobe:tty_flush_to_ldisc \
     -eworkqueue:workqueue_{queue_work,activate_work,execute_start,execute_end} \
     -Ra sleep 1; sudo chown user:user perf.data

perf script | ./script_filter.pl > /tmp/`uname -n`.fg
#+END_SRC

This assumes that kernel debug symbols are available, which is one area where
Ubuntu is actually better than Debian:
[[https://wiki.ubuntu.com/Debug%20Symbol%20Packages]]. Note that the probes look at
read() and write(), some USB stuff, some TTY stuff and some process scheduling
stuff. I was adding probes one at a time as I was chasing the failure, and this
is what was there at the end; I didn't just decided to probe this set of things
from the start. After we set up the dynamic tracepoints with =perf probe=, we
record 1 second of trace data with =perf record=; this writes a binary
=perf.data= file, that can be read by =perf report= (to get statistics) and
=perf script= (to look at each individual trace).

Once we have a trace, a visualization script is used to convert it into
something that [[http://github.com/dkogan/feedgnuplot][=feedgnuplot=]] can visualize. Modulo small visualization tweaks,
=script_filter.pl= looks like this:

#+BEGIN_SRC perl
#!/usr/bin/perl

use warnings;
use feature ':5.10';


$i = 0;
my $machine = `uname -n`;
chomp $machine;
say "#!/usr/bin/feedgnuplot --dom --datai --auto --with 'points ps 2' --style cpu 'with labels' --rangesize cpu 2 --set 'key Left'";

my $arg = $ARGV[0];
$print_orig_if = qr/$arg/ if defined $arg;

while(<STDIN>)
{
    chomp;

    next unless /^ /;

    my @F = split;
    ($proc,$cpu,$t,$id, $arg) = @F[0,2,3,4,5];
    $cpu =~ s/\[(.*?)\]/$1/g; $cpu = 0 + $cpu;
    $id =~ s/probe//;
    $id =~ s/syscalls://;
    $id =~ s/workqueue://;
    $id =~ s/irq://;
    $id =~ s/sched://;
    $id =~ s/://g;
    $t =~ s/://g;

    next if $id =~ /^sys_/ && $proc ne 'frobnicator';

    # id mangling
    if ( $id eq 'sys_exit_read' )
    {
        $id .= ";ret=$arg";
    }

    my ($post) = /$id(.*)/;
    if ($post)
    {
        my @args = $post =~ /[0-9a-zA-Z_]+ *= *[0-9a-zx\.]+/g;
        for my $arg (@args)
        {
            $arg =~ s/[ \.]//g;
            $id .= ";$arg";
        }
    }



    if ( $id eq 'sys_exit_read;ret=0x0' && $proc eq 'frobnicator')
    {
        if ($last_exit_read_0)
        { $t0 = undef; }
        else
        { $last_exit_read_0 = 1; }
    }
    elsif ( $id !~ /n_tty_read|r49|tty_put_user|read_/ and $proc eq 'frobnicator')
    {
        $last_exit_read_0 = 0;
    }

    if (/sys_enter_write.*count: [0x]*7$/)
    {
        $t0 = $t;
        $i++;
    }

    if ( defined $t0 )
    {
        $d = ($t-$t0) / 1e-3;

        if( $id !~ /^ftdi|tty|workqueue_queue_work|workqueue_activate_work|irq/ && $proc !~ /frobnicator|swapper/ )
        {
            $id .= ";proc=$proc";
        }

        say "$i $id $d";

        my $icpu = $i + 0.1 + $cpu/50;
        $cpu .= ";$proc" if $id =~/actual_length=3/;
        say "$icpu cpu $d $cpu";

        say STDERR "processed: '$i(t0=$t0) $id $d', orig line: $_" if (defined $print_orig_if && $id =~ $print_orig_if);
    }

    if( $id eq 'sys_exit_read;ret=0x1' && $proc eq 'frobnicator')
    {
        $t0 = undef;
    }
}
#+END_SRC

This isn't nicely written at all; it's just a one-off made for this
investigation, and is a one-liner that got out of hand. The tracing procedure
was to run =./recordall= on a machine while it's exhibiting the troublesome
behavior, then execute the self-plotting data file it creates:
=/tmp/MACHINE.fg=. Initially, the results look like this:

[[file:files/kernel_frobnicator/perf_overview.png]]

(raster plot because of a /very/ high point count). The x-axis is each attempt
to write to =/dev/ttyUSB2= and to get a response from it. The y-axis is time, in
ms. The initial =write(/dev/ttyUSB2)= is at t=0, at the bottom of each stack.
Each type of event is plotted with a different symbol. Here I omit the legend
because there're way too many different symbols, and too much stuff going on.
Each sequence ends when we either received data from =/dev/ttyUSB2= or if we
gave up. Giving up means we stop calling read() on the port. Even with this
super busy plot we see that most cycles complete after 1-2ms, with a few ending
a bit after 3.5ms, as we have seen previously. These cycles are the problem. The
plot looks like a solid wall of events primarily because of the hammering read()
that's happening: we constantly try to read() the data, and get 0 bytes back.
Much more can be inferred if we focus on various sections of this data.

If we make the same plot, but focus /only/ on the FTDI stuff, we get this:

[[file:files/kernel_frobnicator/perf_ftdi.svg]]

OK. Much less going on. FTDI USB packets are supposed to come in every 1ms, and
we can see this: =ftdi_process_read_urb= runs in response to the USB interrupt,
and we see stuff happen every 1ms or so. Each FTDI USB packet is supposed to
contain 2 bytes of status, followed by a payload. Thus to get our 1-byte payload
into read(), we must get a USB packet that's 3 bytes long. The /great/ news here
is that we consistently see 3-byte FTDI payloads come in when they're supposed
to, even on cycles where the 3.5ms deadline was missed. For instance, the plot
above showed that cycles 11, 18 and 19 each missed the 3.5ms deadline, but in
this plot we see a 3-byte FTDI packet (blue star, orange square) arrive in time
(at about 2.1ms, 1.95ms and 1.9ms respectively). This means that the hardware
/is/ receiving the data in time, so no need to check the write() latencies,
think about buffering issues, or trace stuff in hardware. Whew. Let's see what
/success/ looks like. If we zoom in on the end of the first stack, we get this:

[[file:files/kernel_frobnicator/perf_zoom_success.svg]]

Here I show the events and which CPU they were executing on. Again, it took a
while to settle on this particular data to plot. As before, we see that the
application repeatedly calls read() which returns with 0: it's asking for data
we do not yet have. In the meantime, we see the 3-byte FTDI packet come in
(=ftdi_process_read_urb= with =actual_length=3=). This results in calls to
various functions, eventually making it to the TTY subsystem:
=tty_insert_flip_string_fixed_flag=. We =tty_schedule_flip= for later
processing; this calls =workqueue_queue_work= and =workqueue_activate_work=.
Then after a bit of time we see this deferred task run:
=workqueue_execute_start= runs with the payload function: =flush_to_ldisc=. This
does more stuff, and eventually we see read() return 1. To clarify, the
corresponding raw events coming out of =perf script= are:

#+BEGIN_EXAMPLE
         swapper     0 [000] 93115.013218: probe:ftdi_process_read_urb: (ffffffffa05868c0) actual_length=3 status=0 transfer_buffer_length=200
         swapper     0 [000] 93115.013219: probe:ftdi_process_packet: (ffffffffa05865a0) len=3
         swapper     0 [000] 93115.013220: probe:tty_insert_flip_string_fixed_flag: (ffffffff814723a0) flag=0 size=1
         swapper     0 [000] 93115.013221: probe:tty_schedule_flip: (ffffffff81472090)
         swapper     0 [000] 93115.013222: workqueue:workqueue_queue_work: work struct=0xffff88081e452810 function=flush_to_ldisc workqueue=0xffff88082ec0ac00 req_cpu=256 cpu=0
         swapper     0 [000] 93115.013223: workqueue:workqueue_activate_work: work struct 0xffff88081e452810
         swapper     0 [000] 93115.013227: probe:tty_schedule_flip_ret: (ffffffff814720bb) arg1=1
     kworker/0:1   142 [000] 93115.013234: workqueue:workqueue_execute_start: work struct 0xffff88081e452810: function flush_to_ldisc
     kworker/0:1   142 [000] 93115.013235: probe:flush_to_ldisc: (ffffffff81472500)
     kworker/0:1   142 [000] 93115.013236: probe:receive_buf: (ffffffff814725b0)
     kworker/0:1   142 [000] 93115.013237: probe:n_tty_receive_buf2: (ffffffff8146efa0)
     kworker/0:1   142 [000] 93115.013238: probe:n_tty_receive_buf_common: (ffffffff8146edc0)
     kworker/0:1   142 [000] 93115.013239: workqueue:workqueue_execute_end: work struct 0xffff88081e452810

        intrackx 24483 [001] 93115.013238: syscalls:sys_enter_read: fd: 0x00000007, buf: 0x01f417c4, count: 0x00007fff
        intrackx 24483 [001] 93115.013240: probe:copy_from_read_buf: (ffffffff8146c1f0)
        intrackx 24483 [001] 93115.013241: probe:copy_from_read_buf: (ffffffff8146c1f0)
        intrackx 24483 [001] 93115.013242: syscalls:sys_exit_read: 0x1
#+END_EXAMPLE

That makes sense. What about a failing case? Previously we saw cycle 11 time out
at 3.5ms. We do see a 3-byte USB packet arrive, so what's different about the
sequence in cycle 11 that makes things break, compared to cycle 1 where things
work? The events look like this:

[[file:files/kernel_frobnicator/perf_zoom_failure.svg]]

This generally looks similar to what we saw before. The difference is that while
the deferred task /is/ scheduled by =workqueue_queue_work= and
=workqueue_activate_work=, it does /not/ run in time. This is very consistent in
all the traces I've been looking at, and we have found our failure mechanism.

*** CPU allocation and the scheduler

Now that we know that process scheduling is somehow responsible, let's look at
the success and failure plots again, and pay attention to what the scheduler is
doing and what the various CPUs are doing.

In the success shown above, we see that on CPU 1 =frobnicator= is doing its
hammering read(), again and again. In the meantime, CPU 0 is servicing an
interrupt:

- IRQ 16 fires. It's apparently handling both USB (ehci) and ethernet (eth0).
- Both of these are handled
- then the USB is further processed by the soft IRQ handler, which (eventually)
  calls =ftdi_process_read_urb=. The events indicate that the /swapper/ process
  is what CPU 0 was doing before it was interrupted. This is an internal kernel
  *idle* process: i.e. the CPU was not doing anything.
- As before we see the scheduling of the deferred task:
  =workqueue_activate_work=.
- When this task is scheduled we see some scheduler events: =sched_stat_sleep=
  and =sched_wakeup=
- Then the soft IRQ handler exits, and the scheduler runs to decide what CPU 0
  should do next; we see more scheduler events: =sched_stat_wait= and
  =sched_switch=
- The scheduler makes the deferred task run: =workqueue_execute_start= in the
  =kworker/0:1= kernel process. The =0= in the process name means CPU 0, so the
  CPU handling the interrupt is the same as the CPU handling the deferred task.
  I see this consistently even as I change the CPU servicing the interrupt

The raw events for CPU 0 corresponding to the successful task switch are:

#+BEGIN_EXAMPLE
         swapper     0 [000] 93115.013222: workqueue:workqueue_queue_work: work struct=0xffff88081e452810 function=flush_to_ldisc workqueue=0xffff88082ec0ac00 req_cpu=256 cpu=0
         swapper     0 [000] 93115.013223: workqueue:workqueue_activate_work: work struct 0xffff88081e452810
         swapper     0 [000] 93115.013224: sched:sched_stat_sleep: comm=kworker/0:1 pid=142 delay=865313 [ns]
         swapper     0 [000] 93115.013225: sched:sched_wakeup: comm=kworker/0:1 pid=142 prio=120 success=1 target_cpu=000
         swapper     0 [000] 93115.013227: probe:tty_schedule_flip_ret: (ffffffff814720bb) arg1=1
         swapper     0 [000] 93115.013229: irq:softirq_exit: vec=6 [action=TASKLET]
         swapper     0 [000] 93115.013231: sched:sched_stat_wait: comm=kworker/0:1 pid=142 delay=0 [ns]
         swapper     0 [000] 93115.013232: sched:sched_switch: prev_comm=swapper/0 prev_pid=0 prev_prio=120 prev_state=R ==> next_comm=kworker/0:1 next_pid=142 next_prio=120
     kworker/0:1   142 [000] 93115.013234: workqueue:workqueue_execute_start: work struct 0xffff88081e452810: function flush_to_ldisc
#+END_EXAMPLE

=sched_stat_wait= says =delay=0= meaning that the =kworker/0:1= tasks did not
wait at all to be scheduled. As soon as it was ready to run, it was allowed to.
Great.

OK. What about the failure case? The raw events look like this:

#+BEGIN_EXAMPLE
     frobnicator 24483 [002] 93115.322925: syscalls:sys_enter_write: fd: 0x00000007, buf: 0x01f15cf4, count: 0x00000007
            ...
            perf 27484 [000] 93115.324019: workqueue:workqueue_queue_work: work struct=0xffff88081e452810 function=flush_to_ldisc workqueue=0xffff88082ec0ac00 req_cpu=256 cpu=0
            perf 27484 [000] 93115.324020: workqueue:workqueue_activate_work: work struct 0xffff88081e452810
            perf 27484 [000] 93115.324022: sched:sched_stat_sleep: comm=kworker/0:1 pid=142 delay=992381 [ns]
            perf 27484 [000] 93115.324023: sched:sched_wakeup: comm=kworker/0:1 pid=142 prio=120 success=1 target_cpu=000
            perf 27484 [000] 93115.324024: probe:tty_schedule_flip_ret: (ffffffff814720bb) arg1=1
            perf 27484 [000] 93115.324027: irq:softirq_exit: vec=6 [action=TASKLET]

            ... CPU 0 services the USB interrupt many more times. None of the scheduled tasks run until...
                                                
            perf 27484 [000] 93115.326706: sched:sched_stat_runtime: comm=perf pid=27484 runtime=2856449 [ns] vruntime=482196990 [ns]
            perf 27484 [000] 93115.326708: sched:sched_stat_wait: comm=kworker/0:1 pid=142 delay=2683863 [ns]
            perf 27484 [000] 93115.326709: sched:sched_switch: prev_comm=perf prev_pid=27484 prev_prio=120 prev_state=S ==> next_comm=kworker/0:1 next_pid=142 next_prio=120
            perf 27484 [000] 93115.326710: cs:  ffffffff8176300a [unknown] ([kernel.kallsyms])
     kworker/0:1   142 [000] 93115.326712: workqueue:workqueue_execute_start: work struct 0xffff88081e452810: function flush_to_ldisc
#+END_EXAMPLE

That time the hammering read() is on CPU 2 and once again the interrupt is
serviced by CPU 0. When it was interrupted, CPU 0 was not idle, however: it was
running the =perf= process (used to gather the data we're looking at). Here, the
deferred scheduling happens as in the successful case; we see =sched_stat_sleep=
and =sched_wakeup=, but the scheduled process doesn't run, at least not
immediately.

It is significant that the CPU being interrupted was idle in the successful
case: it had nothing else to do other than to service our interrupt. Here it
/did/ have something to do: when the IRQ handler exited, the CPU went back to
=perf=. Eventually =perf= releases the CPU and our task can run. Here the cycle
started at t=93115.322925, the reply was received and the task was scheduled at
t=93115.324019 (1.1ms later). However the CPU wasn't released until
t=93115.326712, which is 3.8ms after the start, and past our 3.5ms deadline.
=sched_stat_wait= even tells us that the task was sitting there for 2.68ms
waiting for the CPU.

This scenario is consistent in all the traces I collected. The interrupt and the
deferred tasks are handled by one particular CPU, while userspace applications
are free to use any CPU they want. If our USB data happens to be delivered at a
time when some user process is using the interrupt-servicing CPU, then
contention and delays can result. If we increase the system CPU load, then the
machine is spending more time crunching its userspace work, and interrupts are
more likely to fire at an inopportune time. I.e. this is all very consistent
with the observed behavior.

This feels like a fairly run-of-the-mill issue that shouldn't have been exposed
by a kernel upgrade. Why did this work on the older Linux 3.5 boxes at all? It
appears that the machines that the client is running Linux 3.13 on service the
USB interrupt on CPU 0, and this CPU may be used by any user process also. For
whatever reason, when these machines boot into Linux 3.5 instead, the USB
interrupt is serviced on CPU 12, and in practice this core is only used by the
=frobnicator= process. This mapping isn't enforced by any setting anywhere, but
it is what I'm observing. Perhaps there's some heuristic to put user processes
on the same CPU core that services most of the interrupts delivering that
process's data. While waiting for data, the =frobnicator= process spends all its
time calling read(), which in turn goes directly into the kernel. This hammering
read() behavior likely doesn't take priority over the workqueue in the kernel,
and our data can be delivered in a timely fashion. So it appears that on the
older kernel there was some sort of de-facto CPU segregation going on that
allowed the workqueue tasks to run on an uncontested CPU. I.e. we were getting
lucky.

*** Mitigation

We have a CPU contention issue. Potential fixes:

1. Make sure the CPU servicing the interrupt is never busy when an interrupt
   fires
2. Set up the process priorities to prioritize the workqueue above other user
   processes

**** Segregation

The older kernel effectively implements the first option above: the CPU
servicing the interrupt is never doing anything intensive, and can turn around
our data quickly. We can mimic this by using the =taskset= command to explicitly
set the CPU affinities of each process on the machine to stay off the CPU
servicing the USB interrupt. This CPU is controlled by the
=/proc/irq/N/smp_affinity_list= file where =N= is the IRQ number (16 on the box
the traces came from). As expected, this resolves the =frobnicator= performance
issues. This however is quite a big hammer: a whole CPU core becomes unavailable
for any other system work. So it's a good validation of the debugging so far,
but I want a better solution

**** Prioritization

As seen before, during a failure we have:

- CPU is running process =x=
- USB interrupt comes in
- Interrupt schedules deferred task
- Interrupt exits, scheduler runs, CPU goes back to =x=

We want the scheduler to make a different choice: instead of going back to the
process that was running previously, it should service our workqueue /first/.
This can be done by bumping the priority of the process servicing the workqueue.
The tricky thing is that this process is /not/ the =frobnicator=, but a
=kworker/a:b= process. As seen from the traces, on that box this process was
=kworker/0:1=. Setting a very high realtime priority to that process makes the
problem go away also:

#+BEGIN_EXAMPLE
$ chrt -p -r 99 $(pgrep kworker/0:1)
#+END_EXAMPLE

Something like this is a much better solution, since it doesn't sacrifice any
resources, and simply prioritizes the work that has tighter timing requirements
than the other tasks.

This exact command isn't a perfect final solution either, however. I don't like
touching the priority of an internal kernel process, since a later kernel change
could break the way this works. This change will have the desired effect /only/
if the =kworker= process does not change. It very well could change if the
=smp_affinity_list= contains multiple CPUs, or if something touches that file.
And the =kworker= doesn't necessary have to run on the same CPU as the
interrupt, it just happens that way; a later kernel could change that. I don't
see any kernel options to control this stuff in a better way, however. Linux 3.9
introduced higher-priority kworkers (=kworker/0:1H= for instance), but as far as
I can tell I'd need to patch the kernel to make the FTDI stack use them. That's
inherently maintenance-full. So in the end the recommendation was to

- disable the =irqbalance= daemon, which was setting the =smp_affinity_list= as
  the machine was running
- set the =smp_affinity_list= to an arbitrary, single CPU
- raise the priority of the corresponding =kworker= process

This seems to work. More system testing is required in case =irqbalance= was
actually doing something useful that people weren't aware of (this comes by
default on Ubuntu, and it's not obvious if it's a net positive or not). Any
kernel update could break something, and more testing would be required, but
that was probably assumed from the start anyway. OK. Done.

** DONE Bike headlight circuit. Again                                    :EE:
   CLOSED: [2015-09-18 Fri 22:14]

[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Bike headlight circuit continued")){/lisp}][The last time]] I dealt with this stupid headlight, I made things work with some
ridiculous construction techniques. Well, those construction techniques finally
made something die. I still had a full set of parts, and the schematics in an
EDA tool, so I laid out a PCB to try again with more reasonable construction
techniques. The schematics and layout are in their own [[https://github.com/dkogan/flashlight_regulator][git repo]]. The tools were
=gschem= and =pcb= from the gEDA project. Somebody told me to look at [[http://www.oshpark.com][oshpark]]
for the fabrication, and 3 copies of my board cost me $4. Deal. The fabbed
boards look nice:

#+ATTR_HTML: :width 80%
[[file:files/Dorcylight/shipped.jpg]]

And assembly wasn't a giant pain:

#+ATTR_HTML: :width 80%
[[file:files/Dorcylight/stuffed.jpg]]

If /this/ breaks for some reason, I /really/ should just buy another light.

** DONE Debugging GNU Emacs memory leaks (part 1)           :tools:dev:emacs:
   CLOSED: [2015-09-19 Sat 23:40]

#+begin_o_blog_alert info Follow-up posts
[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Debugging GNU Emacs memory leaks (part 2)")){/lisp}][Debugging GNU Emacs memory leaks (part 2)]]
#+end_o_blog_alert

*** Overview

Like many people I run my emacs as a long-running daemon. This allows for the
clients to start quickly, and for state to be preserved as long as the emacs
daemon is running. This works great. However, in the last year or so I've had a
very rough time doing this: something in emacs leaks memory, eats all the RAM on
my machine and at best I have to kill emacs, or at worst restart my whole
machine, since "swapping" can make it unresponsive. It's quite difficult to
debug this, since it's not obvious when memory is leaking in a long-running
process. On top of that, emacs is a lisp vm with its own GC, so it's not even
completely clear when the =free= happens, or if the memory is then returned to
the OS or not. To make it even worse, I couldn't create a reproducible test case
that would reliably leak memory quickly. If such a test existed, one could then
attempt to debug. It was only clear that during normal use memory consumption
would steadily increase. I asked on the =emacs-devel= mailing list a while back
without any obvious results:

https://lists.gnu.org/archive/html/emacs-devel/2015-02/msg00705.html

*** A leak plugged

Many months later I finally figured out how to make it leak on command, and the
results are described below and on the mailing list:

https://lists.gnu.org/archive/html/emacs-devel/2015-09/msg00619.html

Apparently starting up a daemon and then repeatedly creating/destroying a client
frame made the memory use consistently climb. The following =zsh= snippet
tickles this bug:

#+BEGIN_SRC bash
$ emacs --daemon

$ while true; do
    for i in `seq 10`; do
      timeout 5 emacsclient -a '' -c & ;
    done;
    sleep 10;
  done
#+END_SRC

The memory use could be monitored with this bit of =zsh=:

#+BEGIN_SRC bash
$ while true; do
    ps -h -p `pidof emacs` -O rss; sleep 1;
  done
#+END_SRC

The leak was visible both with =emacs -Q= (don't load any user configuration)
and with =emacs= (load my full configuration), but the leak was much more
pronounced if my configuration was loaded. I then bisected my configuration to
find the bit that was causing the leak, and I found it: =winner-mode=.

Apparently =winner-mode= keeps a list of all active frames, but it doesn't clean
dead frames off of this list. In a long-running daemon workflow frames are
created and destroyed all the time, so this list ends up keeping references to
data structures that are no longer active. This in turn prevents the GC from
cleaning up the associated memory. A simple patch to =winner-mode= fixes this,
and we can clearly see the results:

#+ATTR_HTML: :width 80%
[[file:files/emacs_leak_debugging/winner/winner.svg]]

So I fixed /a/ memory leak. It's not obvious that this is /the/ memory leak that
I'm feeling most. And clearly there are other leaks, since the memory
consumption is growing even with no configuration loaded at all. Still, we're on
our way.

** DONE Debugging GNU Emacs memory leaks (part 2)           :tools:dev:emacs:
   CLOSED: [2015-10-01 Thu 16:14]

I'm continuing to look for and plug memory leaks. The [[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Debugging GNU Emacs memory leaks (part 1)")){/lisp}][previous effort]]
successfully plugged a leak, but there's much more to find here. I found some
more stuff, which is documented here. The corresponding bug report is

http://debbugs.gnu.org/cgi/bugreport.cgi?bug=21556

*** Preliminaries

I'm instrumenting all allocation/deallocation functions, and analyzing the data
with some simple (and not-yet-nice) tools to look for anomalies. I need to
generate backtraces, so I use [[https://perf.wiki.kernel.org/][=perf=]] as the main instrumentation tool. Generally
backtraces are computed from frame pointers, but all =-O= optimization levels in
=gcc= strip those out, so I build my own emacs with =-fno-omit-frame-pointer= to
keep them in place. It is possible to make backtraces with =perf= even without
frame pointers (using DWARF debug information), but this results in much larger
trace files. This extra load generally overwhelms my machine, and important data
ends up culled at data-collection time.

I'm using the lucid X11 widgets for my emacs.

I'm on Debian/sid, so debug symbols are generally split off into separate
packages. It appears that =perf= has a bug, and needs a patch to find these
properly. I did that and posted on LKML:
http://lkml.iu.edu/hypermail/linux/kernel/1509.0/04006.html

*** Test configuration

I set up emacs to continually leak memory. Here I do that by running

#+BEGIN_SRC bash
emacs -Q --daemon
while true; do timeout 1 emacsclient -a '' -c; sleep 1; done
#+END_SRC

This is similar to the setup in the previous post, but I create one client frame
at a time instead of 10 at a time. The sequence is 1-second-with-frame followed
by 1-second-without-frame; a new frame pops up every 2 seconds. This appears to
be sufficient as the memory leaks fairly quickly. Note that there are at least
two different leaks here. One of the leaks results from an X error:

http://debbugs.gnu.org/cgi/bugreport.cgi?bug=21509

Here I do not chase that leak, but look for the non-X-error-caused leaks. I
sample the memory consumption with this zsh snippet:

#+BEGIN_SRC bash
while (true) { ps -h -p `pidof emacs` -O rss; sleep 1 } | awk '{print $2;}'
#+END_SRC

and it looks like this:

#+ATTR_HTML: :width 80%
[[file:files/emacs_leak_debugging/first_client/first_client.svg]]

This leak is about 90kB/s or 180kB/frame! As this runs, I make a record of all
memory allocation operations. I use =perf= to do this:

#+BEGIN_SRC bash
perf probe --del '*'
perf probe -x /lib/x86_64-linux-gnu/libc-2.19.so --add 'malloc=malloc bytes'
perf probe -x /lib/x86_64-linux-gnu/libc-2.19.so --add 'malloc_ret=malloc%return $retval'
perf probe -x /lib/x86_64-linux-gnu/libc-2.19.so --add 'calloc=calloc elem_size n'
perf probe -x /lib/x86_64-linux-gnu/libc-2.19.so --add 'calloc_ret=calloc%return $retval'
perf probe -x /lib/x86_64-linux-gnu/libc-2.19.so --add 'realloc=realloc oldmem bytes'
perf probe -x /lib/x86_64-linux-gnu/libc-2.19.so --add 'realloc_ret=realloc%return $retval'
perf probe -x /lib/x86_64-linux-gnu/libc-2.19.so --add 'aligned_alloc alignment bytes'
perf probe -x /lib/x86_64-linux-gnu/libc-2.19.so --add 'aligned_alloc_ret=aligned_alloc%return $retval'
perf probe -x /lib/x86_64-linux-gnu/libc-2.19.so --add 'posix_memalign alignment size'
perf probe -x /lib/x86_64-linux-gnu/libc-2.19.so --add 'posix_memalign_ret=posix_memalign%return $retval'
perf probe -x /lib/x86_64-linux-gnu/libc-2.19.so --add 'free mem'

timeout 40 perf record -m512 -r50 -g --call-graph=fp -p `pidof emacs` \
                       -eprobe_libc:{free,{malloc,calloc,realloc}{,_ret}} \
                       -eprobe_libc:aligned_alloc{,_1,_ret} \
                       -eprobe_libc:posix_memalign{,_ret}
#+END_SRC

So I probe all the memory allocation/deallocation operations and log all
inputs/outputs. This creates a (very large) =perf.data= file. Backtraces are
available if frame pointers are available, so a =malloc()= called directly from
emacs has a backtrace (because I built with =-fno-omit-frame-pointer=). However
=malloc()= that goes through something like =libgtk= first does not. =perf= can
get overloaded and not write all the data, and I make sure to only keep full
data sets.

I =perf record= for 40 seconds. Since I make a new frame every 2 seconds, about
20 new clients were created in that time.

I now convert the log file to a human-readable one:

#+BEGIN_SRC bash
perf script > script
#+END_SRC

This makes a human-readable, but even larger file.

*** Analysis

I now run the =script= file through a =parse_script.pl= tool to follow all
allocations, and report any that have not been freed:

#+BEGIN_SRC perl
#!/usr/bin/perl

use strict;
use warnings;


use feature 'say';


my $Nbytes_allocated = 0;
my %allocated;

my ($prev_addr, $prev_ret, $prev_type, $prev_realloc0, $prev_realloc0_addr, $prev_realloc0_bytes);
my $allocating;


while(<>)
{
    next unless /probe_libc:([^:]+)/;

    my $type = $1;
    my $ret = $type =~ /_ret$/;
    $type =~ s/_ret$//;


    if ( $ret && !( !$prev_ret && $type eq $prev_type) &&
         !($prev_realloc0 && $prev_type eq 'malloc' && $prev_ret && $type eq 'realloc') ) {
        die "$type ret, but prev wasn't a corresponding !ret";
    }
    elsif ( !$ret && !$prev_ret &&
            !($prev_realloc0 && $prev_type eq 'realloc' && !$prev_ret && $type eq 'malloc') &&
            $. > 1) {
        die "$type !ret following another !ret";
    }
    elsif ( $prev_realloc0 && !($type eq 'malloc' || $type eq 'realloc'))
    {
        die "realloc(0, N) must be followed by malloc(N)";
    }
    elsif ( !$ret )
    {
        if ($type eq 'malloc' && /bytes=([0-9a-z]+)/)
        {
            $allocating = hex $1;
            if ( $prev_realloc0 && $allocating != $prev_realloc0_bytes )
            {
                die "realloc(0, N) must be followed by malloc(N)";
            }
        }
        elsif ($type eq 'calloc' && /elem_size=([0-9a-z]+).*n=([0-9a-z]+)/)
        {
            $allocating = (hex $1) * (hex $2);
        }
        elsif ($type eq 'aligned_alloc' && /bytes=([0-9a-z]+)/)
        {
            $allocating = hex $1;
        }
        elsif ($type eq 'realloc' && /oldmem=([0-9a-z]+).*bytes=([0-9a-z]+)/)
        {
            if ( hex($1) == 0 )
            {
                # realloc(0, xxx) is always mapped to a malloc apparently. I treat
                # this specially
                $prev_realloc0       = 1;
                $prev_realloc0_bytes = hex $2;
            }
            else
            {
                $allocating = hex $2;
                $prev_addr = $1;
            }
        }
        elsif ($type eq 'free' && /mem=([0-9a-z]+)/)
        {
            if ( hex($1) != 0)  # free(0) does nothing
            {
                if (!defined $allocated{$1})
                {
                    say "Unallocated free at $1. Line $.";
                }
                else
                {
                    $Nbytes_allocated -= $allocated{$1}{bytes};
                    delete $allocated{$1};
                }
            }

            $ret = 1;           # free has no free-ret so I set that now
        }
        else
        {
            say "Unknown !ret line: '$_'";
            exit;
        }
    }
    elsif ( $ret )
    {
        if ( !/arg1=([0-9a-z]+)/ )
        {
            die "Ret didn't get arg1";
        }

        my $addr = $1;

        if ( hex($addr) == 0 )
        {
            say "$type returned NULL. Giving up";
            exit;
        }
        elsif ( $type =~ /^(?:[cm]alloc|aligned_alloc)$/ )
        {
            if (defined $allocated{$addr})
            {
                say "Double alloc at $addr. Line $.";
            }
            else
            {
                $allocated{$addr}{bytes} = $allocating;
                $allocated{$addr}{line} = $.;
                $Nbytes_allocated += $allocating;
            }

            if ( $prev_realloc0 && $type eq 'malloc')
            {
                $prev_realloc0_addr = $addr;
            }
        }
        elsif ( $type eq 'realloc' )
        {
            if ( $prev_realloc0 )
            {
                if ( $addr ne $prev_realloc0_addr )
                {
                    die "realloc(0, N) must be followed by malloc(N); differing addr";
                }

                $prev_realloc0       = undef;
                $prev_realloc0_addr  = undef;
                $prev_realloc0_bytes = undef;
            }
            else
            {
                my $prev0 = (hex($prev_addr) == 0);

                if (!$prev0 && !defined $allocated{$prev_addr})
                {
                    say "realloc not alloced at $prev_addr. Line $.";
                    $prev0 = 1;
                }

                if ($addr ne $prev_addr && defined $allocated{$addr})
                {
                    say "Double realloc at $addr. Line $.";
                }

                if ( !$prev0 )
                {
                    $Nbytes_allocated -= $allocated{$prev_addr}{bytes};
                    delete $allocated{$prev_addr};
                }

                $allocated{$addr}{bytes} = $allocating;
                $allocated{$addr}{line} = $.;
                $Nbytes_allocated += $allocating;
            }
        }
        else
        {
            say "Unknown ret line: '$_'";
            exit;
        }


        $allocating = undef;
    }


    $prev_type = $type;
    $prev_ret = $ret;
}


$Nbytes_allocated /= 1e6;
say "Total allocated: $Nbytes_allocated MB";
say '';

for my $addr ( sort { $allocated{$a}{line} <=> $allocated{$b}{line}} keys %allocated )
{
    my ($bytes,$line) = ($allocated{$addr}{bytes},
                         $allocated{$addr}{line});
    say "Leaked " . sprintf('%5d', $bytes) . " bytes at line $line ($addr)";
}
#+END_SRC

Allocations reported as leaky by this tool aren't necessarily leaky; I sampled
for a finite amount of time, and maybe the memory hasn't been freed /yet/.
However anything that has been allocated near the beginning of the log file, and
hasn't been freed by the end is potentially a leak, and should be investigated.
I make a plot of leak size vs line number:

#+BEGIN_SRC bash
<leaks awk '$1=="Leaked" {print $6,$2}' | feedgnuplot --domain --points --xlabel 'script line number' --ylabel 'size leaked'
#+END_SRC

and the result looks like this:

#+ATTR_HTML: :width 80%
[[file:files/emacs_leak_debugging/first_client/leaks.svg]]

Note that it looks like we leak exactly 60984 bytes (can see that when zoom in)
at regular intervals, about 20 times. There are 20 frames created in this log,
so this is a strong indication that whatever happens with those allocations
happens every time we create (or destroy) a client frame. Looking at the
backtrace for those allocations, we see that they're all in

#+BEGIN_EXAMPLE
b62c XftFontOpenInfo (/usr/lib/x86_64-linux-gnu/libXft.so.2.3.2)
#+END_EXAMPLE

So we're leaking a font! Those are large, and plugging this leak would be /very/
good. This was called through a library so no backtrace was available. I trace
this again looking /just/ at these allocations, with full DWARF backtrace
tracking:

#+BEGIN_SRC bash
perf probe -x /usr/lib/x86_64-linux-gnu/libXft.so.2 --add XftFontOpenInfo
timeout 40 perf record -m512 -r50 -g --call-graph=dwarf -p `pidof emacs` -eprobe_libc:malloc --filter bytes==60984
#+END_SRC

Backtrace:

#+BEGIN_EXAMPLE
emacs-snapshot- 17249 [001] 681364.216285: probe_libc:malloc: (7fbff4f01020) bytes=0xee38
            7fbff4f01020 malloc (/lib/x86_64-linux-gnu/libc-2.19.so)
            7fbff9b9d62c XftFontOpenInfo (/usr/lib/x86_64-linux-gnu/libXft.so.2.3.2)
            7fbff9b9e4da XftFontOpenPattern (/usr/lib/x86_64-linux-gnu/libXft.so.2.3.2)
                  5c46b5 xftfont_open (/usr/bin/emacs-snapshot-lucid)
                  5767e8 font_open_entity (/usr/bin/emacs-snapshot-lucid)
                  576e5c font_load_for_lface (/usr/bin/emacs-snapshot-lucid)
                  57703a font_open_by_spec (/usr/bin/emacs-snapshot-lucid)
                  577095 font_open_by_name (/usr/bin/emacs-snapshot-lucid)
                  4d0390 x_default_font_parameter (/usr/bin/emacs-snapshot-lucid)
                  4d7f98 Fx_create_frame (/usr/bin/emacs-snapshot-lucid)
                  55f933 Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  595823 exec_byte_code (/usr/bin/emacs-snapshot-lucid)
                  55f350 funcall_lambda (/usr/bin/emacs-snapshot-lucid)
                  55f72b Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  595823 exec_byte_code (/usr/bin/emacs-snapshot-lucid)
                  55f72b Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  560d13 Fapply (/usr/bin/emacs-snapshot-lucid)
                  55f831 Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  595823 exec_byte_code (/usr/bin/emacs-snapshot-lucid)
                  55f72b Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  595823 exec_byte_code (/usr/bin/emacs-snapshot-lucid)
                  55f72b Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  595823 exec_byte_code (/usr/bin/emacs-snapshot-lucid)
                  55f72b Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  595823 exec_byte_code (/usr/bin/emacs-snapshot-lucid)
                  55f72b Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  595823 exec_byte_code (/usr/bin/emacs-snapshot-lucid)
                  55f72b Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  560bb0 Fapply (/usr/bin/emacs-snapshot-lucid)
                  560d8a apply1 (/usr/bin/emacs-snapshot-lucid)
                  55df4a internal_condition_case_1 (/usr/bin/emacs-snapshot-lucid)
                  5992e0 read_process_output (/usr/bin/emacs-snapshot-lucid)
#+END_EXAMPLE

So this is the leaky allocation path. What's the "normal" =free= path that's not
happening? At this point I've played with this enough to notice that these
issues only come up for the first frame. If I create a frame, leave it open, and
then use my loop to create/destroy the /second/ frame, then this leak does not
occur. Probing that situation I know what the proper =free= path is:

#+BEGIN_EXAMPLE
            7fbd19a85660 free (/lib/x86_64-linux-gnu/libc-2.19.so)
            7fbd1e730af4 XftFontManageMemory (/usr/lib/x86_64-linux-gnu/libXft.so.2.3.2)
            7fbd1e72cab7 _XftCloseDisplay (/usr/lib/x86_64-linux-gnu/libXft.so.2.3.2)
            7fbd1eb64e22 XCloseDisplay (/usr/lib/x86_64-linux-gnu/libX11.so.6.3.0)
            7fbd1f4dd3d5 [unknown] (/usr/lib/x86_64-linux-gnu/libXt.so.6.0.0)
            7fbd1f4ddffa XtCloseDisplay (/usr/lib/x86_64-linux-gnu/libXt.so.6.0.0)
                  4c44ce x_delete_terminal (/usr/bin/emacs-snapshot-lucid)
                  4b604b Fdelete_terminal (/usr/bin/emacs-snapshot-lucid)
                  423397 delete_frame (/usr/bin/emacs-snapshot-lucid)
                  55f928 Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  595823 exec_byte_code (/usr/bin/emacs-snapshot-lucid)
                  55f72b Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  595823 exec_byte_code (/usr/bin/emacs-snapshot-lucid)
                  55f72b Ffuncall (/usr/bin/emacs-snapshot-lucid)
                  560bb0 Fapply (/usr/bin/emacs-snapshot-lucid)
                  560d8a apply1 (/usr/bin/emacs-snapshot-lucid)
                  55df4a internal_condition_case_1 (/usr/bin/emacs-snapshot-lucid)
                  5995cf exec_sentinel (/usr/bin/emacs-snapshot-lucid)
                  59b1d9 status_notify (/usr/bin/emacs-snapshot-lucid)
                  5a1cbf wait_reading_process_output (/usr/bin/emacs-snapshot-lucid)
#+END_EXAMPLE

Fine. Looking at the Xft sources, it looks like actual allocation of fonts
happens in =XftFontOpenInfo()=, past where we check for the font being
already-open. The actual =free()= happens in =XftFontDestroy()=. I put a probe
in each of these two places, then create/destroy a single client frame, and I
see this:

#+BEGIN_EXAMPLE
$ perf probe -x /usr/lib/x86_64-linux-gnu/libXft.so --add 'XftFontOpenInfo_alloc=XftFontOpenInfo:121'

$ perf probe -x /usr/lib/x86_64-linux-gnu/libXft.so --add XftFontDestroy

$ sudo perf record -i -p `pidof emacs` -eprobe_libXft:XftFont{OpenInfo_alloc,Destroy}
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.097 MB perf.data (7 samples) ]

$ perf script
emacs-snapshot- 16337 [000] 12141.927687: probe_libXft:XftFontOpenInfo_alloc: (7f7906641620)
emacs-snapshot- 16337 [000] 12141.961706: probe_libXft:XftFontOpenInfo_alloc: (7f7906641620)
emacs-snapshot- 16337 [000] 12141.968348: probe_libXft:XftFontOpenInfo_alloc: (7f7906641620)
emacs-snapshot- 16337 [000] 12142.010935: probe_libXft:XftFontOpenInfo_alloc: (7f7906641620)
emacs-snapshot- 16337 [001] 12142.531279: probe_libXft:XftFontDestroy: (7f7906640e40)
emacs-snapshot- 16337 [001] 12142.531471: probe_libXft:XftFontDestroy: (7f7906640e40)
emacs-snapshot- 16337 [001] 12142.531553: probe_libXft:XftFontDestroy: (7f7906640e40)
#+END_EXAMPLE

Aha. So with each frame we allocate 4 fonts, but destroy only 3. Looking at the
Xft sources, it looks like there are two different reference counters:
=info->num_unref_fonts= and =font->ref=. When a window is closed,
=XftFontManageMemory()= is called, and fonts are killed, based on
=info->num_unref_fonts=. However, this is updated in =XftFontClose()= based on
=font->ref=. So =XftFontClose()= /must/ be called by emacs and we can't assume
that a window closing will do that for us.

OK. Good to know. It looks like all the =free= calls are all coming from
=delete_frame=, which clears out everything in the font cache. How does this
font cache work? Presumably the leaky font is somehow not being added to the
cache, or somehow not being read from there properly. Let me look at the cache.
Most of the allocations come from =font_load_for_lface=. I use =gdb= to place a
breakpoint, and to look at the cache each time. When I create a frame, I should
see a new cache entry with each allocated font. The =emacs/src/.gdbinit= gdb
script has some useful macros, so in =font_load_for_lface= I can look at the
font cache with

#+BEGIN_EXAMPLE
pp f->output_data.x->display_info->name_list_element
#+END_EXAMPLE

The output of this goes to stderr, which the daemon helpfully redirects to
=/dev/null=. I can still see it with =sysdig= however. It has a buffering
problem that I get around with using =unbuffer=:

#+BEGIN_EXAMPLE
$ sudo unbuffer sysdig -s 60000 proc.pid=`pidof emacs` -c stderr | perl -ne 's/\r/\n/g; s/\n$//; print STDERR $_'     

(":0.0" (x 1) (xft 1))
(":0.0" (x 1)
  (xft 1
    (#<font-spec xft nil Monospace nil iso8859-1 nil nil nil nil nil nil nil ((:name . "monospace-10"))> .
      [#<font-entity xft unknown DejaVu\ Sans\ Mono nil iso10646-1 bold oblique normal 0 nil 100 0 ((:font-entity "/usr/share/fonts/truetype/dejavu/DejaVuSansMono-BoldOblique.ttf" . 0) (:name . "monospace-10"))>
       #<font-entity xft unknown DejaVu\ Sans\ Mono nil iso10646-1 bold normal normal 0 nil 100 0 ((:font-entity "/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf" . 0) (:name . "monospace-10"))>
       #<font-entity xft unknown DejaVu\ Sans\ Mono nil iso10646-1 normal normal normal 0 nil 100 0 ((:font-entity "/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf" . 0) (:name . "monospace-10"))>
       #<font-entity xft unknown DejaVu\ Sans\ Mono nil iso10646-1 normal oblique normal 0 nil 100 0 ((:font-entity "/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Oblique.ttf" . 0) (:name . "monospace-10"))>])))
(":0.0" (x 1) (xft 1))
(":0.0" (x 1)
  (xft 1
    (#<font-spec xft unknown DejaVu\ Sans\ Mono nil iso8859-1 nil nil nil nil nil nil nil nil> .
      [#<font-entity xft unknown DejaVu\ Sans\ Mono nil iso10646-1 bold oblique normal 0 nil 100 0 ((:font-entity "/usr/share/fonts/truetype/dejavu/DejaVuSansMono-BoldOblique.ttf" . 0))>
       #<font-entity xft unknown DejaVu\ Sans\ Mono nil iso10646-1 bold normal normal 0 nil 100 0 ((:font-entity "/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf" . 0))>
       #<font-entity xft unknown DejaVu\ Sans\ Mono nil iso10646-1 normal normal normal 0 nil 100 0 ((:font-entity "/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf" . 0))>
       #<font-entity xft unknown DejaVu\ Sans\ Mono nil iso10646-1 normal oblique normal 0 nil 100 0 ((:font-entity "/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Oblique.ttf" . 0))>])))
#+END_EXAMPLE

Aha! So I created a frame, 4 fonts were opened as usual, but for some reason
between the 2nd and 3rd font open, the cache was cleared! Since the cache stores
the fonts that eventually get deallocated, these fonts end up leaking! Where
does this happen? Placing breakpoints into the code where it looks like the
clear could be happening doesn't appear to find the culprit, and I want a
watchpoint so that gdb can tell me when the cache is touched improperly. I need
a watchpoint on an emacs lisp object, which isn't something you can do
explicitly, but I can semi-manually find the raw pointer, and set a watchpoint
on it. gdb session:


#+BEGIN_EXAMPLE
[ breakpoint on font_load_for_lface as before]

[ opened frame. breakpoint hit the first time]

(gdb) p f->output_data.x->display_info->name_list_element
$228 = 24121555

(gdb) xlist
$229 = 0x10cc824
Lisp_String
$230 = (struct Lisp_String *) 0x10cc820
":0.0"
---
$231 = 0x17011d3
Lisp_Cons
$232 = (struct Lisp_Cons *) 0x17011d0
{
  car = 0xc4e0, 
  u = {
    cdr = 0x17011c3, 
    chain = 0x17011c3
  }
}
---
$233 = 0x17011a3
Lisp_Cons
$234 = (struct Lisp_Cons *) 0x17011a0
{
  car = 0xc750, 
  u = {
    cdr = 0x1701193, 
    chain = 0x1701193
  }
}
---
nil

(gdb) p $->u.cdr
$235 = 24121747

(gdb) xpr
Lisp_Cons
$236 = (struct Lisp_Cons *) 0x1701190
{
  car = 0x6, 
  u = {
    cdr = 0x0, 
    chain = 0x0
  }
}

(gdb) watch ((struct Lisp_Cons *) 0x1701190)->u.cdr
Hardware watchpoint 24: ((struct Lisp_Cons *) 0x1701190)->u.cdr

[ disable font_load_for_lface breakpoint ]
(gdb) disa 6

(gdb) commands 24
Type commands for breakpoint(s) 24, one per line.
End with a line saying just "end".
>bt 5
>c
>end

(gdb) c
Continuing.
Hardware watchpoint 24: ((struct Lisp_Cons *) 0x1701190)->u.cdr

Old value = 0
New value = 24122275
XSETCDR (c=24121747, n=24122275) at lisp.h:1194
#0  0x000000000054cdad in XSETCDR (c=24121747, n=24122275) at lisp.h:1194
#1  0x000000000060eb2a in font_list_entities (f=0x19b7d20, spec=21168293) at font.c:2786
#2  0x00000000006107f7 in font_find_for_lface (f=0x19b7d20, attrs=0x7ffcdb167570, spec=21052973, c=-1) at font.c:3261
#3  0x0000000000610b80 in font_load_for_lface (f=0x19b7d20, attrs=0x7ffcdb167570, spec=21052973) at font.c:3334
#4  0x0000000000610f72 in font_open_by_spec (f=0x19b7d20, spec=21052973) at font.c:3428
#5  0x0000000000610fe5 in font_open_by_name (f=0x19b7d20, name=17336596) at font.c:3439

Lisp Backtrace:
"x-create-frame" (0xdb1678a0)
"x-create-frame-with-faces" (0xdb167dd8)
0x12b9d80 PVEC_COMPILED
"apply" (0xdb168450)
"frame-creation-function" (0xdb1689f0)
"make-frame" (0xdb168f40)
"make-frame-on-display" (0xdb1694a8)
"server-create-window-system-frame" (0xdb169a78)
"server-process-filter" (0xdb169ff8)
Hardware watchpoint 24: ((struct Lisp_Cons *) 0x1701190)->u.cdr

Old value = 24122275
New value = 0
0x00000000005d2172 in compact_font_cache_entry (entry=24121763) at alloc.c:5313
#0  0x00000000005d2172 in compact_font_cache_entry (entry=24121763) at alloc.c:5313
#1  0x00000000005d221b in compact_font_caches () at alloc.c:5339
#2  0x00000000005d2742 in garbage_collect_1 (end=0x7ffcdb166830) at alloc.c:5515
#3  0x00000000005d2e1d in Fgarbage_collect () at alloc.c:5720
#4  0x000000000054eb21 in maybe_gc () at lisp.h:4515
#5  0x00000000005f638c in Ffuncall (nargs=3, args=0x7ffcdb166988) at eval.c:2584

Lisp Backtrace:
"Automatic GC" (0x0)
"map-keymap" (0xdb166990)
"keymap-canonicalize" (0xdb166f38)
"x-create-frame" (0xdb1678a0)
"x-create-frame-with-faces" (0xdb167dd8)
0x12b9d80 PVEC_COMPILED
"apply" (0xdb168450)
"frame-creation-function" (0xdb1689f0)
"make-frame" (0xdb168f40)
"make-frame-on-display" (0xdb1694a8)
"server-create-window-system-frame" (0xdb169a78)
"server-process-filter" (0xdb169ff8)
Hardware watchpoint 24: ((struct Lisp_Cons *) 0x1701190)->u.cdr

#+END_EXAMPLE


Bam! The font cache was unexpectedly (to me) touched in
=compact_font_cache_entry=. Looking at the font cache before and after this call
makes it clear that this is the call that's erroneously clearing the font cache.
Apparently it's part of the mark/sweep GC that runs in the sweep phase. For
whatever reason the leaked font isn't marked, so the GC is clearing it out from
the cache. This seems wrong, since simply taking it out of the cache will result
in it not being freed later, but that's irrelevant: this font is not unused, so
it should have been marked. Looking at the font marking business, the issue
becomes clear: each font entity object contains a list of fonts. In
=compact_font_cache_entry= we look for marks on the entity and not in any
individual font. Apparently it is possible for an unmarked entity to contain a
marked font, and this case wasn't being checked. And adding this check to
=compact_font_cache_entry= makes this leak go away entirely. There could be
other smaller leaks that happen here, but they're now hard to see because the
leak in http://debbugs.gnu.org/cgi/bugreport.cgi?bug=21509 now dominates. Done!

** more emacs                                                      :noexport:


So what are these leaks? I follow all these 60984-byte allocations with a
=follow_alloc.pl= script:

#+BEGIN_SRC perl
#!/usr/bin/perl
use strict;
use warnings;

use Getopt::Euclid;
use feature ':5.10';

my $size = sprintf('0x%x', $ARGV{'<size>'} =~ /^0x/ ? hex($ARGV{'<size>'}) : $ARGV{'<size>'} );


my $next_after_alloc_type;
my %addrs;

my $refcount = 0;

my $printing;

while(<>)
{
    if(/^$/)
    {
        print "\n" if $printing;
        $printing = undef;
        next;
    }

    if( $printing && /^\s/ )
    {
        print;
        next;
    }


    next unless /probe_libc:([^:]+)/;

    if( /$size\b/ )
    {
        if(/realloc/)
        {
            die "realloc not supported";
        }

        my $type = /probe_libc:([a-z_]+)/;
        ($next_after_alloc_type) = $type;

        # I don't print allocation entries. Those aren't interesting. Allocation
        # EXITS are interesting and I print those further down
        # doprint();
    }
    elsif( $next_after_alloc_type )
    {
        my $type = /probe_libc:([a-z_]+)/;
        if($type ne $next_after_alloc_type)
        {
            die "Didn't get ret for type $type";
        }

        my ($addr) = /arg1=(0x[0-9a-f]+)/;
        $addrs{$addr} = 1;

        $next_after_alloc_type = undef;

        $refcount++;

        doprint();
        next;
    }
    else
    {
        for my $addr(keys %addrs)
        {
            if(/$addr\b/)
            {
                if(/free|realloc/)
                {
                    $refcount--;
                }

                delete $addrs{$addr};
                doprint();
            }
        }
    }
}

sub doprint
{
    $printing = 1;
    print "Line: $. Refcount: $refcount. $_";
}



=head1 NAME

follow_alloc.pl - trace allocation of a particular size

=head1 SYNOPSIS

 $ ./follow_alloc.pl --size 0x1234

=head1 DESCRIPTION

Looks at C<perf script> output and reports stuff

=head1 REQUIRED ARGUMENTS

=over

=item <size>

Size of allocation to trace

=for Euclid:
  size.type: /0x[0-9a-f]+|[0-9]+/

=back

=head1 AUTHOR

Dima Kogan, C<< <dima@secretsauce.net> >>
#+END_SRC

This acts as a filter to pull out the salient parts of the =script= file:

#+BEGIN_SRC bash
<script ./follow_alloc.pl 60984 > follow
#+END_SRC

#+begin_o_blog_alert info Follow-up posts
[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Already-running process notifications")){/lisp}][Already-running process notifications]]

[[file:{lisp}(ob:link-to-post (ob:get-post-by-title "Even better notifications")){/lisp}][Even better notifications]]
#+end_o_blog_alert





** Math. Horizonator?
** multi-arch in general



* making dvipng work                                               :noexport:
- OPTIONS do not work. Need to enable explicitly with
  (setq org-html-with-latex 'dvipng)

- o-blog translates the path of file: links and copies the file in
  (o-blog-publish-linked-files)

- equations aren't processed there

- equations are touched by the ltxpng stuff in ox-html.el such as

  org-html--format-image

* init                                                             :noexport:
Local Variables:
eval: (progn
          (org-babel-do-load-languages
           'org-babel-load-languages
            '((gnuplot . t)))
          (setq org-format-latex-options (plist-put (plist-put org-format-latex-options :background "White") :foreground "Black"))
          (auto-fill-mode)
          (load-library "compile")
          (load-library "o-blog")
          (setq org-html-table-default-attributes
            '(:border "2" :cellspacing "0" :cellpadding "6" :rules "all" :frame "box"))
          (local-set-key (kbd "<f5>")
                         (lambda () (interactive)
                           (org-publish-blog (buffer-file-name))
                           (browse-url "http://127.0.0.1/blog/")))
          (local-set-key (kbd "<S-f5>")
                         (lambda () (interactive)
                           (shell-command "cd out; git clean -ffdx")
                           (org-publish-blog (buffer-file-name))
                           (shell-command "git push; cd out; git add -A && git commit -a -m 'update' && git push;")))
          (defun ob:link-to-post (post)
            (format "%s/%s" (ob:path-to-root) (ob:post-htmlfile post)))
          (defun ob:get-post-by-title (title)
            (let ((posts (ob:get-posts
                          (lambda (x)
                            (equal title (ob:post-title x)))
                          1)))
              (if posts (car posts) nil))))
End:
